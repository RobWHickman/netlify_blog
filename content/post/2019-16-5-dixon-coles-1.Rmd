---
title: "An Introduction to Modelling Soccer Matches in R (part 1)"
author: "Robert Hickman"
date: '2019-05-16'
output:
  html_document:
    df_print: paged
header:
  caption: ''
  image: ''
slug: dixon_coles_1
tags:
- football
- models
categories: []
---

---
title: "Untitled"
output: html_document
---
_There are various claims in this post that are not strictly true and indeed, this post does not even actaully model the main points of the Dixon and Coles 1997 paper, but please not the title says part 1 and some of these things will be addressed in later posts_

```{r libraries, warning=FALSE,message=FALSE}
# munging
library(tidyverse)
library(magrittr)
# use opisthokonta's goalmodel package as sanity check
# https://github.com/opisthokonta/goalmodel
library(goalmodel)

# seed for reproducibility
set.seed(3459)
```

##Set up

Lets imagine a summer league between 6 English football clubs where each team plays each other twice (once at home and once away)

```{r teams, warning=FALSE,message=FALSE}
teams <- c("Arsenal", # 5th in the 1st tier
           "Blackburn_Rovers", # 15th in 2nd tier
           "Coventry_City", # 8th in 3rd tier
           "Dover_Athletic", # 14th 5th tier 
           "Enfield_Town", # 10th in 7th tier
           "Frimley_Green") # 2nd in 9th tier

```

We've managed to arrange a league that has a nice stratification between teams, so we'd expect each to be comfortably better than the next best (which will make sanity checking our results easier). Lucky for us, the teams are also in alphabetical order of strength so in case you don't have any prior on a team, take the first letter of it's name (A-F).

Each week each team play one game, so we'll have a fixture list that looks like:

```{r create_fixtures, warning=FALSE,message=FALSE,include=FALSE}
#https://stackoverflow.com/questions/54099990/is-there-an-efficient-algorithm-to-create-this-type-of-schedule
create_fixtures <- function(teams) {
  team1 <- as.character(teams[1])
  other_teams <- as.character(teams[!teams %in% team1])
  length <- length(other_teams)
  
  for(week in seq((length(teams)-1)*2)) {
    
    if(week %% 2 == 0) {
      fixtures <- data.frame(home = c(team1, other_teams[1:2]),
                             away = other_teams[length:3],
                             gameweek = week)
    } else {
      fixtures <- data.frame(home = other_teams[length:3],
                             away = c(team1, other_teams[1:2]),
                             gameweek = week)
      
    }
    
    if(week == 1) {
      fixtures_df <- fixtures 
    } else {
      fixtures_df <- rbind(fixtures_df, fixtures)
    }
    
    other_teams <- c(other_teams[length], other_teams[1:length-1])
  }
  
  return(fixtures_df)
}

fixtures <- create_fixtures(teams) %>%
  mutate_if(is.factor, as.character)
```
```{r create_results, warning=FALSE,message=FALSE,include=FALSE}
model <- list()
model$parameters <- list(attack = seq(1, -1 + 2/length(teams), by = -2/(length(teams)-1)) %>%
                           append(-sum(.)) %>%
                           `names<-`(teams), 
                         defense = seq(1, -1 + 2/length(teams), by = -2/(length(teams)-1)) %>%
                           append(-sum(.)) %>%
                           `names<-`(teams), 
                         intercept = 0, 
                         hfa = 0.3)

model$all_teams <- teams

model$model <- "poisson"
model$maxgoal <- 8

results <- predict_expg(model, fixtures$home, fixtures$away, return_df = TRUE) %>%
  mutate(noise1 = rnorm(nrow(.), 0, 0.5),
         noise2 = rnorm(nrow(.), 0, 0.5)) %>%
  mutate(hgoal = round(expg1 + noise1,0 ),
         agoal = round(expg2 + noise2,0),
         home = as.factor(team1),
         away = as.factor(team2)) %>%
  merge(., fixtures, by = c("home", "away")) %>%
  mutate_at(vars(hgoal:agoal), funs(replace(., .<0, 0))) %>%
  select(home, away, hgoal, agoal, gameweek) %>%
  arrange(gameweek, home) %>%
  filter(gameweek <= 8)

results
```

```{r show_fixtures, warning=FALSE,message=FALSE}
head(fixtures, 8)
```

Obviously for this we're going to have to make up our data. For the code used to generate it, see the bottom of the post.

Let's say that we've had 8 weeks of games played so far, and the results have been as follows

```{r print_results, warning=FALSE,message=FALSE}
head(results,8)
```

A better way to show this is to generte a matrix of home (y axis) vs. away (x axis) which gives us:

```{r plot_results, warning=FALSE,message=FALSE}
p1 <- results %>%
  # remove unplayed games
  filter(!is.na(hgoal)) %>%
  ggplot(., aes(x = away, y = home, fill = hgoal-agoal)) +
  geom_tile() +
  # add the scorelines
  geom_label(aes(label = paste(hgoal, agoal, sep = "-")), fill = "white") +
  # colour where green shows home win and red an away win
  scale_fill_gradient2(low = "darkred", high = "green", midpoint = 0, guide = FALSE) +
  scale_x_discrete(limits = levels(results$home), position = "top") +
  scale_y_discrete(limits = rev(levels(results$away))) +
  theme_minimal()

# plot
p1
```

As the colour gradient (from bottom right to top left) shows, the teams we'd expect to do better are. Given the stochastic nature of football though, there are some surprises. E.g. Blackburn only managing to draw at home to Coventry.

A good sense of teams relative abilities can be seen in the league table of results so far (assuming 3 points for a win, and 1 for a draw):

```{r}
# function to melt results
# returns df with team and goals for and against for each match
melt_results <- function(results_df) {
  results_df %>%
    # select only relevant columns
    select(home, away, hgoal, agoal) %>%
    gather(location, team,  -hgoal, -agoal) %>%
    # calculate goals for/against the team
    mutate(g_for = case_when(
      location == "home" ~ hgoal,
      location == "away" ~ agoal
    )) %>%
    mutate(g_ag = case_when(
      location == "home" ~ agoal,
      location == "away" ~ hgoal
    )) 
}

# function to calculate points won and gd for each team
results_to_table <- function(results_df) {
  results_df %>%
    # use above melting function
    melt_results(.) %>%
    # 3 points for a win, 1 for a draw
    mutate(points = case_when(
      g_for > g_ag ~ 3,
      g_ag > g_for ~ 0,
      g_for == g_ag ~ 1
    )) %>%
    # calculate goal difference for each match
    mutate(gd = g_for - g_ag) %>%
    group_by(team) %>%
    # get the final statistics per team
    summarise(games_played = n(),
              gf = sum(g_for),
              ga = sum(g_ag),
              gd = sum(gd),
              points = sum(points)) %>%
    arrange(-points, -gd, -gf)
}

# calculate league table for our played fixtures
league_table <- results  %>%
  filter(!is.na(hgoal)) %>%
  select(-gameweek) %>%
  results_to_table(.) %>%
  print()

```

Where teams positions are nicely rank ordered (the data for this example is fairly curated so it's not that surprising).

##Predictions

With two rounds to go, there's still 6 fixtures we might want to predict (to try and judge which team will end up where, or just to bet on the remaining games).

This are:

```{r remaining_fixtures, warning=FALSE,message=FALSE}
# get the yet to be played matches
unplayed_games <- fixtures %>%
  filter(gameweek > 8) %>%
  print()
```

Before we can predict these though we need to understand how scoring in football is distributed.

Using real data from the engsoccerdata package we can get the results of all 48840 English football league games between August 1992 and May 2016. If we melt this to get the goals scored by each team by their location we get a df of 97680 records such as:

```{r real_world_data, warning=FALSE,message=FALSE}
# load real data from the english league
real_data <- engsoccerdata::england %>%
  # filter out 'premier league era' matches
  filter(Season > 1991) %>%
  # select only relevant columns
  select(home, away = visitor, hgoal, agoal = vgoal) %>%
  # munge
  melt_results() %>%
  select(-hgoal, -agoal) %>%
  mutate(data = "real")

head(real_data)
```
Plotting this shows a nice humped distribution with slightly offset peaks for home and away. 

```{r plot_real_goal_distributions, warning=FALSE,message=FALSE}
# plot goals scored home/away for real english football matches
p2 <- real_data %>%
  ggplot(., aes(x = g_for, fill = location)) +
  # smooth densities
  geom_density(adjust = 8, alpha = 0.5) +
  scale_fill_manual(values = c("red", "blue")) +
  labs(title = "Goals scored at home and away in English football",
       subtitle = "data from 48.8k matches 2000-2016",
       x = "goals scored",
       y = "density") +
  theme_minimal()

# plot
p2

```

That is to say, teams score more on average when playing at home than away.

```{r mean_goals_by_location, warning=FALSE,message=FALSE}
# calculate mean home and away goals
real_data_means <- real_data %>%
    group_by(location) %>%
    summarise(mean_scored = mean(g_for)) %>%
  print()

```

Goals in games are both relatively sparse, and relatively stochastic, football is a low scoring game where goals are evenly distributed throughout the game. In theory any attack made by a team i has a probability of being scored dependent upon the strength of team i's attack (α~i~) which is independent of all the other attacks that team has made.

(there is some reason to doubt this may be the case, but as I said above, for now this is a fine generalisation)

By grouping all teams together into "home" and "away" categories (in a league setting each team will play each other home and away so this should average out) and taking the average number of goals scored per match as the Poisson mean (λ) we can see how well our above graph fits a simulated Poisson process.

```{r simulated_poisson, warning=FALSE,message=FALSE}
# generate Poisson distributed vector with mean = real world mean
simulated_poisson <- real_data_means %>%
  split(f = .$location) %>%
  lapply(., function(x) df = data.frame(dist = rpois(100000, x$mean_scored),
                                        location = x$location)) %>%
  # map it all together and label
  map_df(I) %>%
  mutate(data = "simulated") 

# add these distributions to the plot
p2 + geom_density(data = simulated_poisson, aes(x = dist), fill = NA, adjust = 8, alpha = 0.2) +
  scale_fill_manual(values = c("red", "blue"), guide = FALSE) +
  facet_wrap(~location)

```

It's not perfect. But it's not a bad fit either

```{r chi_squared, warning=FALSE,message=FALSE}
# calc chi squared for home and away goals following Poisson distribution
calc_chi_squared <- function(game_location) {
  goals_scored <- filter(real_data, location == game_location)$g_for
  
  observed_goal_counts <- table(goals_scored)

  mean_goals <- mean(goals_scored)
  
  probs = dpois(sort(unique(goals_scored)), lambda = mean_goals) %>%
    append(., 1-sum(.))
  
  # the chi squared test
  test <- chisq.test(x = c(observed_goal_counts,0), p = probs, simulate.p.value = TRUE)
  test$data.name <- game_location
  
  return(test)
}

# run test for both home and away goals
lapply(c("home", "away"), calc_chi_squared)

```

It's actually perhaps not as significant as might be expected given the sheer amount of observations we have (see above reservations about modelling goals as a Poisson process) but it's clearly not the worst approximation either.


The simplest model we can produce is to estimate λ as each team's attack rating (α~i~) which is equal to observed mean rate of goals.

That is the say the probability of team i scoring x goals against team j is:

$P(X_{i,j} = x) = \frac{\alpha_{i}^{x}e^{-\alpha_{i}}}{x!}$

where:

$\alpha_{i} = \frac{1}{N}\sum_{n=1}^{N} x$

grouping by teams makes this easy to calculate

```{r basic_model_paramters, warning=FALSE,message=FALSE}
basic_model <- results %>%
  melt_results() %>%
  group_by(team) %>%
  # we'll use the goals scored to model the attack
  # and goals conceeded to measure defence rating
  summarise(av_scored = mean(g_for),
            av_conceed = mean(g_ag)) %>%
  print()
```

If we take Coventry's remaining two games as examples we can see that they are yet to play Arsenal and Frimley Green at home

```{r coventry_fixtures, warning=FALSE,message=FALSE}
coventry_games <- unplayed_games %>%
  # filter out Coventry City's remaining fixtures
  filter(grepl("Coventry_City", home)) %>%
  print()

```

And we can take the attack rating of each team and use it to estimate the results

```{r attack_estimates, warning=FALSE,message=FALSE}
# get the attack ratings of all teams
attack_parameters <- basic_model$av_scored %>% `names<-`(basic_model$team)

# assume goals scored for each team will be it's attack rating
e_results <- paste(attack_parameters[coventry_games$home],
                   attack_parameters[coventry_games$away],
                   sep = "-") %>%
  # name each match with the teams competing
  `names<-`(c(paste(coventry_games$home, coventry_games$away, sep = "-"))) %>%
  print()
```

These aren't ridiculous estimates by any stretch but it's clear something is up. It's pretty intuitive that Coventry City would be expected to score more goals at home to Frimley Green than at home to Arsenal.

We can account for this by introducing an opposing team defence paramter β~j~. In our very simple model this will be estimating by taking the average rate a team conceedes goals (x per game). We'll then multiply α~i~ and β~j~ together to get the score estimate

```{r defence_estimates, warning=FALSE,message=FALSE}
# get and name the defence rating for each team
defence_parameters <- basic_model$av_conceed %>% `names<-`(basic_model$team)

# assume the goals scored will be the attack rating of the team times 
# the defence rating of it's opponent
e_results <- paste(round(attack_parameters[coventry_games$home]*
                           defence_parameters[coventry_games$away], 3),
                   round(attack_parameters[coventry_games$away]*
                           defence_parameters[coventry_games$home], 3),
                   sep = "-") %>%
  `names<-`(c(paste(coventry_games$home, coventry_games$away, sep = "-"))) %>%
  print()

```

The opposition scores remain the same because Coventry have on average conceeded 1 goal per game. Coventry's predicted goals though has diverged with them now predicted to score less than a goal against Arsenal and to score 8(!) against Frimley Green, both of which sound reasonable.

However, we're also missing one final piece of the model we'll finish with today. Recall modelling the English football data from 1992 onwards, we were left with

```{r reprint_mean_goals_by_location, warning=FALSE,message=FALSE}
# reprint what we calculated earlier
real_data_means
```

It's pretty common knowledge that football teams do better at home, so we'll want to factor that in. A simple estimate is to divide the mean home goals/game by the mean away goals/game.

We'll call this parameter γ and can be formalised as

$\gamma = \frac{\sum{X_{i}}}{\sum{X_{j}}}$

```{r add_home_advantage, warning=FALSE,message=FALSE}
# the home advantage is how much easier it is to score at home
home_advantage <- sum(results$hgoal) / sum(results$agoal)

e_results <- paste(round(attack_parameters[coventry_games$home]*
                           defence_parameters[coventry_games$away] * 
                           # add in home advantage for home team
                           home_advantage, 3),
                   round(attack_parameters[coventry_games$away]*
                           defence_parameters[coventry_games$home], 3),
                   sep = "-") %>%
  `names<-`(c(paste(coventry_games$home, coventry_games$away, sep = "-"))) %>%
  print()

```

If we put this all together we can predict the remaining 6 matches nice and easily

```{r predict_fixtures, warning=FALSE,message=FALSE}
gamma <- home_advantage

# wrap the above into a function for home and away teams
predict_results <- function(home, away, parameters) {
  e_goals_home <- parameters$alpha[home]*parameters$beta[away] * gamma
  e_goals_away <- parameters$alpha[away]*parameters$beta[home]
  
  # output a df of expected goals for home and away teams
  df <- data.frame(home = home, away = away,
                   e_hgoal = e_goals_home, e_agoal = e_goals_away)
  return(df)
}

# convert the basic_model df into a list with $attack and $defence parameters
# for each team
basic_parameters <- basic_model %>%
  # rename scored/conceeded to attack/defence
  rename_if(is.numeric, function(x) c("alpha", "beta")) %>%
  select(-team) %>%
  # convert to a list and name each element
  as.list() %>%
  lapply(., function(x){names(x) <- teams;return(x)})

# predict results using the function defined above and the list of parameters
predicted_fixtures <- map2_df(unplayed_games$home, unplayed_games$away, 
                    predict_results,
                    # parameters forms an extra argument that does not vary
                    basic_parameters) %>%
  # round the outputs
  mutate_if(is.numeric, round, digits = 2) %>%
  print()

```

All of which look reasonable, if maybe a little bullish on the 'better' teams prospects.

However, while this is good for back of the envelope predictions, we know that this is a very basic model. If we want to improve it, first we must quantify how good it is.

We want to use this model to predict the results we already have observations. Once we have the expected home and away goals. As the expected value is equal to the λ of each Poisson distribution we can see how likely the _observed_ goals are given the expected goals.

This is a lot easier to explain by doing and combining into one df. The lik_hgoal (e.g.) is the log likelihood of a team scoring that many goals if the model is correct.

```{r predict_results, warning=FALSE,message=FALSE}
# 'predict' the already played matches using our function
predicted_results <- map2_df(results$home, results$away, 
                    predict_results,
                    basic_parameters) %>%
  mutate_if(is.numeric, round, digits = 2) %>%
  print()

# calculate the likelihood of each home/away team actually scoring that many goals
# given the parameters for attack/defence supplied
likelihoods <- data.frame(lik_hgoal = dpois(results$hgoal,
                                            predicted_results$e_hgoal),
                          lik_agoal = dpois(results$agoal,
                                            predicted_results$e_agoal)) %>%
  # round the probabilities
  mutate_all(round, 4) %>%
  # bind likelihoods to results
  cbind(results, . ) %>%
  # bind in predictions
  left_join(., predicted_results, by = c("home", "away")) %>%
  # select useful parameters
  select(home, away, hgoal, e_hgoal, lik_hgoal, agoal, e_agoal, lik_agoal) %>%
  print()
```

If we sum the log of those likelihood values we get a measure of how wrong overall our predictions are

```{r calc_likelihood, warning=FALSE,message=FALSE}
log_likehood <- sum(log(likelihoods$lik_hgoal), log(likelihoods$lik_agoal)) * -1

log_likehood

```
(n.b. there'll be some rounding errors- especially on the pre-log probabilities, but this will suffice for now)

To get an idea of whether or not this is good, let's quickly run the model with all the parameters set to zero

```{r calc_worse_log_lik, warning=FALSE,message=FALSE}
# do the same but set each teams attack and defence to 1
# expect model to be worse as assumes all teams are equal
equal_parameters <- list(
  alpha = rep(1, length(teams)) %>% `names<-`(teams),
  beta = rep(1, length(teams)) %>% `names<-`(teams)
)

# predict results and munge through to find sum of log likelihoods
worse_log_likelihood <- map2_df(results$home, results$away, 
                    predict_results,
                    equal_parameters) %>%
  mutate_if(is.numeric, round, digits = 2) %>%
  # take the log probability straight away this time
  mutate(lik_hgoal = dpois(results$hgoal, e_hgoal, log = TRUE),
         lik_agoal = dpois(results$agoal, e_agoal, log = TRUE)) %>%
  select(lik_hgoal, lik_agoal) %>%
  map_dbl(sum) %>%
  sum(.) * -1 

worse_log_likelihood

```
There will exist some parameters (α and β for each team, and γ for the home field advantage) that will minimise this negative log likehood. That is to say, they will predict the results of the already played games most accurately.

If we want to find those we can use the optim() function in the stats package. This will take a vector of paramaters and iterate while slightly changing their values until it gets the lowest value it can find as the output for a supplied function.

The function that we want to minimise the value from is a combination of those above. First we want to relist parameters (as optim takes parameters as a vector), then use those parameters to predict the result. The negative log likelihood to be minised is then calculated from comparing those predicted and actual results.

```{r optim_function, warning=FALSE,message=FALSE}
optimise_params <- function(parameters, results) {
  # form the parameters back into a list
  # parameters names alpha (attack), beta (defense), and gamma (hfa)
  param_list <- relist_params(parameters)
  
  # predict the expected results for the games that have been played
  e_results <- map2_df(results$home, results$away, 
                      predict_results,
                      param_list)
  
  # calculate the negative log likelihood of those predictions
  # given the parameters how likely are those scores
  neg_log_likelihood <- calculate_log_likelihood(results, e_results)
  
  # capture the parameters and likelihood at each loop
  # only do it if i is initialised
  if(exists("i")) {
    i <<- i + 1
    current_parameters[[i]] <<- parameters
    current_nll[[i]] <<- neg_log_likelihood
  }
  
  # return the value to be minimised
  # in this case the negative log likelihood
  return(neg_log_likelihood)
}

```

The three separate functions are coded out separately so we can tinker with them shortly:

```{r optim_subfunctions, warning=FALSE,message=FALSE}
# optim requires parameters to be supplied as a vector
# we want to re list with 
relist_params <- function(parameters) {
  parameter_list <- list(
    # alpha = attack rating
    alpha = parameters %>%
      .[grepl("alpha", names(.))] %>%
      `names<-`(teams),
    # beta = defence rating
    beta = parameters %>%
      .[grepl("beta", names(.))] %>%
      `names<-`(teams),
    # gamma = home field advantage
    gamma = parameters["gamma"]
  )
  
  return(parameter_list)
}

# use these parameters to predict results for supplied matches
predict_results <- function(home, away, param_list) {
  # expected home goals
  e_goals_home <- param_list$alpha[home] * param_list$beta[away] * param_list$gamma
  # expected away goals
  e_goals_away <- (param_list$alpha[away] * param_list$beta[home])
  
  # bind to df
  df <- data.frame(home = home, away = away,
                   e_hgoal = e_goals_home, e_agoal = e_goals_away)
  
  return(df)
}

# calculate the log likelihood of predict results vs supplied results
calculate_log_likelihood <- function(results, e_results) {
  home_likelihoods = dpois(results$hgoal, lambda = e_results$e_hgoal, log = TRUE)
  away_likelihoods = dpois(results$agoal, lambda = e_results$e_agoal, log = TRUE)
  
  # sum log likelihood and multiply by -1 so we're minimising neg log likelihood
  likelihood_sum <- sum(home_likelihoods, away_likelihoods)
  neg_log_likelihood <- prod(likelihood_sum, -1)
  
  return(neg_log_likelihood)
}
```

We'll supply parameters that are all equal to 1 to optim to stop it falling into local minima that might affect the 'optimal' parameters it finds. The unlisted parameters are then supplied to optim along with the optimise_parameters() function.

```{r basic_optimal_parameters, warning=FALSE,message=FALSE}
# start with all parameters equal
equal_parameters <- list(
  alpha = rep(1, length(teams)) %>% `names<-`(teams),
  beta = rep(1, length(teams)) %>% `names<-`(teams),
  gamma = 1
)

# run optim over the functions with these initial parameters
optimised_parameters <- optim(
  # the equal initial parameters
  par = unlist(equal_parameters),
  # run over the function to optimise parameters
  fn = optimise_params,
  # extra arguments to function
  results = results,
  # Nelder-Mead equation with 10k iterations max
  method = "Nelder-Mead",
  control = list(maxit = 10000)
  )

```

We can take the $par element of the output of this to find the parameters for which the negative log likelihood is minimised

```{r basic_optimisation, warning=FALSE,message=FALSE}
# display the parameters found to minimise
# the negative log likelihood
optimised_parameters$par
```

As expected, alpha decreases as teams get worse, and beta increases. The found gamma (1.166) is only marginally higher than the 1.091 for our simple model.

The $value element gives the negative log likelihood calculated for these parameters

```{r basic_min_log_likelihood, warning=FALSE,message=FALSE}
optimised_parameters$value
```

Which is much smaller than the ~100 we got from our very basic model.

## Tinkering

This is all very well but there's still some small improvements we can make.

```{r inverted_beta_parameter, warning=FALSE,message=FALSE,eval=FALSE}
# change prediction to inverse defence parameters
predict_results <- function(home, away, param_list) {
  e_goals_home <- (param_list$alpha[home] / param_list$beta[away]) * param_list$gamma
  e_goals_away <- (param_list$alpha[away] / param_list$beta[home])
  
  df <- data.frame(home = home, away = away,
                   e_hgoal = e_goals_home, e_agoal = e_goals_away)
  
  return(df)
}

# re run using new subfunction
optimised_parameters2 <- optim(
  par = unlist(equal_parameters),
  fn = optimise_params,
  results = results,
  method = "Nelder-Mead",
  control = list(maxit = 10000))
```

```{r log_parameters, warning=FALSE,message=FALSE}
# change prediction to use log parameters
# exp(log(x) + log(y)) = x * y
predict_results <- function(home, away, param_list) {
  e_goals_home <- exp(param_list$alpha[home] - param_list$beta[away] + param_list$gamma)
  e_goals_away <- exp(param_list$alpha[away] - param_list$beta[home])
  
  df <- data.frame(home = home, away = away,
                   e_hgoal = e_goals_home, e_agoal = e_goals_away)
  
  return(df)
}

# initialise parameters as all 0
# log(1) = 0
equal_parameters <- list(
  alpha = rep(0, length(teams)) %>% `names<-`(teams),
  beta = rep(0, length(teams)) %>% `names<-`(teams),
  gamma = 0
)

# re run using new subfunction
optimised_parameters3 <- optim(
  par = unlist(equal_parameters), 
  fn = optimise_params,
  results = results,
  # using log will avoid non-finite differences 
  # so can use BFGS model
  method = "BFGS",
  control = list(maxit = 10000))

```

```{r constrained_parameters, warning=FALSE,message=FALSE}
# introduce sum to zero constraint by calculating
# first teams parameters as minus sum of the rest
relist_params <- function(parameters) {
  parameter_list <- list(
    alpha = parameters %>%
      .[grepl("alpha", names(.))] %>%
      append(prod(sum(.), -1), .) %>%
      `names<-`(teams),
    beta = parameters %>%
      .[grepl("beta", names(.))] %>%
      append(prod(sum(.), -1), .) %>%
      `names<-`(teams),
    gamma = parameters["gamma"]
  )
  
  return(parameter_list)
}

# remove the first team from the attack and defence ratings
equal_parameters <- list(
  alpha = rep(0, length(teams)-1) %>% `names<-`(teams[2:length(teams)]),
  beta = rep(0, length(teams)-1) %>% `names<-`(teams[2:length(teams)]),
  gamma = 0
)

optimised_parameters4 <- optim(
  par = unlist(equal_parameters), 
  fn = optimise_params,
  results = results,
  method = "BFGS",
  control = list(maxit = 10000))

```

```{r, warning=FALSE,message=FALSE}
# add in intercept term
relist_params <- function(parameters) {
  parameter_list <- list(
    alpha = parameters %>%
      .[grepl("alpha", names(.))] %>%
      append(prod(sum(.), -1), .) %>%
      `names<-`(teams),
    beta = parameters %>%
      .[grepl("beta", names(.))] %>%
      append(prod(sum(.), -1), .) %>%
      `names<-`(teams),
    gamma = parameters["gamma"],
    phi = parameters["phi"]
  )
  return(parameter_list)
}

# predict results with intercept added to exp argument
predict_results <- function(home, away, param_list) {
  e_goals_home <- exp(param_list$phi + param_list$alpha[home] - param_list$beta[away] + param_list$gamma)
  e_goals_away <- exp(param_list$phi + param_list$alpha[away] - param_list$beta[home])
  
  df <- data.frame(home = home, away = away,
                   e_hgoal = e_goals_home, e_agoal = e_goals_away)
  
  return(df)
}

# add intercept to the initial parameters
equal_parameters$phi = 0

# initialise i to collect data about theoptimisation process at each iteration
i <- 0
# collect current parameter values and neg log likelihood at each iteration
current_parameters <- list()
current_nll <- list()

optimised_parameters5 <- optim(
  par = unlist(equal_parameters), 
  fn = optimise_params,
  results = results,
  method = "BFGS",
  control = list(maxit = 10000))

```


We can plot the log likelihood at each iteration (notice how it starts at 112- the same value for our initial calculation)

```{r plot_log_liks, warning=FALSE,message=FALSE}
p3 <- data.frame(likelihood = unlist(current_nll),
                iteration = seq(length(current_nll))) %>%
  ggplot(aes(x = iteration, y = likelihood)) +
  geom_line() +
  scale_y_continuous(limits = c(0, 250)) +
  labs(title = "Negative log likelihood of parameters over iterations",
       y = "negative log likelihood",
       x = "iteration") +
  theme_minimal()

p3

```

which gives us parameters of

```{r plot_parameters, warning=FALSE,message=FALSE}
p4 <- optimised_parameters5$par %>%
  # relist to add in first team
  relist_params() %>%
  unlist() %>%
  # select team parameters
  .[grepl("beta|alpha", names(.))] %>%
  data.frame(value = .,
             parameter = names(.)) %>%
  separate(parameter, into = c("parameter", "team"), "\\.") %>%
  # spread into wide format
  spread(parameter, value) %>%
  # pipe into a plot
  ggplot(aes(x = alpha, y = beta)) +
  geom_point() +
  ggrepel::geom_text_repel(aes(label = team)) +
  stat_smooth(method = "lm", se = FALSE) +
  labs(title = "Optimal parameters for teams",
       subtitle = "given first 8 weeks of results",
       x = "alpha (more likely to score ->)",
       y = "beta (less likely to concede ->)") +
  theme_minimal()

p4
```


```{r predict_results2, warning=FALSE,message=FALSE}
predicted_results <- predict_results(unplayed_games$home,
                      unplayed_games$away, 
                      relist_params(optimised_parameters5$par)) %>%
  mutate_if(is.numeric, round, 2)

```

```{r plot_all_games, warning=FALSE,message=FALSE}
p5 <- rbind(
  predicted_results %>%
    rename_if(is.numeric, gsub, pattern = "e_", replacement = "") %>%
    mutate(type = "predicted"),
  results %>%
    select(-gameweek) %>%
    mutate(type = "result")
) %>%
  ggplot(., aes(x = away, y = home, fill = hgoal-agoal)) +
  geom_tile() +
  # add the scorelines
  geom_label(aes(label = paste(hgoal, agoal, sep = "-"), colour = type), fill = "white") +
  # colour where black for actual results and red for predictions
  scale_colour_manual(values = c("red", "black")) +
  # colour where green shows home win and red an away win
  scale_fill_gradient2(low = "darkred", high = "green", midpoint = 0, guide = FALSE) +
  scale_x_discrete(limits = levels(results$home), position = "top") +
  scale_y_discrete(limits = rev(levels(results$away))) +
  theme_minimal()

p5
```

