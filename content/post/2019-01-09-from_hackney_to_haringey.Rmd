---
title: 
author: Robert Hickman
date: '2020-01-09'
slug: from_hackney_to_haringey
output: pdf_document
categories: []
tags:
  - maps
  - politics
header:
  caption: ''
  image: ''
---


_[note: this post was just a few sickday afternoons work on an idea I had from Twitter and is not in any way a serious political analysis. Really it's just a first past at trying to solve a very specific question, which I think it does to a greater or lesser extent. It's also full of the [Ecological Fallacy](https://en.wikipedia.org/wiki/Ecological_fallacy) so just bear all that in mind throughout]_

A perculiar way in which the UK's constituency-based electoral system shapes media coverage is that the names of certain towns/districts have an outsized effect. For instance, in the 2019 UK general election, much was made of [Workington](https://www.newstatesman.com/politics/uk/2019/10/which-voters-who-swing-election-2019-workington-man) [Man](https://www.dailymail.co.uk/news/article-7640915/Workington-Man-backing-Boris-Johnson-Survey-finds-Tories-course-win-key-Labour-seat.html)* in Cumbria- a seat that had fairly consistently returned Labour MPs in the modern era.

One particular media trend made possible by the variety of names for UK seats is to alliterate between constituencies that are seen as showing a range of geography/opinion/etc. This is best summed up in a great exchange between the absolute boy, and Health Secretary, Matt Hancock, and Kay Burley:

<blockquote class="twitter-tweet" data-lang="en-gb"><p lang="en" dir="ltr">On Sky, Matt Hanock says new cancer treatments are being rolled out &quot;from Barnsley to Bassetlaw; from Wigan to Warrington.&quot;<br><br>Kay Burley: &quot;That&#39;s not very far, you know.&quot;<br><br>Hancock: &quot;It&#39;s also happening in Cornwall.&quot;</p>&mdash; Peter Walker (@peterwalker99) <a href="https://twitter.com/peterwalker99/status/1189443331237003265?ref_src=twsrc%5Etfw">30 October 2019</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

Given that I had an afternoon off sick from work, and enjoy wasting my time on such things, I wanted to see what the best constituencies to use for 'From Xx to Xy' in British politics is. For this I'm going to use mostly data that is hosted on this website, however, where it isn't I've made it pretty clear in comments where it can be downlaoded.

*for a good take on this, see [here](https://www.theguardian.com/commentisfree/2019/nov/22/workington-man-voter-caricature-essex-man)

```{r load_data_secret, warning=FALSE,message=FALSE,echo=FALSE}
library(rgdal)

#some of these files are large so I store the locally
#I've provided links to where you can find them below
census_oa_data <- readRDS("C:/Users/rob-getty/Desktop/cleanup desktop/geo_data/census_data/census_data.rds")
constituency_shapefiles <- readOGR(dsn = "C:/Users/rob-getty/Desktop/cleanup desktop/geo_data/boundary/Data/GB", layer = "westminster_const_region")
```

## Geographic Distance
First, and easiest, let's start with geographic distances between constituencies. For this I use the Ordnance Survey [boundary line](https://www.ordnancesurvey.co.uk/business-government/products/boundaryline) dataset which gives shapefile of each constituency in the UK.

After some string regex to match names between datasets, I also removed all constituencies beginning with North/South/East/West (as 'From East Surry to East Hampshire' doesn't really have a ring to it) and also only took seats within England or Wales (more on why later). I also took out constituency names that were longer than two words, again for stylistic reasons.

We're then left with 350 (out of 650 total) seats which we can plot, filled by the first letter of their name.

```{r get_data, warning=FALSE,message=FALSE}
#load tidyverse for munging
library(tidyverse)

#this data can be found at https://www.ordnancesurvey.co.uk/business-government/products/boundaryline
#open as:
# constituency_shapefiles <- readOGR(dsn = "where/you/downloaded", 
#                                    layer = "westminster_const_region")
#using rgdal and sf for geospatial work
library(rgdal)
library(sf)

constituency_geography <- constituency_shapefiles %>%
  st_as_sf() %>%
  #some munging to line up datasets
  mutate(name = gsub(" Co Const| Burgh Const| Boro Const", "", NAME)) %>%
  mutate(name = case_when(
    grepl("London and Westminster", name) ~ "Cities of London and Westminster",
    grepl("-.*-", name) ~ gsub("(-)([a-z]{1})(.*-)", perl = TRUE, "\\1\\U\\2\\E\\3", name),
    grepl("St\\. ", name) ~ gsub("St\\. ", "St ", name),
    grepl(" of ", name) ~ gsub(" of ", " Of ", name),
    grepl("Newcastle upon ", name) ~ gsub(" upon ", " Upon ", name),
    TRUE ~ name
  )) %>%
  #get the first letter
  #removing compass directions
  filter(!grepl("North |East |South |West ", name) & !grepl(" .* ", name)) %>%
  mutate(first_letter = gsub("(.)(.*)", "\\1",  name)) %>%
  #only going to play with English constituencies here
  filter(grepl("^E|^W", CODE)) %>%
  #remove Chorley (speaker's seat)
  filter(!grepl("Chorley", name)) %>%
  #select and rename relevant columns
  select(WSTid = CODE, WSTnm = name, first_letter)

constituency_names <- constituency_geography %>%
  `st_geometry<-`(NULL)

#ggthemes for map theme
library(ggthemes)

#plot remaining constituencies coloured based on first letter
first_letter_plot <- ggplot() +
  geom_sf(data = constituency_geography, aes(fill = first_letter)) +
  scale_fill_discrete(guide = FALSE) +
  theme_map()

plot(first_letter_plot)
```

To calculate the distance between any two constituencies, I use the center location of each, calculated using sf::st_centroid(). Grouping by first letter then creating a matrix from each to each is simple enough using sf::st_distance() as follows:

```{r geographic_center_distance, warning=FALSE,message=FALSE}
#get the coordinates of the center of each constituency
geographic_centers <- constituency_geography %>%
  st_centroid() %>%
  split(f = .$first_letter)

#function to find distances between center points
get_distances <- function(letter_list) {
  constituencies <- letter_list$WSTnm
  first_letter <- unique(letter_list$first_letter)
  
  #get distance to/from every center point with same first letter
  distance_matrix <- st_distance(letter_list, letter_list)
  
  distances_df <- distance_matrix %>%
    as.data.frame()
  names(distances_df) <- constituencies
  
  melted_df <- distances_df %>%
    pivot_longer(., names(.), names_to = "to", values_to = "distance") %>%
    mutate(from = rep(unique(to), each = length(unique(to)))) %>%
    mutate(first_letter = first_letter)
  
  return(melted_df)
}

#run the function to get the distances between constituencies with same
#first letter
constituency_interdistances <- map_df(geographic_centers, get_distances)
```

We can then find the longest distance (in metres) between the centre of constituencies, grouped by the first letter of their name using some simple muning:

```{r show_longest_distances, warning=FALSE,message=FALSE}
#find the longest distances 
longest_distances <- constituency_interdistances %>%
  #arrange by longest first
  arrange(-distance) %>%
  #take the longest per first letter
  filter(!duplicated(first_letter)) %>%
  filter(distance != 0)

#show the ongest 10 interdistances
head(longest_distances %>% arrange(-distance))
```

Perhaps not surprisingly, St Ives (in the far South West on England) to Sunderland Central (in the far North East) is the furthest distance (601km). We can see though that there's a fair few first letter for which we have a pair of constituencies that are pretty far away from each other.

To plot the longest distance between a pair of constituencies that alliterate is simple enough. I also load a shapefile of the outline of England and Wales to pretty up the plots and create lines between each constituency. Where constituencies are too small to be plotted on this scale, I use a red dot.

```{r plot_interdistances, warning=FALSE,message=FALSE,, fig.width=14, fig.height=12}
#shapefile of England and Wales for plotting
eng_wal <- "../../static/files/constituency_distances/england_wales_shape.rds" %>%
  readRDS()

#filter the longest journey per letter
selected_constituencies <- constituency_geography %>%
  filter(WSTnm %in% pivot_longer(longest_distances, cols = c("to", "from"))$value) %>%
  left_join(., 
            longest_distances %>% 
              mutate(journey = paste(to, from, sep = " to\n")) %>% 
              select(first_letter, journey),
            by = "first_letter")

#get the center coordinates of constituencies
#to help plotting small constituencies
plotting_points <- do.call(rbind, geographic_centers) %>%
  filter(WSTnm %in% selected_constituencies$WSTnm) %>%
  left_join(., 
            longest_distances %>% 
              mutate(journey = paste(to, from, sep = " to\n")) %>% 
              select(first_letter, journey),
            by = "first_letter") %>%
  st_transform(crs = st_crs(eng_wal))

#calculate straight lines between two constituencies
plotting_lines <- plotting_points %>%
  split(f = .$journey) %>%
  map_df(., function(data) {
    coords <- rbind(st_coordinates(data[1,]), st_coordinates(data[2,]))
    line <- st_linestring(coords)
    df <- st_sfc(line, crs = st_crs("+init=epsg:27700")) %>%
      as.data.frame() %>%
      mutate(journey = unique(data$journey))
  }) %>%
  st_as_sf(crs = st_crs(plotting_points))

#plot the longest journey between constituencies with the same first letter
alliterative_journeys_plot <-  ggplot() +
  geom_sf(data = eng_wal, fill = "white") +
  geom_sf(data = plotting_lines, colour = "darkblue") +
  #some constituencies are too small to plot as shapefiles
  geom_sf(data = plotting_points, colour = "red", size = 2.5) +
  geom_sf(data = selected_constituencies, fill = "red") +
  theme_map() +
  #split by first letter
  facet_wrap(~journey)

plot(alliterative_journeys_plot)
```

## Brexit Difference

We can also find the alliterative constituencies that vary across the forever cultural war over Brexit. To do this, I use [Chris Hanretty's estimates of brexit vote share](https://medium.com/@chrishanretty/final-estimates-of-the-leave-vote-or-areal-interpolation-and-the-uks-referendum-on-eu-membership-5490b6cab878) by constituency, that I've tacked onto a csv of the 2019 General Election results. (You can find the data in the source for this website).

```{r load_vote_data, warning=FALSE,message=FALSE}
#load data on voting in the 2019 general election
#2016 brexit vote based on Hanretty work also included
votes_data <- readRDS("../../static/files/constituency_distances/ge2019_results.rds") %>%
  select(WSTnm = constituency_name, winner = first_party, votes = electorate, 
         con, lab, ld, brexit, green, other, brexit_hanretty) %>%
  #convert to vote fractions
  #for later
  modify_at(c("con", "lab", "ld", "brexit", "green", "other"), function(x) x/.$votes) %>%
  #take only relevant constituencies
  filter(WSTnm %in% constituency_geography$WSTnm)

head(votes_data)
```

Finding the biggest difference is then a simple question of subtraction of the brexit vote (in this case the % voting for leave) between two constituencies sharing the first name which is easy to calculate using the outer product of a vector.

```{r get_brexit_differences, warning=FALSE,message=FALSE}
#find the largest gap in 2016 brexit vote between constituencies
#which same first letter
brexit_differences <- votes_data %>%
  left_join(., constituency_names, by = "WSTnm") %>%
  split(f = .$first_letter) %>%
  map_df(., function(data) {
    difference <- outer(data$brexit_hanretty, data$brexit_hanretty, "-") %>%
      as.data.frame() %>%
      mutate(from = data$WSTnm)
    names(difference)[1:(ncol(difference) - 1)] <- data$WSTnm
    df <- difference %>%
      pivot_longer(cols = -starts_with("from"),
                   names_to = "to",
                   values_to = "brexit_2016_difference") %>%
      mutate(first_letter = unique(data$first_letter))
  }) %>%
  filter(to != from) %>%
  #arrange by greatest difference
  arrange(-brexit_2016_difference)

head(brexit_differences, n = 10)
```

It's tempting to think that Britain follows a nice geographic divide. That there's a 'metropolitan elite' remain-voting south, and a leave-voting north even though it should be pretty obvious that this is a [massive oversimplification](https://upload.wikimedia.org/wikipedia/commons/d/d5/United_Kingdom_EU_referendum_2016_area_results.svg).

We can do a very quick unscientific test of this by plotting the geographic distances against the difference in brexit vote share for all constituencies*. It's fairly clear there's no real correlation, sometimes constituencies are far away from each other but quite similar. Sometimes, they are very close but have wildly different economies. For instance, I grew up in North London which is [sometimes thought of](https://www.msn.com/en-gb/news/other/this-daughter-of-immigrants-needs-no-lectures-from-the-north-london-metropolitan-liberal-elite-home-secretary-priti-patel-vows-to-end-freedom-of-movement-once-and-for-all-after-brexit/ar-AAI7Bnq) as some haven of metropolitan elitism, but also has [some of the worst deprivation in the whole UK](https://www.citymetric.com/sites/default/files/styles/nodeimage/public/article_2019/03/inequality_maps_head.png?itok=K1dTNrEm).

*not actually all constituencies, just between ones with the same first letter because see the post header. I've overlaid the biggest Brexit vote differences between alliterative constituencies labelled in purple.

```{r plot_brexit_differences, warning=FALSE,message=FALSE}
library(ggrepel)

#plot the distances between constituencies of same first letter with
#greatest difference in 2016 brexit vote
brexit_geo_differences <- brexit_differences %>%
  #filter(!duplicated(first_letter)) %>%
  left_join(constituency_interdistances, by = c("to", "from")) %>%
  mutate(journey = case_when(
    !duplicated(first_letter.x) ~ paste(to, from, sep = "-\n"))) %>%
  select(journey, first_letter.x, brexit_2016_difference, distance)

brexit_difference_plot <- brexit_geo_differences %>%
  ggplot(aes(x = distance/1000, 
             y = abs(brexit_2016_difference),
             label = journey)) +
  geom_point(alpha = 0.1) +
  #highlight biggest alliterative difference in brexit vote
  geom_point(data = filter(brexit_geo_differences, !is.na(journey)), 
             colour = "purple", size = 3) +
  geom_text(size = 2.5, colour = "#702963") +
  labs(x = "geographic distance /km",
       y = "difference in 2016 Brexit vote share") +
  theme_minimal()

brexit_difference_plot
```

## Census Data

Having established the extremely obvious point that different constituencies can be quite different from each other, I thought I'd also have a go at looking at how constituencies vary. For this we're going to want to start delving into actual large data, using the results per constituency from the 2011 Census.

Firstly, census data is released at [a variety of levels](https://www.ons.gov.uk/methodology/geography/ukgeographies/censusgeography), none of which are constituency level, so we're going to have to calculate this ourselves. Again, I use a very basic way to do this and your mileage may vary on more sophisticated techniques. At the end, we have the proportion of each constituency that falls into each measured census variable (of which there are ~400).

```{r load_census_data, warning=FALSE,message=FALSE}
#load the raw values from the census data for each output area
census_oa_data <- census_oa_data %>%
  #select only integer data (counts not percentages)
  select(OAid = GeographyCode, which(sapply(.,class)=="integer"))

#load the lookup between output areas to westminster constituency
oa_to_westminster <- readRDS("../../static/files/constituency_distances/oa_to_westminster.rds") %>%
  select(OAid = OA11CD, WSTid = PCON11CD, WSTnm = PCON11NM, WSTperc = OA11PERCENT) %>%
  #select only english constituencies
  filter(WSTid %in% constituency_names$WSTid)

#gather the census data by westminster constituency
census_data_westminster <- left_join(census_oa_data, oa_to_westminster, by = "OAid") %>%
  filter(!is.na(WSTid)) %>%
  #for output areas split between constituencies guesstimate the correct amounts
  mutate_if(is.integer, funs(round(. * (WSTperc/100)))) %>%
  select(-WSTnm, -WSTperc, -OAid) %>%
  #sum the counts per constituency for each statistic
  group_by(WSTid) %>%
  summarise_if(is.numeric, sum, na.rm = TRUE) %>%
  #turn into percentages from the total number of people (KS101)
  modify_if(is.numeric, function(x) x/.$KS101EW0001) %>%
  #arrange by name
  arrange(WSTid)

#only preview the first few columns as we have ~400 total
head(census_data_westminster[1:8])

```

The census codes don't really tell us anything about what we're measuring, fortunately there's an index we can load to check:

```{r load_census_index, warning=FALSE,message=FALSE}
#load the terminology for each census statistic
census_index <- readRDS("../../static/files/constituency_distances/census_names.rds")

head(select(census_index, Code, Meaning))
```

WEe're only going to take census variables which appear in this index (all but about 5), and also remove any variables that are all equal to 1 or 0 (otherwise we'll be screwed later on).

```{r take_relevant_census_data, warning=FALSE,message=FALSE}
census_data_westminster <- census_data_westminster %>%
  #a few codes missing from the index
  .[-which(!names(.)[2:ncol(.)] %in% census_index$Code)] %>%
  .[c(1, which(!apply(.[2:ncol(.)],2,function(x) var(x,na.rm=T)==0))+1)]
```


```{r get_correlations_func, warning=FALSE,message=FALSE}
get_correlations_tidy <- function(demography, dependent_var) {
  #first split up the demography data by variable so we can independently
  #correlate each against the dependent variable
  split_demog <- demography %>%
    column_to_rownames("WSTid") %>%
    t() %>%
    split(f = rownames(.))
  
  #run the values for each variables against the dependent_var
  correlations <- map_df(split_demog, function(x) {
    regression <- lm(dependent_var ~ x)
    adj_r_squared <- summary(regression)$adj.r.squared
    f_stat <- summary(regression)$fstatistic[1]
    df <- summary(regression) %>%
      #tidy it to bind to df
      broom::tidy() %>%
      filter(term != "(Intercept)") %>%
      mutate(adj_r = adj_r_squared, f_stat)
  })
  
  tidy_df <- correlations %>%
    #left join in the meaning for each variable
    mutate(Code = names(demography[2:ncol(demography)])) %>%
    left_join(., select(census_index, Code, Meaning), by = "Code") %>%
    arrange(-abs(statistic)) %>%
    select(-term)
  
  #return this data frame
  return(tidy_df)
}
```

```{r get_lr_correlations, warning=FALSE,message=FALSE}
lr_margin <- votes_data %>%
  left_join(constituency_names, by = "WSTnm") %>%
  #must line up in order with census data
  arrange(WSTid) %>%
  #assuming a simple left vs right decision for voters
  mutate(left = lab + ld + green,
         right = con + brexit) %>%
  #take the difference between left and right sum votes for each constituency
  mutate(margin = left - right) %>%
  .$margin

#run in the above function
lr_correlations <- get_correlations_tidy(census_data_westminster, lr_margin)

head(select(lr_correlations, Code, Meaning, statistic, p.value))
```

```{r get_lr_variables, warning=FALSE,message=FALSE}
lr_correlations <- lr_correlations %>%
  #lots of these stats are self-correlated
  #e.g. 3 cars in household vs 4+ cars in household
  mutate(stat_category = gsub("(.{5})(.*)", "\\1", Code)) %>%
  group_by(stat_category) %>%
  #take only the strongest correlated variable from each 'category'
  mutate(duplicate_n = 1:n()) %>%
  ungroup() %>%
  filter(duplicate_n == 1 & abs(statistic) > 10 & !duplicated(Meaning))

right_variables <- lr_correlations %>%
  mutate(census_info = paste(Code, Meaning)) %>%
  filter(statistic < 0) %>%
  .$census_info

left_variables <- lr_correlations %>%
  mutate(census_info = paste(Code, Meaning)) %>%
  filter(statistic > 0) %>%
  .$census_info

right_variables

left_variables

```

```{r}
brexit_vote <- votes_data %>%
  left_join(constituency_names, by = "WSTnm") %>%
  #must line up in order with census data
  arrange(WSTid) %>%
  .$brexit_hanretty

brexit_correlations <- get_correlations_tidy(census_data_westminster, brexit_vote) %>%
  #lots of these stats are self-correlated
  #e.g. 3 cars in household vs 4+ cars in household
  mutate(stat_category = gsub("(.{5})(.*)", "\\1", Code)) %>%
  group_by(stat_category) %>%
  #take only the strongest correlated variable from each 'category'
  mutate(duplicate_n = 1:n()) %>%
  ungroup() %>%
  filter(duplicate_n == 1 & abs(statistic) > 10 & !duplicated(Meaning))

head(brexit_correlations) 
```

```{r}
lr_correlations$Meaning[which(lr_correlations$Code %in% brexit_correlations$Code)]
```

```{r do_census_pca, warning=FALSE,message=FALSE}
pca_census <- census_data_westminster %>%
  #take only the variable that strongly correlate with 2019/brexit vote
  select(unique(c(lr_correlations$Code, brexit_correlations$Code))) %>%
  #scale before pca
  scale()

#run the pca
#take first 3 components
demographic_pca <- prcomp(pca_census)$x %>%
  as.data.frame() %>%
  .[1:3] %>%
  #add back in ID column
  mutate(WSTid = census_data_westminster$WSTid) %>%
  #join in additional dta for plotting
  left_join(., constituency_names, by = "WSTid") %>%
  left_join(., select(votes_data, WSTnm, winner), by = "WSTnm")

#plot
demographic_pca_plot <- demographic_pca %>%
  ggplot(aes(x = PC1, y = PC2, label = gsub("a|e|i|o|u", "", WSTnm), colour = winner)) +
  geom_point() +
  geom_text() +
  scale_colour_manual(values = c("mediumblue", "green", "red", "goldenrod", "darkgreen")) +
  labs(x = "PC1 - Urban, Young & Diverse ->",
       y = "PC2 - Economically 'Left Behind' ->") +
  facet_wrap(~first_letter)

demographic_pca_plot
```

```{r get_census_distances, warning=FALSE,message=FALSE}
distances <- demographic_pca %>%
  split(f = .$first_letter) %>%
  map_df(., function(data) {
    distances <- (outer(data$PC1, data$PC1, "-")^2 + outer(data$PC2, data$PC2, "-")^2) %>%
    sqrt() %>%
    as.data.frame() %>%
    mutate(from = data$WSTnm)
    names(distances)[1:(ncol(distances)-1)] <- as.character(data$WSTnm)
    df <- pivot_longer(distances, -starts_with("from"),
                       names_to = "to",
                       values_to = "pca_distance") %>%
      mutate(pca_distance = abs(pca_distance))
    return(df)
  }) %>%
  filter(!duplicated(pca_distance) & pca_distance != 0)
```

```{r}
all_distances <- distances %>%
  left_join(brexit_differences, by = c("from", "to")) %>%
  mutate(brexit_2016_difference = abs(brexit_2016_difference)) %>%
  select(-first_letter) %>%
  left_join(constituency_interdistances, by = c("from", "to")) %>%
  mutate(label = case_when(
    distance > 400000 & pca_distance > 15 & brexit_2016_difference > 0.3 ~ paste(to, from, sep = "-")
  )) %>%
  mutate(distance = distance / 1000)

p <- ggplot(all_distances, aes(x = distance, y = pca_distance, size = brexit_2016_difference)) +
  geom_point(alpha = 0.2) +
  geom_point(data = filter(all_distances, !is.na(label))) +
  geom_text_repel(aes(label = label)) +
  scale_size_continuous(name = "diff Brexit\n 2016 vote", range = c(0.5, 5)) +
  labs(x = "Geographic Distances between Constituences (/km",
       y = "'Distance' between Constituencies Demograph (2011 Census)") +
  theme_minimal()

plot(p)
```

