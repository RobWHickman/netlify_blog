<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Robert Hickman on Robert Hickman</title>
    <link>/</link>
    <description>Recent content in Robert Hickman on Robert Hickman</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Fri, 05 Jan 2018 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Five Minute Football Trivia - Trans-Europe Express</title>
      <link>/post/five_min_trivia_kraftwerk/</link>
      <pubDate>Thu, 02 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/five_min_trivia_kraftwerk/</guid>
      <description>


&lt;p&gt;&lt;em&gt;generally as I have less and less time to waste on meaningless football stats I get halfway through a post and abandon it. To remedy this, I want to start pushing out posts that give a reasonable half-guess at an answer within an hour or so without needing to really check my working or write good prose. This is the third of these&lt;/em&gt;&lt;/p&gt;
For this weeks question, I’m stealing straight from the source of most of my posts, &lt;a href=&#34;https://www.theguardian.com/football/series/theknowledge&#34;&gt;The Knowledge column&lt;/a&gt; at The Guardian:
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
What is the shortest total distance a club has had to travel in a Champions League winning campaign? (Perhaps average distance per (away) fixture to balance out changes in format over the years.)
&lt;/p&gt;
— JBfaeDundee (&lt;span class=&#34;citation&#34;&gt;@JBfaeDundee&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/JBfaeDundee/status/1242529510735720448?ref_src=twsrc%5Etfw&#34;&gt;March 24, 2020&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
I’m going to turn it on it’s head a bit, and find the longest distance campaigns, mostly because I find it more interesting, but also because it reminded me of this tweet from a few years ago
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
The longest away trip in the world took place today as Baltika Kaliningrad travelled about 10,000 km to meet Luch Vladivostok in the second division in Russia. &lt;br&gt;The gamed ended 0-0, of course. &lt;a href=&#34;https://t.co/EsSpmWzddk&#34;&gt;pic.twitter.com/EsSpmWzddk&lt;/a&gt;
&lt;/p&gt;
— Michael Yokhin (&lt;span class=&#34;citation&#34;&gt;@Yokhin&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/Yokhin/status/980050993810493440?ref_src=twsrc%5Etfw&#34;&gt;March 31, 2018&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;And generally I love weird quirks of geography that lead to commutes of 13 hours like this.&lt;/p&gt;
&lt;p&gt;As always, first load the libraries we need. Having looked around, the most organised dataset seemed to be at &lt;a href=&#34;https://www.worldfootball.net&#34;&gt;worldfootball.net&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#scrape
library(rvest)
#using data from worldfootbal.net
base_url &amp;lt;- &amp;quot;https://www.worldfootball.net&amp;quot;

#tidy
library(tidyverse)
library(magrittr)
#map
library(sf)
library(rnaturalearth)
library(ggthemes)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To find the location of every team, we need a data.frame of every team to have competed in the Champions League (and Qualifying) since it’s inception. We can get that by sprintf’ing a list of urls and scraping the links to each team page from there. For this, and most of the scraping jobs below, I saved the data from the first time I scrape so that I don’t have to continually re-stress the worldfootball server. The datasets can be found in the static folder of my website GitHub.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#the years each competition took place
years &amp;lt;- 1955:2018
qual_years &amp;lt;- c(1966, 1969:1971, 1978:1982, 1992:2018)

#sprintf the correct urls together
all_urls &amp;lt;- c(sprintf(&amp;quot;/champions-league-%d-%d&amp;quot;, years, years+1),
      sprintf(&amp;quot;/champions-league-qualifikation-%d-%d&amp;quot;, qual_years, qual_years+1))

#some exceptions
all_urls[grepl(&amp;quot;champions-league-2010-2011&amp;quot;, all_urls)] %&amp;lt;&amp;gt;% paste0(., &amp;quot;_3&amp;quot;)
all_urls[grepl(&amp;quot;champions-league-2008-2009&amp;quot;, all_urls)] %&amp;lt;&amp;gt;% paste0(., &amp;quot;_2&amp;quot;)
all_urls[grepl(&amp;quot;qualifikation-2008-2009&amp;quot;, all_urls)] %&amp;lt;&amp;gt;% gsub(&amp;quot;qualifikation&amp;quot;, &amp;quot;qf&amp;quot;, .)
all_urls[grepl(&amp;quot;qualifikation&amp;quot;, all_urls) &amp;amp; as.numeric(gsub(&amp;quot;.*-&amp;quot;,&amp;quot;&amp;quot;,all_urls)&amp;gt;2009)]  %&amp;lt;&amp;gt;%
  gsub(&amp;quot;qualifikation&amp;quot;, &amp;quot;qual&amp;quot;, .)

#scrape the list of each team&amp;#39;s links
teams &amp;lt;- map_df(all_urls, function(competition_link) {
  #read once and scrape from there
  read &amp;lt;- read_html(paste0(base_url, &amp;quot;/players&amp;quot;, competition_link))
  #get the useful info
  competition &amp;lt;- read %&amp;gt;% html_nodes(&amp;quot;h1&amp;quot;) %&amp;gt;% html_text() %&amp;gt;% gsub(&amp;quot; » .*&amp;quot;, &amp;quot;&amp;quot;, .)
  team_name &amp;lt;- read %&amp;gt;% html_nodes(&amp;quot;td:nth-child(2) a&amp;quot;) %&amp;gt;% html_text()
  team_info &amp;lt;- read %&amp;gt;% html_nodes(&amp;quot;td:nth-child(4) a&amp;quot;) %&amp;gt;% html_attr(&amp;quot;href&amp;quot;)
  #compile into a df to return
  df &amp;lt;- data.frame(competition, team_name, team_info)
  return(df)
})&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;we can then take a look at what we have on our hands&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(teams)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                  competition              team_name
## 1 Champions League 1955/1956      1. FC Saarbrücken
## 2 Champions League 1955/1956              Aarhus GF
## 3 Champions League 1955/1956               AC Milan
## 4 Champions League 1955/1956 Budapesti Vörös Lobogó
## 5 Champions League 1955/1956         Djurgårdens IF
## 6 Champions League 1955/1956       Gwardia Warszawa
##                     team_info
## 1 /teams/1-fc-saarbruecken/1/
## 2         /teams/aarhus-gf/1/
## 3          /teams/ac-milan/1/
## 4      /teams/mtk-budapest/1/
## 5    /teams/djurgardens-if/1/
## 6  /teams/gwardia-warszawa/1/&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As a short aside, one of the things I really enjoy about posts like this one is it exposes you to lots of history from the ‘early’ days of organised football and the teams (some of which remain, some do not) that were present then.&lt;/p&gt;
&lt;p&gt;After this, we then want to scrape the data on every match played in the Champions League in a similar manner:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;match_data &amp;lt;- map_df(all_urls, function(competition_link) {
  #read once
  read &amp;lt;- read_html(paste0(base_url, &amp;quot;/all_matches&amp;quot;, competition_link))
  #get the competition/season id from the url
  season &amp;lt;- gsub(&amp;quot;(^.*-)([0-9]{4}-[0-9]{4})(.*)&amp;quot;, &amp;quot;\\2&amp;quot;, competition_link)
  competition &amp;lt;- ifelse(grepl(&amp;quot;-qual|-qf&amp;quot;, competition_link), &amp;quot;ucl-quals&amp;quot;, &amp;quot;ucl&amp;quot;)
  
  #scrape the links to each match- we&amp;#39;ll need some of these later
  match_link &amp;lt;- read %&amp;gt;%
    html_nodes(&amp;quot;td:nth-child(6) a&amp;quot;) %&amp;gt;%
    html_attr(&amp;quot;href&amp;quot;)
  
  #save the champions league matches into a df
  matches_df &amp;lt;- read %&amp;gt;% 
    html_nodes(&amp;quot;#site &amp;gt; div.white &amp;gt; div.content &amp;gt; div &amp;gt; div.box &amp;gt; div &amp;gt; table&amp;quot;) %&amp;gt;% 
    html_table(fill = TRUE, header = FALSE) %&amp;gt;%
    as.data.frame() %&amp;gt;%
    #rename
    select(date = X1, round = X4, home = X3, away = X5, result = X6) %&amp;gt;%
    #mutate the correct round to matches
    mutate(round = case_when(
      round != &amp;quot;-&amp;quot; ~ round
    )) %&amp;gt;%
    mutate(date = case_when(
      date != &amp;quot;&amp;quot; ~ date
    )) %&amp;gt;%
    mutate(round = zoo::na.locf(round)) %&amp;gt;%
    #filter out valid matches
    filter(grepl(&amp;quot;^[0-9]*:[0-9]*|abor.&amp;quot;, result)) %&amp;gt;%
    mutate(date = zoo::na.locf(date)) %&amp;gt;%
    #few exceptions of matches that wern&amp;#39;t played
    filter(!(grepl(&amp;quot;dec.&amp;quot;, result) &amp;amp; date == &amp;quot;01/12/1965&amp;quot;)) %&amp;gt;%
    filter(!(home == &amp;quot;FK Partizani&amp;quot; &amp;amp; date == &amp;quot;30/09/1987&amp;quot;)) %&amp;gt;%
    mutate(match_link, season, competition)
  return(matches_df)
})&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Which we can glimpse to see that there are 7206 matches listed across the competition proper and qualification rounds since the 1950s. This resolves down to 2875 unique team-seasons (from ~561 unique teams) who have been involved in either competition.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(match_data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         date    round                   home             away    result
## 1 04/09/1955 1. Round            Sporting CP         Partizan 3:3 (1:1)
## 2 07/09/1955 1. Round Budapesti Vörös Lobogó   RSC Anderlecht 6:3 (3:2)
## 3 08/09/1955 1. Round        Servette Genève      Real Madrid 0:2 (0:0)
## 4 14/09/1955 1. Round        Rot-Weiss Essen     Hibernian FC 0:4 (0:2)
## 5 20/09/1955 1. Round         Djurgårdens IF Gwardia Warszawa 0:0 (0:0)
## 6 21/09/1955 1. Round              Aarhus GF      Stade Reims 0:2 (0:1)
##                                                                    match_link
## 1            /report/champions-league-1955-1956-1-runde-sporting-cp-partizan/
## 2     /report/champions-league-1955-1956-1-runde-mtk-budapest-rsc-anderlecht/
## 3     /report/champions-league-1955-1956-1-runde-servette-geneve-real-madrid/
## 4    /report/champions-league-1955-1956-1-runde-rot-weiss-essen-hibernian-fc/
## 5 /report/champions-league-1955-1956-1-runde-djurgardens-if-gwardia-warszawa/
## 6           /report/champions-league-1955-1956-1-runde-aarhus-gf-stade-reims/
##      season competition
## 1 1955-1956         ucl
## 2 1955-1956         ucl
## 3 1955-1956         ucl
## 4 1955-1956         ucl
## 5 1955-1956         ucl
## 6 1955-1956         ucl&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To work out the distances travelled, we then need to find the locations of each of these matches. The easiest way would be to run through each of those match links and scrape the location data, but that would put a lot of load on the worldfootball servers, so we can be smarter than that.&lt;/p&gt;
&lt;p&gt;Matches generally take place at the home location (or in some exceptions, very close to) of every team (e.g. Arsenal’s home matches take place in North London). However, in the history of the competition, 2-legged matches that ended as a draw used to go to a third leg at a neutral location (for example &lt;a href=&#34;https://www.worldfootball.net/report/champions-league-1992-1993-1-runde-vfb-stuttgart-leeds-united_2/&#34;&gt;Leeds United vs. VFB Stuttgart in 1992 took place at the Nou Camp&lt;/a&gt;). Also, each final is played at a pre-selected venue that is independent of the eventual finalists.&lt;/p&gt;
&lt;p&gt;We can find the data for these matches and scrape the exact location from the match link, while taking the rest from the location of the home team in the tie.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#split data by neutral venue or not
match_locations &amp;lt;- match_data %&amp;gt;%
  split(f = (.$round == &amp;quot;Final&amp;quot; | 
               duplicated(paste(.$home, .$away, .$round, .$season))))

#function for scraping the location of the neutral matches
#uses a link to a specific match
get_neutral_location &amp;lt;- function(link) {
  full_url &amp;lt;- paste0(base_url, link)
  
  #get and munge the location
  node &amp;lt;- &amp;quot;.standard_tabelle tr:nth-child(1) .dunkel~ .dunkel+ .dunkel&amp;quot;
  read &amp;lt;- read_html(full_url)
  location &amp;lt;- read %&amp;gt;% html_nodes(node) %&amp;gt;% html_text() %&amp;gt;%
    gsub(&amp;quot;\\(|\\)|\\/&amp;quot;, &amp;quot;&amp;quot;, .)
  return(location)
}

#run through this function to locate all neutral matches
neutral_matches &amp;lt;- match_locations[[2]] %&amp;gt;%
  mutate(location = unlist(lapply(match_link, get_neutral_location))) %&amp;gt;%
  mutate(type = &amp;quot;neutral&amp;quot;) %&amp;gt;%
  select(-match_link)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can see we’ve gathered a few extra matches that wern’t actually neutral, but given we get their correct location anyway, it’s not big deal.&lt;/p&gt;
&lt;p&gt;We then have to use the information on each team to get the location of thier home ground. For larger teams we can get this to within an exct postcode if we so wish, but many (e.g. &lt;a href=&#34;https://www.worldfootball.net/teams/szombierki-bytom/1/&#34;&gt;former Polish champions Szombierki Bytom&lt;/a&gt;) all we can get from their page is the country. This is fine because we’ll combine this with the team name to use a google search to get more exact locations later. (in any case it’s probably fine because the proportion of teams with poor geographic data probably gets lost in noise overall).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#scrape the information on the teams location from their
#worldfootball profile page
get_team_location &amp;lt;- function(link) {
  read &amp;lt;- read_html(paste0(base_url, link))
  
  stadium_link &amp;lt;- read %&amp;gt;%
    html_nodes(&amp;quot;.yellow tr:nth-child(5) a&amp;quot;) %&amp;gt;%
    html_attr(&amp;quot;href&amp;quot;)
  
  #if the link contains a link to a stadium scrape from there
  if(length(stadium_link) &amp;gt; 0) {
    stadium_link &amp;lt;- paste0(base_url, stadium_link)
    location &amp;lt;- read_html(stadium_link) %&amp;gt;%
      html_nodes(&amp;quot;.yellow tr:nth-child(1) td , .yellow tr:nth-child(2) td&amp;quot;) %&amp;gt;%
      html_text() %&amp;gt;%
      .[c(2,4)] %&amp;gt;%
      gsub(&amp;quot;\\r|\\t|\\n&amp;quot;, &amp;quot;&amp;quot;, .) %&amp;gt;%
      paste0(collapse  = &amp;quot; &amp;quot;)
    return(location)
  #otherwise get a best approximation
  } else {
    country &amp;lt;- read %&amp;gt;%
      html_nodes(&amp;quot;.portfolio tr:nth-child(3) .hell+ .hell&amp;quot;) %&amp;gt;%
      html_text() %&amp;gt;%
      gsub(&amp;quot;\\r|\\t|\\n&amp;quot;, &amp;quot;&amp;quot;, .)
    return(country)
  }
}

#run the function over each team
team_info &amp;lt;- teams %&amp;gt;%
  filter(!duplicated(team_name)) %&amp;gt;%
  mutate(location = unlist(lapply(team_info, get_team_location)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(team_info)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                  competition              team_name
## 1 Champions League 1955/1956      1. FC Saarbrücken
## 2 Champions League 1955/1956              Aarhus GF
## 3 Champions League 1955/1956               AC Milan
## 4 Champions League 1955/1956 Budapesti Vörös Lobogó
## 5 Champions League 1955/1956         Djurgårdens IF
## 6 Champions League 1955/1956       Gwardia Warszawa
##                     team_info            location
## 1 /teams/1-fc-saarbruecken/1/ Saarbrücken Germany
## 2         /teams/aarhus-gf/1/      Aarhus Denmark
## 3          /teams/ac-milan/1/        Milano Italy
## 4      /teams/mtk-budapest/1/    Budapest Hungary
## 5    /teams/djurgardens-if/1/    Stockholm Sweden
## 6  /teams/gwardia-warszawa/1/         Poland 0000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we have a rough location for each team we can join everything back together to get a complete list of matches and where (to a best approximation sometimes) they took place.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#join the team location into the non-neutral matches
nonneutral_matches &amp;lt;- match_locations[[1]] %&amp;gt;%
  left_join(., select(team_info, -competition), by = c(&amp;quot;home&amp;quot; = &amp;quot;team_name&amp;quot;)) %&amp;gt;%
  mutate(type = &amp;quot;normal&amp;quot;) %&amp;gt;%
  select(names(neutral_matches)) 

#join neutral and non neutral matches back together
all_matches &amp;lt;- rbind(neutral_matches, nonneutral_matches) %&amp;gt;%
  mutate(match_location = case_when(
    type == &amp;quot;normal&amp;quot; ~ paste(home, &amp;quot;football club&amp;quot;, location),
    type == &amp;quot;neutral&amp;quot; ~ location
  ))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we have the locations for each match, but not in a quantative form. For that, we’ll use the &lt;a href=&#34;https://cran.r-project.org/web/packages/googleway/vignettes/googleway-vignette.html&#34;&gt;googleway&lt;/a&gt; package that provides access to a variety of Google APIs to access the map geolocation feature of Google Mapes. Obviously, I haven’t included my unique key for this below, but you can get one for free using &lt;a href=&#34;https://developers.google.com/maps/documentation/javascript/tutorial&#34;&gt;this link&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For each location we’ll return a latitude and longitude that will allow us to calculate exactly the distances between a teams home location and each match they played.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#fake key
google_key &amp;lt;- &amp;quot;myGooGLeKEy1234567&amp;quot;

#function to get lat/lon data from Google Maps
googleway_geocode &amp;lt;- function(location, key){
  data &amp;lt;- google_geocode(location, key = key)
  latlon &amp;lt;- data$results$geometry$location[1,]
  
  if(length(latlon) == 0) {
    return(data.frame(lat = NA, lng = NA, location))
  } else {
    return(latlon %&amp;gt;% mutate(location))
  }
}

#run the function over each unique location
locations &amp;lt;- unique(all_matches$match_location) %&amp;gt;%
  map_df(., googleway_geocode, key = google_key)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This gets us 99% of the way there, though the API does miss a few smaller/less well formatted clubs (e.g. Monaco is not ‘in’ France per se, but an enclave in the French territory, which fucks Google Maps up)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;locations %&amp;gt;%
  filter(is.na(lat))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    lat lng                                           location
## 1   NA  NA              AS Monaco football club Monaco France
## 2   NA  NA St Patrick&amp;#39;s Athletic football club Dublin Ireland
## 3   NA  NA  FK Sloga Jugomagnat football club North Macedonia
## 4   NA  NA        Tsement Ararat football club Ararat Armenia
## 5   NA  NA        NK Brotnjo football club Bosnia-Herzegovina
## 6   NA  NA             Dunaferr SE football club Hungary 0000
## 7   NA  NA          Araks Ararat football club Ararat Armenia
## 8   NA  NA                FK Gomel football club Belarus 1959
## 9   NA  NA                Sioni Bolnisi football club Georgia
## 10  NA  NA                 SS Murata football club San Marino
## 11  NA  NA      KF Shkëndija 79 football club North Macedonia
## 12  NA  NA              SP Tre Penne football club San Marino
## 13  NA  NA                   Ulisses FC football club Armenia
## 14  NA  NA             SP La Fiorita football club San Marino
## 15  NA  NA      Lincoln Red Imps football club Gibraltar 0000
## 16  NA  NA                    Dila Gori football club Georgia
## 17  NA  NA                  KF Trepça&amp;#39;89 football club Kosovo
## 18  NA  NA                  Europa FC football club Gibraltar
## 19  NA  NA                   FK Spartaks football club Latvia
## 20  NA  NA                    FK Kukësi football club Albania&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To solve this, the best way sometimes is just the stupidest, so here are the manually found locations of these clubs&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#manually enter lat lon for the missing locations
missing_locs &amp;lt;- data.frame(
  lat = c(43.73, 53.34, 42.02, 39.86, 43.2, 46.96, 39.86, 52.44, 41.44, 43.93, 42.01, 43.93, 40.17, 43.93, 36.14, 41.98, 42.88, 36.14, 56.94, 42.07),
  lng = c(7.41, -6.27, 21.44, 44.69, 17.7, 18.94, 44.69, 31.01, 44.53, 12.44, 20.97, 12.44, 44.52, 12.44, -5.35, 44.10, 20.86, -5.35, 23.61, 20.42),
  location = locations$location[is.na(locations$lat)]
)

#bind everything together
all_locations &amp;lt;- locations %&amp;gt;%
  filter(!is.na(lat)) %&amp;gt;%
  rbind(., missing_locs) %&amp;gt;%
  #convert to an sf object with worldwide projection
  st_as_sf(coords = c(&amp;quot;lng&amp;quot;, &amp;quot;lat&amp;quot;), crs = st_crs(&amp;quot;+init=epsg:4326&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At the end, I also cast the object to an &lt;a href=&#34;https://r-spatial.github.io/sf/articles/sf1.html&#34;&gt;simple features&lt;/a&gt; (sf) data.frame to allow for easier manipulation of geographic data and add the reference for Earth’s lat/lon coordinate system (epsg:4326).&lt;/p&gt;
&lt;p&gt;We can then merge the geographic data into our dataframe of every match and see the location of every club to have played in (some stage) of the Champions League over the last ~60 years&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#join in the geographic information
all_matches %&amp;lt;&amp;gt;% left_join(., all_locations, by = c(&amp;quot;match_location&amp;quot; = &amp;quot;location&amp;quot;))

#plot the home locations of all teams
p1 &amp;lt;- all_matches %&amp;gt;%
  filter(type == &amp;quot;normal&amp;quot;) %&amp;gt;%
  filter(!duplicated(home)) %&amp;gt;%
  ggplot(.) +
  geom_sf(data = st_as_sf(ne_countries(scale=110), st_crs(&amp;quot;+init:epsg=4326&amp;quot;)),
          colour = NA) +
  geom_sf_text(aes(label = home, geometry = geometry), alpha = 0.5) +
  #taken from st_bbox(all_matches$geometry)
  coord_sf(xlim = c(-24, 78), ylim = c(30, 67)) +
  ggtitle(&amp;quot;Home location of every Champions League team&amp;quot;,
          subtitle = &amp;quot;1955-2019, includes qualifying rounds&amp;quot;) +
  theme_map()

#plot 
p1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-29-ucl_distance_files/figure-html/plot_locations-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It’s quite nice to see the distribution- hubs around large cities with competitive leagues (e.g. Denmark, Czech Republic, The Rhine), with extremes in the north in Iceland/Faroe Islands, to the south in Israel, and the far far East with the Central Asian UEFA countries.&lt;/p&gt;
&lt;p&gt;The first thing to then work out is the matches per team, which can be done via a simple gather. (in theory you’d want to use pivot_long which has deprecated gather but afaik it doesnt play well with geometry data yet). We also mutate in 2 variables for the home and away teams to keep the matches for data presentation purposes.&lt;/p&gt;
&lt;p&gt;Once we have that, we have each match played by each team, each season. A nice little result is we can see which teams have had the longest campaigns (in terms of number of matches), which it turns out are the Valencia and Bayer Leverkusen teams that qualified and got to the finals of the Champions League during the longer two-group-stage format at the turn of the century.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#melt the mach data by team
team_campaigns &amp;lt;- all_matches %&amp;gt;%
  select(season, date, competition, round, home, away, result, geometry) %&amp;gt;%
  #keep the home and away columns for later
  mutate(home_keep = home, away_keep = away) %&amp;gt;%
  gather(&amp;quot;location&amp;quot;, &amp;quot;team_name&amp;quot;,
         -season, -competition, -round, -result, -geometry, -date,
         -home_keep, -away_keep)

#get the longest campaigns in terms of n matches
longest_campaigns &amp;lt;- team_campaigns %&amp;gt;%
  group_by(season, team_name) %&amp;gt;%
  summarise(matches = n()) %&amp;gt;%
  arrange(-matches)

head(longest_campaigns)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 3
## # Groups:   season [4]
##   season    team_name        matches
##   &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;              &amp;lt;int&amp;gt;
## 1 1999-2000 Valencia CF           19
## 2 2000-2001 Valencia CF           19
## 3 2001-2002 Bayer Leverkusen      19
## 4 2002-2003 AC Milan              19
## 5 2000-2001 Leeds United          18
## 6 2001-2002 FC Barcelona          18&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But we want to work out the distance to each match, not the number. To do this, first we want to work backwards and get the lat/lon of each clubs home ground. We can then merge this with the match location data and find the difference between these two locations (in metres). I.e. for every home game, a team will travel 0m to the game, whereas the away club will travel probably many kilometres.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#work backwards and get the home location of each team
team_locations &amp;lt;- all_matches %&amp;gt;%
  filter(type == &amp;quot;normal&amp;quot;) %&amp;gt;%
  filter(!duplicated(home)) %&amp;gt;%
  select(team_name = home, location = match_location) %&amp;gt;%
  left_join(., all_locations, by = &amp;quot;location&amp;quot;)

#merge this in
#for each team match have location of match and home location of team
match_travel &amp;lt;- team_campaigns %&amp;gt;%
  left_join(., select(team_locations, team_name, geometry), by = &amp;quot;team_name&amp;quot;) %&amp;gt;%
  #calculate the distance between each teams home location the match
  mutate(distance = st_distance(geometry.x, geometry.y, by_element = TRUE))

head(match_travel)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      season       date competition       round             result
## 1 1955-1956 13/06/1956         ucl       Final          4:3 (2:2)
## 2 1956-1957 16/09/1956         ucl    1. Round          7:0 (4:0)
## 3 1956-1957 28/11/1956         ucl Round of 16          3:1 (1:0)
## 4 1956-1957 12/12/1956         ucl Round of 16          2:0 (2:0)
## 5 1956-1957 30/05/1957         ucl       Final          2:0 (0:0)
## 6 1957-1958 15/10/1957         ucl    1. Round 1:1 (0:1, 1:1) aet
##                   geometry.x                 home_keep        away_keep
## 1  POINT (2.253049 48.84144)               Real Madrid      Stade Reims
## 2  POINT (7.453112 51.49276)         Borussia Dortmund  Spora Luxemburg
## 3  POINT (2.253049 48.84144)                  OGC Nice       Rangers FC
## 4 POINT (-3.688344 40.45305)               Real Madrid       Rapid Wien
## 5 POINT (-3.688344 40.45305)               Real Madrid   ACF Fiorentina
## 6  POINT (13.40849 52.54356) SC Wismut Karl-Marx-Stadt Gwardia Warszawa
##   location                 team_name                 geometry.y
## 1     home               Real Madrid POINT (-3.688344 40.45305)
## 2     home         Borussia Dortmund  POINT (7.450945 51.49807)
## 3     home                  OGC Nice  POINT (7.195828 43.68232)
## 4     home               Real Madrid POINT (-3.688344 40.45305)
## 5     home               Real Madrid POINT (-3.688344 40.45305)
## 6     home SC Wismut Karl-Marx-Stadt  POINT (12.69902 50.58733)
##           distance
## 1 1043745.9567 [m]
## 2     609.3633 [m]
## 3  688197.6337 [m]
## 4       0.0000 [m]
## 5       0.0000 [m]
## 6  223136.3518 [m]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then all we need to do is group by each team and season and calculate the total distance travelled by that team. I then printed the top 10 total distances (in km) that team had to travel to complete all of their matches&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;longest_distance_campaigns &amp;lt;- match_travel %&amp;gt;%
  group_by(season, team_name) %&amp;gt;%
  mutate(total_travel = sum(distance), 
         date = as.Date(gsub(&amp;quot;\\/&amp;quot;, &amp;quot;-&amp;quot;, date), &amp;quot;%d-%m-%Y&amp;quot;)) %&amp;gt;%
  select(season, date, competition, round, team = team_name,
         home = home_keep, away = away_keep, result, distance, total_travel) %&amp;gt;%
  arrange(-total_travel, date) 

longest_distance_campaigns %&amp;gt;%
  filter(!duplicated(paste(season, team))) %&amp;gt;%
  select(season, team, total_travel) %&amp;gt;%
  mutate(total_travel = total_travel / 1000) %&amp;gt;%
  head(., n = 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10 x 3
## # Groups:   season, team [10]
##    season    team             total_travel
##    &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;                   &amp;lt;dbl&amp;gt;
##  1 2015-2016 FK Astana              25874.
##  2 2011-2012 APOEL Nikosia          19112.
##  3 2009-2010 APOEL Nikosia          18649.
##  4 2011-2012 SL Benfica             17817.
##  5 2009-2010 Maccabi Haifa          17808.
##  6 2000-2001 Galatasaray            17371.
##  7 2010-2011 Hapoel Tel Aviv        17350.
##  8 2017-2018 Qarabag FK             17286.
##  9 2015-2016 Maccabi Tel Aviv       17041.
## 10 2002-2003 Lokomotiv Moskva       16732.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Perhaps unsurprisingly &lt;a href=&#34;https://en.wikipedia.org/wiki/2015_FC_Astana_season&#34;&gt;FK Astana&lt;/a&gt; from the capital of Kazakhstan come out top (by far), having worked through the qualifying round and making it to the group stages (where they were unbeaten at home). After that, succesful teams from the far corners of Europe (Benfica, APOEL, Hapoel Tel Aviv) come out on top. I was surprised that Lokomotiv are the only Russian team in the list, and as far back as 2002-2003. Also that all of these seasons are from this century (perhaps due to the ever increasing number of fixtures in the Champions League).&lt;/p&gt;
&lt;p&gt;I select the matches FK Astana played in their record-breaking 2015-2016 below:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;longest_distance_campaigns %&amp;gt;%
  filter(season == &amp;quot;2015-2016&amp;quot; &amp;amp; team == &amp;quot;FK Astana&amp;quot;) %&amp;gt;%
  select(-team)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 12 x 10
## # Groups:   season, team [1]
##    team  season date       competition round home  away  result distance
##    &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;date&amp;gt;     &amp;lt;chr&amp;gt;       &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;       [m]
##  1 FK A… 2015-… 2015-07-14 ucl-quals   2. R… NK M… FK A… 1:0 (…  4025459
##  2 FK A… 2015-… 2015-07-22 ucl-quals   2. R… FK A… NK M… 3:1 (…        0
##  3 FK A… 2015-… 2015-07-29 ucl-quals   3. R… HJK … FK A… 0:0 (…  3022119
##  4 FK A… 2015-… 2015-08-05 ucl-quals   3. R… FK A… HJK … 4:3 (…        0
##  5 FK A… 2015-… 2015-08-18 ucl-quals   Play… FK A… APOE… 1:0 (…        0
##  6 FK A… 2015-… 2015-08-26 ucl-quals   Play… APOE… FK A… 1:1 (…  3510897
##  7 FK A… 2015-… 2015-09-15 ucl         Grou… SL B… FK A… 2:0 (…  6180579
##  8 FK A… 2015-… 2015-09-30 ucl         Grou… FK A… Gala… 2:2 (…        0
##  9 FK A… 2015-… 2015-10-21 ucl         Grou… Atlé… FK A… 4:0 (…  5713668
## 10 FK A… 2015-… 2015-11-03 ucl         Grou… FK A… Atlé… 0:0 (…        0
## 11 FK A… 2015-… 2015-11-25 ucl         Grou… FK A… SL B… 2:2 (…        0
## 12 FK A… 2015-… 2015-12-08 ucl         Grou… Gala… FK A… 1:1 (…  3421522
## # … with 1 more variable: total_travel &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, one of the real niche joys in my love is making maps and what better oppurtunity than to map these long distance Champions League campaigns. It’s a bit of a munge to get the lines from point data but sf does at least make it possible.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#get the top ten longest campaigns
data &amp;lt;- filter(longest_distance_campaigns,
               !duplicated(paste(season, team)))[1:10,] %&amp;gt;%
  ungroup() %&amp;gt;%
  select(season, team_name = team, total_travel) %&amp;gt;%
  left_join(., match_travel) %&amp;gt;%
  #munge the geometry
  filter(st_geometry(.$geometry.x) != st_geometry(.$geometry.y)) %&amp;gt;%
    mutate(versus = case_when(
        location == &amp;quot;home&amp;quot; ~ away_keep,
        location == &amp;quot;away&amp;quot; ~ home_keep
    )) %&amp;gt;%
    select(season, team_name, versus, round, total_travel,
           geometry.x, geometry.y) %&amp;gt;%
  split(f = rownames(.)) %&amp;gt;%
  #calculate lines from points
  lapply(., function(row) {
    coords1 &amp;lt;- st_coordinates(row$geometry.x) %&amp;gt;%
      split(f = rownames(.))
    coords2 &amp;lt;- st_coordinates(row$geometry.y) %&amp;gt;%
      split(f = rownames(.))
    
    lines &amp;lt;- map2(coords1, coords2, ~st_linestring(rbind(.x, .y)))
    row$lines &amp;lt;- st_as_sfc(lines, crs = st_crs(&amp;quot;+init=epsg:4326&amp;quot;))
    return(row)
  }) %&amp;gt;%
  do.call(rbind, .) %&amp;gt;%
  mutate(title = paste(season, team_name, &amp;quot;=&amp;quot;, round(total_travel/1000), &amp;quot;km&amp;quot;))

#plot the travel of each team
p2 &amp;lt;- ggplot() +
  geom_sf(data = st_as_sf(ne_countries(scale=110), st_crs(&amp;quot;+init:epsg=4326&amp;quot;)), 
          colour = NA) +
  geom_sf(data = data, aes(geometry = lines),
          colour = &amp;quot;red&amp;quot;, size = 2) +
  geom_sf_text(data = data, aes(geometry = geometry.x, label = versus),
               size = 4, nudge_y = 2) +
  #again taken from st_bbox
  coord_sf(xlim = c(-23, 77), ylim = c(66, 30)) +
  theme_map() +
  theme(
    strip.background = element_rect(fill = &amp;quot;white&amp;quot;),
    strip.text = element_text(size = 10)
  ) +
  facet_wrap(~title)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;https://www.robert-hickman.eu/img/longest_distances_plot.svg&#34; title=&#34;plot of the longest UCL campaigns&#34;&gt;&lt;img src=&#34;/img/longest_distance_campaigns.png&#34; alt=&#34;plot of the longest UCL campaigns&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Click on the image for a higher-res version :)&lt;/p&gt;
&lt;p&gt;Two quick finishing pieces:&lt;/p&gt;
&lt;p&gt;Firstly, what is the single longest journey in the history of the Champions League? Unsurprisingly it involves the 2015-2016 FK Astana season travelling to Benfica on the coast of Portugal (and of course the return fixture).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;match_travel[which.max(match_travel$distance),]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          season       date competition   round    result
## 12000 2015-2016 15/09/2015         ucl Group C 2:0 (0:0)
##                       geometry.x  home_keep away_keep location team_name
## 12000 POINT (-9.184503 38.75253) SL Benfica FK Astana     away FK Astana
##                      geometry.y    distance
## 12000 POINT (71.40261 51.10822) 6180579 [m]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And secondly, answering the original question- what the shortest average commute for a winning side?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#get UCL champions
winners &amp;lt;- match_travel %&amp;gt;%
  filter(round == &amp;quot;Final&amp;quot;) %&amp;gt;%
  mutate(result = gsub(&amp;quot; .*&amp;quot;, &amp;quot;&amp;quot;, result)) %&amp;gt;%
  separate(result, into = c(&amp;quot;h_goal&amp;quot;, &amp;quot;a_goal&amp;quot;), sep = &amp;quot;:&amp;quot;) %&amp;gt;%
  filter((location == &amp;quot;home&amp;quot; &amp;amp; h_goal &amp;gt; a_goal) | (location == &amp;quot;away&amp;quot; &amp;amp; a_goal &amp;gt; h_goal)) %&amp;gt;%
  select(season, team_name)

#find the matches played by champions
winners_matches &amp;lt;- left_join(winners, match_travel, by = c(&amp;quot;season&amp;quot;, &amp;quot;team_name&amp;quot;)) %&amp;gt;%
  group_by(season, team_name) %&amp;gt;%
  mutate(matches = n(), total_travel = sum(distance/1000)) %&amp;gt;%
  ungroup() %&amp;gt;%
  #calculate average travel per game
  mutate(average_travel = total_travel / matches,
         date = as.Date(gsub(&amp;quot;\\/&amp;quot;, &amp;quot;-&amp;quot;, date), &amp;quot;%d-%m-%Y&amp;quot;)) %&amp;gt;%
  select(season, date, round, home = home_keep, away = away_keep, result, distance, average_travel) %&amp;gt;%
  arrange(average_travel, date)

#print the 3 campaigns with the lowest average travel
head(winners_matches, n = 27)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 27 x 8
##    season  date       round   home    away   result distance average_travel
##    &amp;lt;chr&amp;gt;   &amp;lt;date&amp;gt;     &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;       [m]          &amp;lt;dbl&amp;gt;
##  1 1963-1… 1963-09-18 1. Rou… Everto… Inter  0:0 (… 1247112…           410.
##  2 1963-1… 1963-09-25 1. Rou… Inter   Evert… 1:0 (…       0…           410.
##  3 1963-1… 1963-11-27 Round … Inter   AS Mo… 1:0 (…       0…           410.
##  4 1963-1… 1963-12-04 Round … AS Mon… Inter  1:3 (…  236127…           410.
##  5 1963-1… 1964-02-26 Quarte… Partiz… Inter  0:2 (…  891298…           410.
##  6 1963-1… 1964-03-04 Quarte… Inter   Parti… 2:1 (…       0…           410.
##  7 1963-1… 1964-04-15 Semi-f… Boruss… Inter  2:2 (…  684493…           410.
##  8 1963-1… 1964-04-29 Semi-f… Inter   Borus… 2:0 (…       0…           410.
##  9 1963-1… 1964-05-27 Final   Inter   Real … 3:1 (…  632859…           410.
## 10 1971-1… 1971-09-15 1. Rou… AFC Aj… Dynam… 2:0 (…       0…           433.
## # … with 17 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Where the top three are Inter’s 1963-1964, Ajax’s 1971-1972, and Bayern Munich’s 1973-1974 seasons all of which have an average travel of just over 400km per game. It’s fairly striking how many more Central European teams there are further in the competitions in these seasons comapred to today.&lt;/p&gt;
&lt;p&gt;And that’s all for now! Thanks for reading and I’ll try and put out another post soon :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Five Minute Football Trivia - Birthday Five-A-Side</title>
      <link>/post/five_min_trivia_birthdays/</link>
      <pubDate>Sat, 14 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/five_min_trivia_birthdays/</guid>
      <description>


&lt;p&gt;&lt;em&gt;generally as I have less and less time to waste on meaningless football stats I get halfway through a post and abandon it. To remedy this, I want to start pushing out posts that give a reasonable half-guess at an answer within an hour or so without needing to really check my working or write good prose. This is the second of these&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;A semi-common question I’ve come across when doing stupid football trivia is ‘Which Birthday could field the best 5-a-side team?’. That is, if you could only select 5 players all born on the same date, which date would you pick in order to allow for the strongest team. For an example, see &lt;a href=&#34;https://www.theguardian.com/football/2014/feb/19/best-team-players-born-same-day&#34;&gt;the Guardian’s knowledge blog&lt;/a&gt; from 2014. However, this was based on gut feel of the team, and this blog (however flawed) deals in data, so let’s go.&lt;/p&gt;
&lt;p&gt;As always, we’ll start by loading some libraries&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#munging
library(tidyverse)
#regression (later)
library(glmnet)
#plots (at the end)
library(ggsoccer)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’ll then load our data to compare players’ ability. For this I’m using a database I put together of every character in the FIFA database I scraped from &lt;a href=&#34;https://www.fifaindex.com/&#34;&gt;FIFAindex.com&lt;/a&gt;. The database goes back 15 years to the ‘05’ version of the game so we won’t have to limit ourselves to current players. The scraped db can be found at &lt;a href=&#34;https://github.com/RobWHickman/fifadb&#34;&gt;my github&lt;/a&gt;*&lt;/p&gt;
&lt;p&gt;*it’s still very beta version at the moment and needs a lot more munging but should work for most applications&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;player_data &amp;lt;- map_df(
  #load female and male player data from the github repo
  c(&amp;quot;male_players.rds&amp;quot;), function(x) {
    data &amp;lt;- readRDS(paste0(&amp;quot;path/to/file/&amp;quot;, x)) %&amp;gt;%
      mutate(version = as.character(version), dob = as.Date(dob, &amp;quot;%Y-%B-%D&amp;quot;))
    return(data)
}) %&amp;gt;%
  #munge date of birth in day and month of birth (don&amp;#39;t care about year)
  mutate(day_of_birth = gsub(&amp;quot;^[0-9]{4}-&amp;quot;, &amp;quot;&amp;quot;, dob)) %&amp;gt;%
  separate(day_of_birth, into = c(&amp;quot;month&amp;quot;, &amp;quot;day&amp;quot;), sep = &amp;quot;-&amp;quot;, remove = FALSE) %&amp;gt;%
  mutate(month = as.numeric(month), day = as.numeric(day), ability = as.numeric(ability))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This should give us a 145536 observation df for 65 variables (!). I.e. the information on, and stats of, every character to appear over the last decade and half. We can then look at the spread of birthdays in the dataset:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#plot the numbers of players per day of birth in the dataset
p1 &amp;lt;- ggplot(player_data, aes(x = day, fill = factor(month))) +
  geom_histogram(stat = &amp;quot;count&amp;quot;) +
  scale_fill_discrete(guide = FALSE) +
  labs(title = &amp;quot;Number of players sharing birthday by day of year&amp;quot;,
       x = &amp;quot;day of month&amp;quot;) +
  facet_wrap(~month) +
  theme_minimal()

p1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-14-birthdays_files/figure-html/plot_birthdays-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Two peaks that pop out are the massive spike on February 29th and the smaller one of January 1st. On inspection, it looks like these are used as placeholders when true date of birth isn’t known. FOr the reaminer of the post we’re going to exclude them&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#filter out 1st January and 29th February (placeholders for unknown dob?)
player_data &amp;lt;- filter(player_data,
                      !(day == 1 &amp;amp; month == 1) &amp;amp; !(day == 29 &amp;amp; month == 2))

#replot
p2 &amp;lt;- player_data %&amp;gt;%
  ggplot(., aes(x = day, fill = factor(month))) +
  geom_histogram(stat = &amp;quot;count&amp;quot;) +
  scale_fill_discrete(guide = FALSE) +
  labs(title = &amp;quot;Number of players sharing birthday by day of year&amp;quot;,
       subtitle = &amp;quot;placeholder dates removed&amp;quot;,
       x = &amp;quot;day of month&amp;quot;) +
  facet_wrap(~month) +
  theme_minimal()

p2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-14-birthdays_files/figure-html/plot_birthdays2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Then we can put teams together by taking the top 5 players by the ‘overall ability’ stat for each date of birth:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;by_day &amp;lt;- player_data %&amp;gt;%
  #take only relevant data
  select(name = name2, ability, day, month, version) %&amp;gt;%
  arrange(-ability) %&amp;gt;%
  #group by day and take each players best ability score
  group_by(day, month) %&amp;gt;%
  filter(!duplicated(name)) %&amp;gt;%
  #get the top five by day
  split(f = paste(.$day, .$month)) %&amp;gt;%
  map(., function(dat) dat[1:5,] %&amp;gt;% mutate(team_ability = sum(ability)))

#glimpse the first two teams (1/10 and 1/11)
by_day[1:2]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $`1 10`
## # A tibble: 5 x 6
## # Groups:   day, month [1]
##   name           ability   day month version team_ability
##   &amp;lt;chr&amp;gt;            &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
## 1 Anthony Lopes       85     1    10 19               418
## 2 Mirko Vucinic       84     1    10 07               418
## 3 Julio Baptista      83     1    10 05               418
## 4 Vitor Baía          83     1    10 06               418
## 5 Ümit Karan          83     1    10 07               418
## 
## $`1 11`
## # A tibble: 5 x 6
## # Groups:   day, month [1]
##   name                  ability   day month version team_ability
##   &amp;lt;chr&amp;gt;                   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
## 1 Miloš Krasic               83     1    11 11               403
## 2 Filip Kostic               82     1    11 20               403
## 3 Mahler Tressor Moreno      80     1    11 06               403
## 4 Vaclav Sverkos             79     1    11 06               403
## 5 Dimo Wache                 79     1    11 07               403&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then to find the best 5 of these teams, we can push it through two quick functions as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#get the top 5 teams by summed ability
top_teams &amp;lt;- by_day %&amp;gt;%
  #sum the ability per team
  map_dbl(., function(dat) return(unique(dat$team_ability))) %&amp;gt;%
  sort() %&amp;gt;%
  #return the top n teams
  tail(n = 5) %&amp;gt;%
  names(.) %&amp;gt;%
  map(., function(date) return(by_day[date]))

top_teams&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## [[1]]$`7 10`
## # A tibble: 5 x 6
## # Groups:   day, month [1]
##   name                   ability   day month version team_ability
##   &amp;lt;chr&amp;gt;                    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
## 1 Dida                        91     7    10 06               436
## 2 Gilberto                    89     7    10 05               436
## 3 Sami Hyypiä                 86     7    10 05               436
## 4 Diego Costa                 86     7    10 17               436
## 5 Santiago Hernán Solari      84     7    10 05               436
## 
## 
## [[2]]
## [[2]]$`17 8`
## # A tibble: 5 x 6
## # Groups:   day, month [1]
##   name           ability   day month version team_ability
##   &amp;lt;chr&amp;gt;            &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
## 1 Thierry Henry       97    17     8 05               437
## 2 Ederson             88    17     8 20               437
## 3 William Gallas      87    17     8 05               437
## 4 Güiza               83    17     8 09               437
## 5 Phil Jagielka       82    17     8 10               437
## 
## 
## [[3]]
## [[3]]$`22 9`
## # A tibble: 5 x 6
## # Groups:   day, month [1]
##   name                 ability   day month version team_ability
##   &amp;lt;chr&amp;gt;                  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
## 1 Ronaldo                   94    22     9 06               437
## 2 Thiago Silva              89    22     9 17               437
## 3 Harry Kewell              86    22     9 05               437
## 4 Javier López Vallejo      84    22     9 06               437
## 5 Maarten Stekelenburg      84    22     9 12               437
## 
## 
## [[4]]
## [[4]]$`24 6`
## # A tibble: 5 x 6
## # Groups:   day, month [1]
##   name                ability   day month version team_ability
##   &amp;lt;chr&amp;gt;                 &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
## 1 Lionel Messi             94    24     6 12               439
## 2 Juan Román Riquelme      88    24     6 07               439
## 3 Luis García              86    24     6 06               439
## 4 David Alaba              86    24     6 17               439
## 5 Shunsuke Nakamura        85    24     6 08               439
## 
## 
## [[5]]
## [[5]]$`5 2`
## # A tibble: 5 x 6
## # Groups:   day, month [1]
##   name                     ability   day month version team_ability
##   &amp;lt;chr&amp;gt;                      &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
## 1 Cristiano Ronaldo             94     5     2 17               439
## 2 Neymar Jr                     92     5     2 17               439
## 3 Carlos Tévez                  87     5     2 06               439
## 4 Stefan de Vrij                84     5     2 18               439
## 5 Giovanni Van Bronckhorst      82     5     2 05               439&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So our top team is comprised of &lt;a href=&#34;https://en.wikipedia.org/wiki/Carli_Lloyd&#34;&gt;2017 Carli Lloyd&lt;/a&gt;, &lt;a href=&#34;https://en.wikipedia.org/wiki/Vicente_Rodr%C3%ADguez&#34;&gt;2005 Vincente&lt;/a&gt;, &lt;a href=&#34;https://en.wikipedia.org/wiki/Gareth_Bale&#34;&gt;2017 Gareth Bale&lt;/a&gt;, &lt;a href=&#34;https://en.wikipedia.org/wiki/Sergio_Busquets&#34;&gt;2019 Sergio Busquets&lt;/a&gt;, and &lt;a href=&#34;https://en.wikipedia.org/wiki/Mousa_Demb%C3%A9l%C3%A9_(Belgian_footballer)&#34;&gt;2018 Moussa Dembele&lt;/a&gt;, all of whom were born on July 16th.&lt;/p&gt;
&lt;p&gt;However, it’s pretty clear this isn’t a very satisfactory answer; the best team here has 5 midfielders. To get a little deeper, we need to bust out a bit of machine learning. First we want to see what are all the positions in the dataset:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#take the primary position for each player
unique(as.character(sapply(player_data$positions, &amp;quot;[[&amp;quot;, 1)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;ST&amp;quot;   &amp;quot;GK&amp;quot;   &amp;quot;CAM&amp;quot;  &amp;quot;CDM&amp;quot;  &amp;quot;CB&amp;quot;   &amp;quot;LCAM&amp;quot; &amp;quot;CM&amp;quot;   &amp;quot;LM&amp;quot;   &amp;quot;CF&amp;quot;   &amp;quot;LWM&amp;quot; 
## [11] &amp;quot;RM&amp;quot;   &amp;quot;RB&amp;quot;   &amp;quot;RWB&amp;quot;  &amp;quot;RWM&amp;quot;  &amp;quot;LB&amp;quot;   &amp;quot;LCB&amp;quot;  &amp;quot;LS&amp;quot;   &amp;quot;LF&amp;quot;   &amp;quot;RCB&amp;quot;  &amp;quot;LAM&amp;quot; 
## [21] &amp;quot;LWB&amp;quot;  &amp;quot;LCDM&amp;quot; &amp;quot;RS&amp;quot;   &amp;quot;LCM&amp;quot;  &amp;quot;RAM&amp;quot;  &amp;quot;RCM&amp;quot;  &amp;quot;RF&amp;quot;   &amp;quot;SW&amp;quot;   &amp;quot;RCDM&amp;quot; &amp;quot;RCAM&amp;quot;
## [31] &amp;quot;LDM&amp;quot;  &amp;quot;RDM&amp;quot;  &amp;quot;RW&amp;quot;   &amp;quot;LW&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So a fair few, but a lot of these (e.g. RW and LW) are basically the same position, just played of the opposite side of the pitch. We’d expect a left winger to &lt;em&gt;mostly&lt;/em&gt; have the same skills as a right winger.&lt;/p&gt;
&lt;p&gt;To fix this we can make these positions ‘symmetric’ by replacin the left/right with a W (for wide):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#add in the symmetric position column
player_data$position &amp;lt;- sapply(player_data$positions, &amp;quot;[[&amp;quot;, 1)
player_data &amp;lt;- player_data %&amp;gt;%
  mutate(symmetric_position = gsub(&amp;quot;L|R&amp;quot;, &amp;quot;W&amp;quot;, position))

unique(player_data$symmetric_position)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;ST&amp;quot;   &amp;quot;GK&amp;quot;   &amp;quot;CAM&amp;quot;  &amp;quot;CDM&amp;quot;  &amp;quot;CB&amp;quot;   &amp;quot;WCAM&amp;quot; &amp;quot;CM&amp;quot;   &amp;quot;WM&amp;quot;   &amp;quot;CF&amp;quot;   &amp;quot;WWM&amp;quot; 
## [11] &amp;quot;WB&amp;quot;   &amp;quot;WWB&amp;quot;  &amp;quot;WCB&amp;quot;  &amp;quot;WS&amp;quot;   &amp;quot;WF&amp;quot;   &amp;quot;WAM&amp;quot;  &amp;quot;WCDM&amp;quot; &amp;quot;WCM&amp;quot;  &amp;quot;SW&amp;quot;   &amp;quot;WDM&amp;quot; 
## [21] &amp;quot;WW&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We then want to use the attributes for each player at various skills (e.g. Shot Power, Ball Control, GK Rushing [out], Free Kicks,…) to work out how they interact with the palyer’s chosen position to create their overall ability score in the game.&lt;/p&gt;
&lt;p&gt;For example, in &lt;a href=&#34;https://www.fifaindex.com/player/158023/lionel-messi/fifa20/&#34;&gt;FIFA 2020, Lionel Messi&lt;/a&gt; has rather poor defensive stats (e.g. only 26/100 for sliding tackles). Any reasonable person would reognise that sliding tackles just &lt;em&gt;aren’t important&lt;/em&gt; for Lionel Messi’s role in the Barcelona team. However, we can use these stats to work out what his overall ability would be &lt;em&gt;if he were a defender&lt;/em&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#attribute variables we&amp;#39;ll need to use to work out player position ability
attribute_vars &amp;lt;- grep(&amp;quot;Ball_Control&amp;quot;, names(player_data)):
  grep(&amp;quot;GK_Rushing&amp;quot;, names(player_data))

names(player_data)[attribute_vars]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;Ball_Control&amp;quot;       &amp;quot;Dribbling&amp;quot;          &amp;quot;Marking&amp;quot;           
##  [4] &amp;quot;Slide_Tackle&amp;quot;       &amp;quot;Stand_Tackle&amp;quot;       &amp;quot;Aggression&amp;quot;        
##  [7] &amp;quot;Reactions&amp;quot;          &amp;quot;Attack_Positioning&amp;quot; &amp;quot;Interceptions&amp;quot;     
## [10] &amp;quot;Vision&amp;quot;             &amp;quot;Crossing&amp;quot;           &amp;quot;Short_Pass&amp;quot;        
## [13] &amp;quot;Long_Pass&amp;quot;          &amp;quot;Acceleration&amp;quot;       &amp;quot;Stamina&amp;quot;           
## [16] &amp;quot;Strength&amp;quot;           &amp;quot;Balance&amp;quot;            &amp;quot;Sprint_Speed&amp;quot;      
## [19] &amp;quot;Agility&amp;quot;            &amp;quot;Jumping&amp;quot;            &amp;quot;Heading&amp;quot;           
## [22] &amp;quot;Shot_Power&amp;quot;         &amp;quot;Long_Shots&amp;quot;         &amp;quot;Finishing&amp;quot;         
## [25] &amp;quot;FK_Accuracy&amp;quot;        &amp;quot;Curve&amp;quot;              &amp;quot;Penalties&amp;quot;         
## [28] &amp;quot;Volleys&amp;quot;            &amp;quot;GK_Reflexes&amp;quot;        &amp;quot;GK_Handling&amp;quot;       
## [31] &amp;quot;GK_Positioning&amp;quot;     &amp;quot;GK_Diving&amp;quot;          &amp;quot;GK_Kicking&amp;quot;        
## [34] &amp;quot;Tackling&amp;quot;           &amp;quot;Anticipation&amp;quot;       &amp;quot;Composure&amp;quot;         
## [37] &amp;quot;Creativity&amp;quot;         &amp;quot;Passing&amp;quot;            &amp;quot;Long_Balls&amp;quot;        
## [40] &amp;quot;Pace&amp;quot;               &amp;quot;Shot_Accuracy&amp;quot;      &amp;quot;GK_Rushing&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’ll then run a &lt;a href=&#34;https://www.statisticshowto.datasciencecentral.com/lasso-regression/&#34;&gt;LASSO regression&lt;/a&gt; to calculate exactly how important each of these variables are to players of each position, and then use these weights to calculate the hypothetical ability of players in positions they would never play. For some more explanation, a lot of this is taken from some old blog posts &lt;a href=&#34;https://www.robert-hickman.eu/post/yorkshire_world_cup_2/&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#function to do the lasso regression
get_player_position_abilities &amp;lt;- function(model_pos, model_vers) {
  #id players by their link to fifaindex
  ids &amp;lt;- player_data$player_link[player_data$version == model_vers]
  
  #train on players who play each position
  train_data &amp;lt;- player_data %&amp;gt;%
    filter(symmetric_position == model_pos &amp;amp; version == model_vers) %&amp;gt;%
    select(&amp;quot;ability&amp;quot;, attribute_vars) %&amp;gt;%
    mutate(ability = as.numeric(ability)) %&amp;gt;%
    #some variables aren&amp;#39;t in all versions of FIFA
    #get rid of any that are all NA
    purrr::discard(~all(is.na(.)))
  #if no examples of this position for a version of FIFA, return NULL
  if(length(train_data) == 0) return(NULL)
  #convert to a matrix and train the regression
  train_matrix &amp;lt;- model.matrix(ability~., train_data)
  cv_model &amp;lt;- cv.glmnet(train_matrix, train_data$ability)
  
  #use these weights on every player from that version of FIFA
  test_data &amp;lt;- player_data %&amp;gt;%
    filter(version == model_vers) %&amp;gt;%
    select(&amp;quot;ability&amp;quot;, attribute_vars) %&amp;gt;%
    mutate(ability = as.numeric(ability)) %&amp;gt;%
    purrr::discard(~all(is.na(.)))
  #calculate the ability score for each player for that position
  test_matrix &amp;lt;- model.matrix(ability~., test_data)
  position_ability &amp;lt;- predict(cv_model, newx = test_matrix, s = &amp;quot;lambda.min&amp;quot;, type=&amp;quot;response&amp;quot;)
  
  #return the positional scores
  df &amp;lt;- data.frame(
    player_link = ids,
    ability = as.numeric(position_ability),
    version = model_vers,
    position = model_pos
  )
  return(df)
}

#get all combinations of position and FIFA version
crossed_vars &amp;lt;- crossing(
  pos = unique(player_data$symmetric_position), 
  vers = unique(player_data$version)
)

#get all players ability in every position
position_abilities &amp;lt;- map2_df(crossed_vars$pos, crossed_vars$vers, get_player_position_abilities) %&amp;gt;%
  left_join(select(player_data, name = name2, day, month, player_link), by = &amp;quot;player_link&amp;quot;) %&amp;gt;%
  pivot_wider(names_from = position, values_from = ability) %&amp;gt;%
  select(-player_link)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So once we’ve run that we can see how each player is expected to perform in any position. For instance, if we take the first three players in the dataset we can see how Thierry Henry&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(position_abilities, n = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 25
##   version name    day month   CAM    CB   CDM    CF    CM    GK    ST    SW
##   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 05      Thie…    17     8  88.8  53.1  70.9  96.5  76.4  24.2  96.5  55.2
## 2 05      Gian…    28     1  34.3  39.5  34.7  39.0  34.3  96.3  39.2  34.5
## 3 05      Zine…    23     6  96.1  72.1  86.8  93.9  91.1  26.7  93.9  75.2
## # … with 13 more variables: WAM &amp;lt;dbl&amp;gt;, WB &amp;lt;dbl&amp;gt;, WCAM &amp;lt;dbl&amp;gt;, WCB &amp;lt;dbl&amp;gt;,
## #   WCDM &amp;lt;dbl&amp;gt;, WCM &amp;lt;dbl&amp;gt;, WDM &amp;lt;dbl&amp;gt;, WF &amp;lt;dbl&amp;gt;, WM &amp;lt;dbl&amp;gt;, WS &amp;lt;dbl&amp;gt;,
## #   WW &amp;lt;dbl&amp;gt;, WWB &amp;lt;dbl&amp;gt;, WWM &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can also plot the relative abilities of each player to see if they make sense. In the below I’ve excluded the names of each playey on the y axis to save space, but every slither is a separate player:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p3 &amp;lt;- position_abilities %&amp;gt;%
  #arrange ordering
  arrange(-ST) %&amp;gt;%
  filter(!duplicated(name)) %&amp;gt;%
  mutate(name = factor(name, levels = unique(name),)) %&amp;gt;%
  select(name, 5:ncol(.)) %&amp;gt;%
  #melt data
  pivot_longer(cols = c(2:ncol(.)), names_to = &amp;quot;position&amp;quot;, values_to = &amp;quot;ability&amp;quot;) %&amp;gt;%
  arrange(name, -ability) %&amp;gt;%
  mutate(position = factor(position, levels = unique(position))) %&amp;gt;%
  ggplot(aes(y = name, x = position)) +
  geom_tile(aes(fill = ability)) +
  labs(title = &amp;quot;Relative abilities of all players in all positions&amp;quot;,
       x = &amp;quot;position&amp;quot;,
       y = &amp;quot;player&amp;quot;) +
  theme_minimal() +
  #get rid of y axis text
  theme(axis.text.y = element_blank()) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

p3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-14-birthdays_files/figure-html/plot_position_abilities-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And it’s clear that players that excel in the attacking positions towards the left are weaker at the defensive positions towards the right (also not the big section of dark blue for weakness in the goalkeepers column).&lt;/p&gt;
&lt;p&gt;In building a 5-a-side team, I’m going to assume you want at least one defencer, one midfielder, one attacker, one goalkeeper, and then one extra outfield player in whatever position. It’s important to note that this not have to be ‘player traditionally thought of as a defender’, a particularly skilled striker could very well take up the defensive space if they had the requisite abilities.&lt;/p&gt;
&lt;p&gt;To do this, we have to bin the positions into attack/defense and then find the highest value for each for every player&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gk_cols &amp;lt;- c(&amp;quot;GK&amp;quot;)
def_cols &amp;lt;- c(&amp;quot;CB&amp;quot;, &amp;quot;SW&amp;quot;, &amp;quot;WCB&amp;quot;, &amp;quot;CDM&amp;quot;, &amp;quot;WCDM&amp;quot;, &amp;quot;WDM&amp;quot;)
mid_cols &amp;lt;- c(&amp;quot;CM&amp;quot;, &amp;quot;WCM&amp;quot;, &amp;quot;CAM&amp;quot;, &amp;quot;WCAM&amp;quot;, &amp;quot;WM&amp;quot;, &amp;quot;WWM&amp;quot;, &amp;quot;WB&amp;quot;, &amp;quot;WWB&amp;quot;)
attack_cols &amp;lt;- c(&amp;quot;CF&amp;quot;, &amp;quot;WF&amp;quot;, &amp;quot;ST&amp;quot;, &amp;quot;WS&amp;quot;, &amp;quot;WAM&amp;quot;, &amp;quot;WW&amp;quot;)

#find the best defensive/attack position for each player
fiveaside_abilities &amp;lt;- map(list(gk_cols, def_cols, mid_cols, attack_cols),
               function(cols) position_abilities %&amp;gt;% select(cols) %&amp;gt;% apply(., 1, max, na.rm = TRUE)) %&amp;gt;%
  do.call(cbind, .) %&amp;gt;%
  as.data.frame() %&amp;gt;%
  #bind this back to the original data
  cbind(position_abilities, .) %&amp;gt;%
  #select the necessary columns
  select(name, version, gk = V1, def = V2, mid = V3, att = V4, day, month)

head(fiveaside_abilities)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                  name version       gk      def      mid      att day
## 1       Thierry Henry      05 24.24627 70.91822 88.87479 96.60456  17
## 2    Gianluigi Buffon      05 96.29510 40.01513 39.58011 39.76021  28
## 3     Zinedine Zidane      05 26.66050 86.77503 96.06867 96.11257  23
## 4 Ruud van Nistelrooy      05 22.75526 75.99536 86.59128 94.70145   1
## 5          Roy Makaay      05 23.52925 65.63241 78.20789 93.82865   9
## 6       Iker Casillas      05 94.11531 54.33178 45.29751 51.61508  20
##   month
## 1     8
## 2     1
## 3     6
## 4     7
## 5     3
## 6     5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we have the player abilities, combining them into a team is not quite trivial, but not far off&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#melt data back down for team selection
team_selection_dat &amp;lt;- fiveaside_abilities %&amp;gt;%
  pivot_longer(cols = names(fiveaside_abilities)[3:6],
               names_to = &amp;quot;pos&amp;quot;, values_to = &amp;quot;ability&amp;quot;)

#fun on a function to select optimal five a side teams
best_teams &amp;lt;- 
  #run for each date we want to select for
  map_df(unique(paste(team_selection_dat$day, team_selection_dat$month, sep = &amp;quot;-&amp;quot;)), 
         function(select_dob, data) {
           #filter only players with that birth date
           bday_dat &amp;lt;- data %&amp;gt;%
             mutate(dob = paste(day, month, sep = &amp;quot;-&amp;quot;)) %&amp;gt;%
             filter(dob == select_dob) %&amp;gt;%
             arrange(-ability)
           
           #take positions in order of highest ability score
           #in order to pick optimally
           position_order &amp;lt;- unique(bday_dat$pos)
           
           #init a data frame
           team &amp;lt;- data.frame(
             name = NULL,
             version = NULL,
             day = NULL,
             month = NULL,
             pos = NULL,
             ability = NULL
           )
           
           #for loop through the positions to be picked
           #probably a better way to write this but
           #by now my brain was melting
           for(position in position_order) {
             #select the best player for that position
             selected_player &amp;lt;- bday_dat %&amp;gt;%
               filter(pos == position) %&amp;gt;%
               top_n(1, ability) %&amp;gt;%
               select(-dob)
             team &amp;lt;- rbind(team, selected_player)
             
             #remove selected player from later choices
             bday_dat &amp;lt;- bday_dat %&amp;gt;%
               filter(!name %in% team$name)
           }
           
           #pick the last last player
           team &amp;lt;- bday_dat %&amp;gt;%
             filter(pos != &amp;quot;gk&amp;quot;) %&amp;gt;%
             top_n(1, ability) %&amp;gt;%
             select(-dob) %&amp;gt;%
             rbind(team, .)
           
           return(team)
  }, data = team_selection_dat)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can then plot the best teams by taking the mean of each teams positional ability and finding the top 10 teams. I then plotted these on half pitches using Ben Torvaney’s (mentoned in 2/2 posts so far…) &lt;a href=&#34;https://github.com/Torvaney/ggsoccer&#34;&gt;ggsoccer&lt;/a&gt; package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p4 &amp;lt;- best_teams %&amp;gt;%
  #work out total ability by team
  group_by(day, month) %&amp;gt;%
  mutate(team_ability = mean(ability)) %&amp;gt;%
  group_by(day, month, pos) %&amp;gt;%
  mutate(total_pos = n(), pos_n = 1:n()) %&amp;gt;%
  #calculate the x and y coordinates for each player on a pitch
  mutate(x = case_when(
    pos == &amp;quot;gk&amp;quot; ~ 5,
    pos == &amp;quot;def&amp;quot; ~ 22,
    pos == &amp;quot;mid&amp;quot; ~ 35,
    pos == &amp;quot;att&amp;quot; ~ 52
  )) %&amp;gt;%
  mutate(y = case_when(
    pos_n == 1 &amp;amp; total_pos == 2 ~ 20,
    pos_n == 2 ~ 60,
    TRUE ~ 40
  )) %&amp;gt;%
  ungroup() %&amp;gt;%
  select(-pos_n, -total_pos) %&amp;gt;%
  #take the 10 best teams
  top_n(50, team_ability) %&amp;gt;%
  #add in a column for the faceting
  mutate(dob = paste0(day, &amp;quot;/&amp;quot;, month, &amp;quot;: &amp;quot;, round(team_ability, 2))) %&amp;gt;%
  ggplot(aes(x = x, y = y)) +
  annotate_pitch(dimensions = pitch_statsbomb,
                 colour = &amp;quot;black&amp;quot;,
                 fill   = &amp;quot;white&amp;quot;,
                 limits = FALSE) +
  coord_flip(xlim = c(0, 60)) +
  geom_text(aes(
    label = gsub(&amp;quot;( )([A-Z])&amp;quot;, &amp;quot;\n\\2&amp;quot;, paste(name, version, sep = &amp;quot;-&amp;quot;)),
    colour = ability), size = 5.5) +
  scale_colour_gradient(low = &amp;quot;darkblue&amp;quot;, high = &amp;quot;red&amp;quot;, name = &amp;quot;player\n ability&amp;quot;) +
  labs(title = &amp;quot;Ten Best Birthday Teams&amp;quot;) +
  theme_pitch() +
  theme(strip.text.x = element_text(size = 14)) +
  facet_wrap(~dob) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/birthday_teams.svg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;All the top 10 teams have fairly similar total abilities- around 86-87. These best of which is an average of 87.51 for a team of
- 2006 Dida (GK)
- 2005 Sami Hyypia (Def)
- 2005 Gilberto Silva (Mid)
- 2005 Santiago Solari (Att)
- 2017 Diego Costa (Att)&lt;/p&gt;
&lt;p&gt;who all share a birthday on the 7th October. Many of the top teams we found earlier also show up, though surprisingly the 1st November which has players such as Neymar Jr., Christiano Ronaldo, Carlos Tevez, and Stefan De Vrij, doesn’t make the cut.&lt;/p&gt;
&lt;p&gt;That’s all for the second of these posts. The first one can be found &lt;a href=&#34;https://www.robert-hickman.eu/post/five_min_trivia_invincibles/&#34;&gt;here&lt;/a&gt;. Hopefully it provides some relief from the madness that is a complete lack of football. Stay safe, and wash your hands.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Five Minute Football Trivia - Invincibles</title>
      <link>/post/five_min_trivia_invincibles/</link>
      <pubDate>Sat, 07 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/five_min_trivia_invincibles/</guid>
      <description>


&lt;p&gt;&lt;em&gt;generally as I have less and less time to waste on meaningless football stats I get halfway through a post and abandon it. To remedy this, I want to start pushing out posts that give a reasonable half-guess at an answer within an hour or so without needing to really check my working or write good prose. This is the first of these&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Liverpool Football Club have had a pretty impressive season until recently, winning &lt;a href=&#34;https://www.google.com/search?client=firefox-b-d&amp;amp;q=premier+league+table#sie=lg;/g/11fj6snmjm;2;/m/02_tc;st;fp;1;;&#34;&gt;26 of the first 27 games&lt;/a&gt; and remaining unbeaten. Last weekend however, they lost &lt;a href=&#34;https://www.bbc.co.uk/sport/football/51595064&#34;&gt;3-0 to Watford&lt;/a&gt; which means that Arsenal remain the only team to have gone a full (modern) season of top flight English football unbeaten (in &lt;a href=&#34;https://en.wikipedia.org/wiki/The_Invincibles_(football)&#34;&gt;2003/2004&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Modern football twitter being what it is, a lot of debate has sprung up about which would be more impressive- going to whole season unbeaten like Arsenal, or winning 100 (out of a max 114) points in a single season, as Manchester City did in 2017-2018 and both Manchester City and Liverpool &lt;em&gt;almost&lt;/em&gt; did last season. (A third option also is the treble won by Manchester United in &lt;a href=&#34;https://en.wikipedia.org/wiki/1998%E2%80%9399_Manchester_United_F.C._season&#34;&gt;1998/1999&lt;/a&gt; but since Liverpool have also lost to Chelsea in the FA cup this week, that too remains unbeaten).&lt;/p&gt;
&lt;p&gt;As usual, first we need some libraries&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#munging
library(tidyverse)
#plotting
library(ggrepel)
#football data
library(engsoccerdata)
library(rvest)
#Ben Torvaney&amp;#39;s excellend package to model football
library(regista)

#set seed for reproducibility
set.seed(22081992)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we can get going loading up the data on English football results up until the end of the 2018/2019 season. We’ll also take some time to find the winners each season which will be useful later. There’s a lot of repetitive munging in this post so bear in mind the 3 main things we’ll be doing are:
+ pivoting data to longer to get the results for each team (not each match)
+ working out the goals for and against each team using case_when()
+ working out the points for each team using case_when()&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data &amp;lt;- engsoccerdata::england %&amp;gt;%
  #only care about the top flight in the premier league era
  dplyr::filter(Season &amp;gt; 1991 &amp;amp; Season &amp;lt; 2019 &amp;amp; division == 1) %&amp;gt;%
  select(season = Season, home, away = visitor, hgoal, agoal = vgoal)

league_winners &amp;lt;- data %&amp;gt;%
  #pivot data to longer to get team (rather than match) data
  pivot_longer(c(&amp;quot;home&amp;quot;, &amp;quot;away&amp;quot;), names_to = &amp;quot;location&amp;quot;, values_to = &amp;quot;team&amp;quot;) %&amp;gt;%
  #find goals for and goals against per team
  mutate(g_for = case_when(
    location == &amp;quot;home&amp;quot; ~ hgoal,
    location == &amp;quot;away&amp;quot; ~ agoal
  )) %&amp;gt;%
  mutate(g_ag = case_when(
    location == &amp;quot;home&amp;quot; ~ agoal,
    location == &amp;quot;away&amp;quot; ~ hgoal
  )) %&amp;gt;%
  #get the team&amp;#39;s points per match
  mutate(points = case_when(
    g_for &amp;gt; g_ag ~ 3,
    g_for == g_ag ~ 1,
    g_ag &amp;gt; g_for ~ 0
  )) %&amp;gt;%
  mutate(gd = g_for - g_ag) %&amp;gt;%
  group_by(team, season) %&amp;gt;%
  #calculate total points and goal difference
  summarise(total_points = sum(points),
            total_gd = sum(gd)) %&amp;gt;%
  #get the winners of each league season
  arrange(season, -total_points, -total_gd) %&amp;gt;%
  group_by(season) %&amp;gt;%
  mutate(league_position = 1:n()) %&amp;gt;%
  ungroup() %&amp;gt;%
  mutate(winner = case_when(
    league_position == 1 ~ &amp;quot;y&amp;quot;,
    TRUE ~ &amp;quot;n&amp;quot;
  ))

head(league_winners)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 6
##   team                season total_points total_gd league_position winner
##   &amp;lt;chr&amp;gt;                &amp;lt;int&amp;gt;        &amp;lt;dbl&amp;gt;    &amp;lt;int&amp;gt;           &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt; 
## 1 Manchester United     1992           84       36               1 y     
## 2 Aston Villa           1992           74       17               2 n     
## 3 Norwich City          1992           72       -4               3 n     
## 4 Blackburn Rovers      1992           71       22               4 n     
## 5 Queens Park Rangers   1992           63        8               5 n     
## 6 Liverpool             1992           59        7               6 n&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can then use the match data to calculate the offensive and defensive strength of each teams over the whole season using the &lt;a href=&#34;https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/1467-9876.00065&#34;&gt;Dixon-Coles method&lt;/a&gt;. I’ve previously written an introduction to this method &lt;a href=&#34;https://www.robert-hickman.eu/post/dixon_coles_1/&#34;&gt;here&lt;/a&gt; (which I need to finish part two of) but suffice to say it takes the goals scored and goals conceded per game and gives a good estimation of how good a team is. It’s similar in concept to &lt;a href=&#34;https://projects.fivethirtyeight.com/soccer-predictions/&#34;&gt;fivethirtyeight’s Soccer SPI&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#split data by seasons
fit_data &amp;lt;- data %&amp;gt;%
  split(f = .$season) %&amp;gt;%
  lapply(., function(x) x %&amp;gt;% mutate(home = factor(home), away = factor(away)))

#model using dixoncoles() from the regista package
fits &amp;lt;- lapply(fit_data, function(x) dixoncoles(hgoal, agoal, home, away, x))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can then extract the parameters from this model to see how teams have performed in each season of the Premier League. I also flip the defence axis (higher being a better defence) as I think it makes a little more sense&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;parameters &amp;lt;- fits %&amp;gt;%
  #extract the team parameters per fit
  lapply(., function(f) {
    par_data &amp;lt;- f$par[grepl(&amp;quot;def_|off_&amp;quot;, names(f$par))]
    teams &amp;lt;- unique(gsub(&amp;quot;def_*|off_*&amp;quot;, &amp;quot;&amp;quot;, names(par_data)))
    par_df &amp;lt;- matrix(par_data, ncol = 2) %&amp;gt;%
      as.data.frame() %&amp;gt;%
      rename(attack = V1, defence = V2)
    rownames(par_df) &amp;lt;- teams
    return(par_df)
  }) %&amp;gt;%
  do.call(rbind, .) %&amp;gt;%
  rownames_to_column() %&amp;gt;%
  separate(rowname, c(&amp;quot;season&amp;quot;, &amp;quot;team&amp;quot;), sep = &amp;quot;\\.&amp;quot;) %&amp;gt;%
  mutate(season = as.numeric(season)) %&amp;gt;%
  #flip the defence parameter (higher = better)
  mutate(defence = defence * -1) %&amp;gt;%
  left_join(., league_winners, by = c(&amp;quot;season&amp;quot;, &amp;quot;team&amp;quot;))

#plot the parameters with season performance (points) as the colour
p1 &amp;lt;- parameters %&amp;gt;%
  ggplot(aes(x = attack, y = defence, fill = total_points, colour = winner)) +
  geom_point(shape = 21, size = 3, alpha = 0.7, stroke = 2) +
  #label exceptional teams
  geom_text_repel(data = filter(parameters, winner == 1 | attack + defence &amp;gt; 1),
            aes(label = paste(team, season))) +
  labs(title = &amp;quot;Dixon Coles parameters per team per Premier League Season&amp;quot;,
       subtitle = &amp;quot;league winners and exceptional teams labelled&amp;quot;,
       x = &amp;quot;attacking strength&amp;quot;,
       y = &amp;quot;defensive strength&amp;quot;) +
  scale_colour_manual(values = c(&amp;quot;blue&amp;quot;, &amp;quot;red&amp;quot;)) +
  theme_minimal()

p1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-04-invincibles_files/figure-html/get_dc_parameters-1.png&#34; width=&#34;1152&#34; /&gt;
We can then use these parameters as ‘true estimates’ of how good each team was each season, and go back and simulate results from each match to work out how likely a win/lose/draw for any team was in any match. This is questionably a good idea but as I said up top, this is stream of consciousness first-guesses at answering stupid trivia questions so I’m going to go along with it.&lt;/p&gt;
&lt;p&gt;The regista package’s augment.dixoncoles easily gives us the chance of a win/lose/draw per match based on the attacking/defensive strength of each team (see above) that season&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#split the matches by season
matches &amp;lt;- data %&amp;gt;%
  select(season, home, away) %&amp;gt;%
  split(f = .$season)

#function to predict the results per match
predict_matches &amp;lt;- function(dc_fit, fixtures) {
  augment.dixoncoles(x = dc_fit, newdata = fixtures, type = &amp;quot;outcomes&amp;quot;) %&amp;gt;% 
    unnest() %&amp;gt;%
    spread(outcome, prob)
}

#run the prediction function
predictions &amp;lt;- map2_df(fits, matches,
                       predict_matches)

head(predictions)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 6
##   season home    away             away_win  draw home_win
##    &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;               &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
## 1   1992 Arsenal Aston Villa         0.294 0.379    0.327
## 2   1992 Arsenal Blackburn Rovers    0.319 0.344    0.337
## 3   1992 Arsenal Chelsea             0.220 0.342    0.437
## 4   1992 Arsenal Coventry City       0.214 0.333    0.454
## 5   1992 Arsenal Crystal Palace      0.188 0.322    0.490
## 6   1992 Arsenal Everton             0.223 0.338    0.439&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So e.g. based on Dixon-Coles estimates, given how well Arsenal and Aston Villa did over the &lt;em&gt;whole&lt;/em&gt; of the 1992/1993 season, Arsenal had a 32.6% chance of beating Aston Villa at home on the opening day of the season.&lt;/p&gt;
&lt;p&gt;We can then use these probability estimates to calculate the chance of any one team going unbeaten over the whole league (multiply out the probabilities of not losing each game)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;invincible_chance &amp;lt;- predictions %&amp;gt;%
  #get match predictions per team
  pivot_longer(c(&amp;quot;home&amp;quot;, &amp;quot;away&amp;quot;), names_to = &amp;quot;location&amp;quot;, values_to = &amp;quot;team&amp;quot;) %&amp;gt;%
  mutate(nonloss_chance = case_when(
    location == &amp;quot;home&amp;quot; ~ 1 - away_win,
    location == &amp;quot;away&amp;quot; ~ 1 - home_win
  )) %&amp;gt;%
  select(season, team, nonloss_chance) %&amp;gt;%
  group_by(team, season) %&amp;gt;%
  #chance of going invincible = product sum of chance of not drawing
  summarise(invincible_chance = prod(nonloss_chance)) %&amp;gt;%
  arrange(-invincible_chance)

head(invincible_chance, n = 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10 x 3
## # Groups:   team [6]
##    team              season invincible_chance
##    &amp;lt;chr&amp;gt;              &amp;lt;int&amp;gt;             &amp;lt;dbl&amp;gt;
##  1 Chelsea             2004           0.0494 
##  2 Manchester City     2017           0.0362 
##  3 Manchester City     2018           0.0286 
##  4 Liverpool           2018           0.0232 
##  5 Arsenal             1998           0.0164 
##  6 Manchester City     2011           0.0124 
##  7 Manchester United   2007           0.0123 
##  8 Tottenham Hotspur   2016           0.00846
##  9 Arsenal             2003           0.00529
## 10 Chelsea             2009           0.00475&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So it turns out that the team most likely to have gone invincible over a whole season was Chelsea in 2004/2005 (not surprising given their &lt;a href=&#34;https://en.wikipedia.org/wiki/2004%E2%80%9305_Chelsea_F.C._season#Results_by_round&#34;&gt;excellent defensive record that year&lt;/a&gt;), but with only a ~5% chance.&lt;/p&gt;
&lt;p&gt;Arsenal’s &lt;em&gt;actual&lt;/em&gt; invincible year is estimated that have had a 0.05% chance based on the team’s results (surprisingly low!). Another notable team is Tottenham Hotspur who only finished 2nd in 2016/2017 but perhaps went under the radar as a very good team that year (with a 0.08% chance of finishing unbeaten).&lt;/p&gt;
&lt;p&gt;So we can assume* that the very best ‘unbeatable’ teams have ~5% chance of finishing a season invincible. We can use this baseline to see how hard this seems compared to the expectation a team gets 100 points.&lt;/p&gt;
&lt;p&gt;*not really, but for this post yes&lt;/p&gt;
&lt;p&gt;We’re going to simulate every Premier League season 1000 times and calculate the total points expected of a team based on their Dixon-Coles parameters. To narrow down the search a bit, I’m going to limit it to only exceptional teams with an attack and defence parameter &amp;gt; 0.25 (which gives 33 season-teams).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;result_probs &amp;lt;- predictions %&amp;gt;%
  #pivoting and case_when to get result probabilities per team
  pivot_longer(c(&amp;quot;home&amp;quot;, &amp;quot;away&amp;quot;), names_to = &amp;quot;location&amp;quot;, values_to = &amp;quot;team&amp;quot;) %&amp;gt;%
  mutate(win = case_when(
    location == &amp;quot;home&amp;quot; ~ home_win,
    location == &amp;quot;away&amp;quot; ~ away_win
  )) %&amp;gt;%
  mutate(lose = 1 - draw - win) %&amp;gt;%
  select(season, team, win, lose, draw) %&amp;gt;%
  group_by(team, season) %&amp;gt;%
  mutate(game = 1:n()) %&amp;gt;%
  nest(probs = c(win, lose, draw))

#filter down to only the very best teams to save processing
selected_teams &amp;lt;- parameters %&amp;gt;%
  filter(attack &amp;gt; 0.25 &amp;amp; defence &amp;gt; 0.25) %&amp;gt;%
  select(season, team) %&amp;gt;%
  left_join(., result_probs, by = c(&amp;quot;team&amp;quot;, &amp;quot;season&amp;quot;))

sim_result &amp;lt;- function(probabilities) {
  chosen_results &amp;lt;- gather(probabilities) %&amp;gt;%
    sample_n(., 1, weight = value)
  result &amp;lt;- chosen_results$key
}

simulate_all_games &amp;lt;- function(data) {
  data$result &amp;lt;- unlist(lapply(data$probs, sim_result))
  return(data)
}

#will simulate 1000 seasons for each of these teams
n_sims &amp;lt;- 1000

#run simulations - will take ~10mins
simulated_results &amp;lt;- rerun(n_sims, simulate_all_games(selected_teams))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Calculating the total points won per season, we can work out the percentage of simulations in which each team exceed 100 points quite easily&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;simulated_points &amp;lt;- simulated_results %&amp;gt;%
  #for each sim, get the points won by each team
  lapply(., function(data) {
    data &amp;lt;- data %&amp;gt;%
      mutate(points = case_when(
        result == &amp;quot;win&amp;quot; ~ 3,
        result == &amp;quot;draw&amp;quot; ~ 1,
        result == &amp;quot;lose&amp;quot; ~ 0
      )) %&amp;gt;%
      group_by(season, team) %&amp;gt;%
      mutate(total_points = sum(points)) %&amp;gt;%
      select(season, team, total_points) %&amp;gt;%
      unique()
  }) %&amp;gt;%
  do.call(rbind, .)

#probability of reaching 100 points is no. of sims &amp;gt; 100 points / n_sims
centurion_probs &amp;lt;- simulated_points %&amp;gt;%
  filter(total_points &amp;gt; 99) %&amp;gt;%
  group_by(season, team) %&amp;gt;%
  summarise(centurion_prob = n() / n_sims) %&amp;gt;%
  arrange(-centurion_prob)

print(centurion_probs)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 27 x 3
## # Groups:   season [16]
##    season team              centurion_prob
##     &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;                      &amp;lt;dbl&amp;gt;
##  1   2017 Manchester City            0.17 
##  2   2018 Manchester City            0.107
##  3   2018 Liverpool                  0.076
##  4   1994 Manchester United          0.069
##  5   2004 Chelsea                    0.046
##  6   2009 Chelsea                    0.039
##  7   2011 Manchester City            0.029
##  8   2007 Manchester United          0.023
##  9   2016 Tottenham Hotspur          0.023
## 10   2006 Manchester United          0.011
## # … with 17 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As expected, the two recent Manchester City teams come top, with the one that actually did reach 100 points (2017) given a 14.5% chance of reaching that milestone, given their strength.&lt;/p&gt;
&lt;p&gt;So now we have a baseline that the best team at accumulating points (Manchester City 2017/2018) has ~3x as much chance of winning 100 points in that season than the very best (potentially) invincible team (Chelsea 2004/2005). I.e. we have some (not super strong) evidence that it is ~3x as hard to go a season unbeaten than it is to become a ‘centurion’.&lt;/p&gt;
&lt;p&gt;We can calculate how many points our threshold needs to be set at to have an equal chance using top_frac() on our 1000 simulations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#find the points threshold for Man City 2017 that would reach n points 
#as often as Chelsea 2004 would go unbeaten
invincible_equivalent &amp;lt;- simulated_points %&amp;gt;%
  ungroup() %&amp;gt;%
  filter(season == 2017 &amp;amp; team == &amp;quot;Manchester City&amp;quot;) %&amp;gt;%
  top_frac(max(invincible_chance$invincible_chance)) %&amp;gt;%
  arrange(total_points)

#print the lowest threshold
head(invincible_equivalent, n = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 3
##   season team            total_points
##    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;                  &amp;lt;dbl&amp;gt;
## 1   2017 Manchester City          103&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So we might presume that the equivalent achievement to going the season unbeaten is to win 103 points in the Premier League. To see how the 2017/2018 Manchester City team compare to this we can plot the expected final points total of that season (given league team strengths) in a histogram:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p2 &amp;lt;-  simulated_points %&amp;gt;%
  ungroup() %&amp;gt;%
  filter(season == 2017 &amp;amp; team == &amp;quot;Manchester City&amp;quot;) %&amp;gt;%
  ggplot(., aes(x = total_points)) +
  geom_histogram(fill = &amp;quot;skyblue&amp;quot;, alpha = 0.7) +
  #invincle equivalent achievement in red
  geom_vline(xintercept = min(invincible_equivalent$total_points),
             colour = &amp;quot;red&amp;quot;, linetype = &amp;quot;dashed&amp;quot;, size = 2) +
  #actual achievement in blue
  geom_vline(xintercept = filter(league_winners, season == 2017 &amp;amp; league_position == 1)$total_points,
             colour = &amp;quot;blue&amp;quot;, linetype = &amp;quot;dashed&amp;quot;, size = 2) +
  labs(title = &amp;quot;Man C. expected 2017/2018 performance c.f. invincible equivalent threshold&amp;quot;,
       subtitle = &amp;quot;invincible equivalent achievement = 103 points, actual = 100 points&amp;quot;,
       x = &amp;quot;season expected total points&amp;quot;,
       y = paste(&amp;quot;times achieved over&amp;quot;, n_sims, &amp;quot;simulations&amp;quot;)) +
  theme_minimal()

p2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-04-invincibles_files/figure-html/plot_threshold-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The original question was really if this years Liverpool team might achieve this 103 point threshold (given they have now failed to go unbeaten). We can test this by doing exactly the same procedure on their season so far.&lt;/p&gt;
&lt;p&gt;First we need to download all the match data from fbref. Handily, fbref doesn’t just gives us the goals scored per match but the &lt;a href=&#34;https://fbref.com/en/expected-goals-model-explained/&#34;&gt;&lt;em&gt;expected goals&lt;/em&gt;&lt;/a&gt; each team managed to put up. We’re going to use that to model team strengths as we might assume* this is a better measure of how good a team really is. In order to fit the model using the regista package I need to supply an integer, so I’ve simply rounded those xG numbers to the nearest whole number**&lt;/p&gt;
&lt;p&gt;*lets ignore game state and other such important thing- this is &lt;em&gt;five minute&lt;/em&gt; football trivia
**you actually can use expected goals in a regista::dixoncoles model, see &lt;a href=&#34;https://www.robert-hickman.eu/post/wsl-prediction-1/&#34;&gt;here&lt;/a&gt;, but this is &lt;em&gt;five minute&lt;/em&gt; football trivia&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#download the match data from 2019/2020
fixtures_2020 &amp;lt;- &amp;quot;https://fbref.com/en/comps/9/schedule/Premier-League-Fixtures&amp;quot; %&amp;gt;%
  read_html() %&amp;gt;%
  html_nodes(&amp;quot;#sched_ks_3232_1&amp;quot;) %&amp;gt;%
  html_table() %&amp;gt;%
  as.data.frame() %&amp;gt;%
  separate(Score, into = c(&amp;quot;hgoal&amp;quot;, &amp;quot;agoal&amp;quot;), sep = &amp;quot;–&amp;quot;) %&amp;gt;%
  #only care about goals and expected goals
  select(home = Home, away = Away, home_xg = xG, away_xg = xG.1, hgoal, agoal) %&amp;gt;%
  filter(home != &amp;quot;&amp;quot;) %&amp;gt;%
  mutate(home = factor(home), away = factor(away)) %&amp;gt;%
  #round expected goals to nearest integer
  mutate_at(c(&amp;quot;home_xg&amp;quot;, &amp;quot;away_xg&amp;quot;, &amp;quot;hgoal&amp;quot;, &amp;quot;agoal&amp;quot;), .funs = funs(round(as.numeric(.))))

#matches with a known result
#used for modelling
played_matches &amp;lt;- fixtures_2020 %&amp;gt;%
  filter(!is.na(home_xg))

#matches with an unknown result
#used for simulation
unplayed_matches &amp;lt;- fixtures_2020 %&amp;gt;%
  filter(is.na(home_xg)) %&amp;gt;%
  select_if(negate(is.numeric))

#fit the dixon coles model
fit_2020 &amp;lt;- dixoncoles(home_xg, away_xg, home, away, data = played_matches)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And as before we can plot the team strength in attacking and defending dimensions&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#extract parameters from the model
pars_2020 &amp;lt;- fit_2020$par %&amp;gt;%
  .[grepl(&amp;quot;def_|off_&amp;quot;, names(.))] %&amp;gt;%
  matrix(., ncol = 2) %&amp;gt;%
  as.data.frame() %&amp;gt;%
  rename(attack = V1, defence = V2)
pars_2020$team &amp;lt;- unique(gsub(&amp;quot;def_*|off_*&amp;quot;, &amp;quot;&amp;quot;, names(fit_2020$par)))[1:20]

#plot as before
p3 &amp;lt;- pars_2020 %&amp;gt;%
  mutate(defence = 1 - defence) %&amp;gt;%
  ggplot(aes(x = attack, y = defence, colour = attack + defence, label = team)) +
  geom_point(size = 3, alpha = 0.7) +
  geom_text_repel() +
  labs(title = &amp;quot;Dixon Coles parameters per team 2019/2020&amp;quot;,
       x = &amp;quot;attacking strength&amp;quot;,
       y = &amp;quot;defensive strength&amp;quot;) +
  scale_colour_continuous(guide = FALSE) +
  labs(title = &amp;quot;Dixon Coles parameters per team for the 2019/2020 Premier League Season&amp;quot;,
       x = &amp;quot;attacking strength&amp;quot;,
       y = &amp;quot;defensive strength&amp;quot;) +
  theme_minimal()

p3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-04-invincibles_files/figure-html/2020_dc_parameters-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Surprisingly, a distant 2nd place Manchester City actually rate higher than Liverpool using this model, and Manchester United (by all accounts having a very middling season) aren’t far off either.&lt;/p&gt;
&lt;p&gt;Now we just need to simulate the remaining games of Liverpool’s season to see how likely they are to hit are 103 points target. We can then add the points we expect Liverpool to win to the number of points we know they already have to get an estimate of final total points.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#calculate points we know Liverpool have
liverpool_points &amp;lt;- played_matches %&amp;gt;%
  filter(home == &amp;quot;Liverpool&amp;quot; | away == &amp;quot;Liverpool&amp;quot;) %&amp;gt;%
  mutate(points = case_when(
    hgoal == agoal ~ 1,
    home == &amp;quot;Liverpool&amp;quot; &amp;amp; (hgoal &amp;gt; agoal) ~ 3,
    away == &amp;quot;Liverpool&amp;quot; &amp;amp; (agoal &amp;gt; hgoal) ~ 3,
    TRUE ~ 0
  )) %&amp;gt;%
  summarise(total_points = sum(points))

#estimate the chance of results in all remaining games
unplayed_results &amp;lt;-
  augment.dixoncoles(fit_2020, unplayed_matches, type.predict = &amp;quot;outcomes&amp;quot;) %&amp;gt;%
  unnest() %&amp;gt;%
  #filter out the liverpool ones
  filter(home == &amp;quot;Liverpool&amp;quot; | away == &amp;quot;Liverpool&amp;quot;)

#function to simulate a season by making weighted samples
simulate_season &amp;lt;- function(result_probabilities) {
  result_probabilities %&amp;gt;%
    nest(outcome, prob, .key = &amp;quot;results&amp;quot;) %&amp;gt;%
    mutate(sampled = map(results, ~ sample_n(., 1, weight = prob))) %&amp;gt;%
    select(-results) %&amp;gt;%
    unnest()
}

#simulate the rest of liverpool&amp;#39;s season
liverpool_2020_simulated &amp;lt;- rerun(n_sims, simulate_season(unplayed_results)) %&amp;gt;%
  bind_rows(.id = &amp;quot;simulation_id&amp;quot;) %&amp;gt;%
  #find the sampled points won per game
  mutate(points = case_when(
    home == &amp;quot;Liverpool&amp;quot; &amp;amp; outcome == &amp;quot;home_win&amp;quot; ~ 3,
    away == &amp;quot;Liverpool&amp;quot; &amp;amp; outcome == &amp;quot;away_win&amp;quot; ~ 3,
    outcome == &amp;quot;draw&amp;quot; ~ 1,
    TRUE ~ 0
  )) %&amp;gt;%
  group_by(simulation_id) %&amp;gt;%
  #calculate Liverpool&amp;#39;s total season points for this simulation
  summarise(total_points = sum(points) + as.numeric(liverpool_points))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It’s then very easy to find the fraction of sims in which Liverpool break this 103 point challenge&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;length(which(liverpool_2020_simulated$total_points &amp;gt; 102)) / 1000&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.157&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we can plot it as before to see how many points we expect Liverpool to win this season:
(this time the 103 point threshold is in blue to stand out against the red that Liverpool play in)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p4 &amp;lt;- liverpool_2020_simulated %&amp;gt;%
  ggplot(., aes(x = total_points)) +
  geom_histogram(fill = &amp;quot;red&amp;quot;, alpha = 0.7) +
  #invincle equivalent achievement in red
  geom_vline(xintercept = min(invincible_equivalent$total_points),
             colour = &amp;quot;blue&amp;quot;, linetype = &amp;quot;dashed&amp;quot;, size = 2) +
  labs(title = &amp;quot;Liverpool&amp;#39;s expected 2019/2020 performance c.f. invincible equivalent threshold&amp;quot;,
       subtitle = &amp;quot;invincible equivalent achievement = 103 points in blue this time&amp;quot;,
       x = &amp;quot;season expected total points&amp;quot;,
       y = paste(&amp;quot;times achieved over&amp;quot;, n_sims, &amp;quot;simulations&amp;quot;)) +
  theme_minimal()

p4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-04-invincibles_files/figure-html/plot_liverpool_expectation-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Anyway, that’s that for the first of these (hopefully? of many!). Did we learn anything? probably not. But did we at least do something interesting? also probably not. But I do like doing these silly little analyses in my spare time and by not limiting myself to things like rigor, I can pump them out faster. I’ll probably aim for one post (smaller than this) a week to start building a little bit of a public portfolio up again (I’m unemployed in 5 months- hire me!!). Hope you enjoyed reading it :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Advent Calendar of Football Trivia Analyses</title>
      <link>/post/advent_calendar_trivia/</link>
      <pubDate>Sun, 01 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/advent_calendar_trivia/</guid>
      <description>


&lt;p&gt;One of the most consistent &lt;a href=&#34;https://www.robert-hickman.eu/project/guardian_knowledge/&#34;&gt;fonts of posts on this blog&lt;/a&gt; is The Guardian’s football trivia page &lt;a href=&#34;https://www.theguardian.com/football/series/theknowledge&#34;&gt;The Knowledge&lt;/a&gt;. A particular reason for this is that the small contained questions lend themselves to small blogposts that I can turn around in an hour or two, as opposed to being endlessly redrafted until I lose interest.&lt;/p&gt;
&lt;p&gt;However, I still sometimes don’t quite get round to finishing some of these posts, or have trouble justifying a blog post on a very small and ‘trivial’ answer to a question. Therefore, as a sort of end-of-year round up, and a Christmas present to myself, I wanted to push out answers to questions I found particularly interesting over the last year and hadn’t quite got round to &lt;sup&gt;1&lt;/sup&gt;. I’ll probably add them all to this post as I finish them up.&lt;/p&gt;
&lt;div id=&#34;nd-december---everything-in-its-right-place&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;2nd December - Everything in its right place&lt;/h1&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
I wonder if any of any sporting leagues have ever ended in alphabetical order? &lt;a href=&#34;https://t.co/you6u8Uzwz&#34;&gt;pic.twitter.com/you6u8Uzwz&lt;/a&gt;
&lt;/p&gt;
— P A Hunt (&lt;span class=&#34;citation&#34;&gt;@TeachFMaths&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/TeachFMaths/status/1139832761295024128?ref_src=twsrc%5Etfw&#34;&gt;June 15, 2019&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;div id=&#34;answer---yes-kind-of.-but-also-no.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Answer - yes, kind of. But also no.&lt;/h2&gt;
&lt;p&gt;This question has actually &lt;a href=&#34;https://www.theguardian.com/football/2011/mar/09/has-league-ever-finished-alphabetical-order&#34;&gt;been answered&lt;/a&gt; (as many of these will have been). For a league of 20 teams (like the English Premier League), we might imagine if would have happened over the last ~150 years, but it’s almost certain from some basic maths that it won’t have, and moreover, will never happen.&lt;/p&gt;
&lt;p&gt;Let’s load some data and see why.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#as per usual, going to heavily rely on tidyverse 
#and engsoccerdata throughout these posts
library(tidyverse)
library(engsoccerdata)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#load English league data
league_data &amp;lt;- engsoccerdata::england %&amp;gt;%
  #select and gather match results
  select(season = Season, division, home, visitor, hgoal, vgoal) %&amp;gt;%
  gather(&amp;quot;location&amp;quot;, &amp;quot;team&amp;quot;, -season, -division, -hgoal, -vgoal) %&amp;gt;%
  mutate(
    g_for = case_when(
      location == &amp;quot;home&amp;quot; ~ hgoal,
      location == &amp;quot;visitor&amp;quot; ~ vgoal
    ),
    g_ag = case_when(
      location == &amp;quot;home&amp;quot; ~ vgoal,
      location == &amp;quot;visitor&amp;quot; ~ hgoal
    )) %&amp;gt;%
  #get correct point for a win/loss
  mutate(
    points = case_when(
      g_for &amp;gt; g_ag &amp;amp; season &amp;lt; 1981 ~ 2,
      g_for &amp;gt; g_ag &amp;amp; season &amp;gt; 1980 ~ 3,
      g_for == g_ag ~ 1,
      g_for &amp;lt; g_ag ~ 0
    ),
    gd = g_for - g_ag
  ) %&amp;gt;%
  #group by season and league and get final tables
  group_by(season, division, team) %&amp;gt;%
  summarise(points = sum(points),
            gd = sum(gd),
            g_for = sum(g_for)) %&amp;gt;%
  arrange(-points, -gd, -g_for) %&amp;gt;%
  #rank league order and alphabetical order
  mutate(league_pos = rank(-points, ties.method = &amp;quot;first&amp;quot;),
         alph_order = rank(team, ties.method = &amp;quot;first&amp;quot;)) %&amp;gt;%
  select(season, division, team, league_pos, alph_order) %&amp;gt;%
  #split by league and season
  split(., f = list(.$season, .$division)) %&amp;gt;%
  keep(function(x) nrow(x) &amp;gt; 0)

#print the top of the first league table
head(league_data[[1]])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 5
## # Groups:   season, division [1]
##   season division team                    league_pos alph_order
##    &amp;lt;int&amp;gt;    &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;                        &amp;lt;int&amp;gt;      &amp;lt;int&amp;gt;
## 1   1888        1 Preston North End                1          9
## 2   1888        1 Aston Villa                      2          2
## 3   1888        1 Wolverhampton Wanderers          3         12
## 4   1888        1 Blackburn Rovers                 4          3
## 5   1888        1 Bolton Wanderers                 5          4
## 6   1888        1 West Bromwich Albion             6         11&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can then run a load of Spearman’s rank correlation tests on the data to see which ones are perfectly correlated or anti-correlated in both league and alphabetical ranking. We’ll use the very handy &lt;a href=&#34;https://cran.r-project.org/web/packages/broom/vignettes/broom.html&#34;&gt;broom&lt;/a&gt; package to tidy the results of our many tests into one data.frame (remove the filter at the end of the pipe chain to see what gets output).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#use broom to tidily do stats
library(broom)

#correlate league and alphabetical order by year
exact_correlations &amp;lt;- league_data %&amp;gt;%
  map_df(., function(data) {
    cor.test(
      data$league_pos,
      data$alph_order,
      method = &amp;quot;spearman&amp;quot;
    ) %&amp;gt;%
      tidy() %&amp;gt;%
      mutate(season = unique(data$season),
             division = unique(data$division))
  }) %&amp;gt;%
  #take only significantly 
  filter(abs(statistic) == 1)

print(exact_correlations)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 0 x 7
## # ... with 7 variables: estimate &amp;lt;dbl&amp;gt;, statistic &amp;lt;dbl&amp;gt;, p.value &amp;lt;dbl&amp;gt;,
## #   method &amp;lt;chr&amp;gt;, alternative &amp;lt;chr&amp;gt;, season &amp;lt;int&amp;gt;, division &amp;lt;int&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And so we find no exact correlations. There are no instances in 363 separate seasons of English league football where teams line up in either alphabetical, or anti-alphabetical order.&lt;/p&gt;
&lt;p&gt;Let’s see why this is. To make things simpler, I’m going to imagine a cutdown league of only 6 teams using teams starting with each of the first 6 letter of the alphabet:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;first_letter_names &amp;lt;- league_data %&amp;gt;%
  bind_rows() %&amp;gt;%
  ungroup() %&amp;gt;%
  #get first letter of a team name
  mutate(first_letter = gsub(&amp;quot;(^.)(.*)&amp;quot;, &amp;quot;\\1&amp;quot;, team)) %&amp;gt;%
  filter(season &amp;gt; 1992 &amp;amp;
           division == 1 &amp;amp;
           first_letter %in% toupper(letters[1:6])
         ) %&amp;gt;%
  #get one team beginning with A, B, C...
  filter(!duplicated(first_letter)) %&amp;gt;%
  select(team) %&amp;gt;%
  arrange(team) %&amp;gt;%
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 1
##   team            
##   &amp;lt;chr&amp;gt;           
## 1 Arsenal         
## 2 Blackburn Rovers
## 3 Coventry City   
## 4 Derby County    
## 5 Everton         
## 6 Fulham&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the league to finish in alphabetical order, we first need the team that is first alphabetically (Arsenal) to finish in first position. Assuming all teams have an equal chance of winning the league, the chance of this is obviously&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ p(Arsenal = 1) =  \frac{1}{n}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Then we need the second team (Blackburn Rovers), to finish in second. This is predicated on Arsenal already finishing in first position, so the chance becomes&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ p(Blackburn = 2 | Arsenal = 1) = \frac{1}{n-1} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and so on until the last team (Fulham) just have to slot into the only position left (n, 6th in our example)&lt;/p&gt;
&lt;p&gt;Thus the total chance becomes&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \frac{1}{n} \cdot \frac{1}{n-1} ... \cdot \frac{1}{1} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;which can also be written&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ p(ordered) = \prod_{n = 1}^{N} \frac{1}{n}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;which multiplies out to&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ p(ordered) = \frac{1}{n!} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;so for our very small league the chance of n (assumed equally strong teams)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;factorial(nrow(first_letter_names))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 720&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;so we have a 1/720 chance that this league ends perfectly in alphabetical order. For bigger leagues (for reference most large European leagues contain 18-24 teams) this denominator grows &lt;em&gt;super-exponentially&lt;/em&gt; and becomes tiny.&lt;/p&gt;
&lt;p&gt;For the English Premier League (20 teams) for instance the chance becomes&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;league_data %&amp;gt;%
  bind_rows() %&amp;gt;%
  ungroup() %&amp;gt;%
  filter(season == max(season) &amp;amp; division == 1) %&amp;gt;% 
  nrow() %&amp;gt;%
  factorial()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2.432902e+18&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or 1 in 2.4 &lt;a href=&#34;https://en.wikipedia.org/wiki/Order_of_magnitude&#34;&gt;quintillion&lt;/a&gt;. In short, if it’s assumed that there’s no relation between order of names and team strength, we might expect the universe to end before all 20 teams finish in perfect order.&lt;/p&gt;
&lt;p&gt;We can test if our predictions bear out by looking at tiny leagues with small numbers of teams, e.g. &lt;a href=&#34;https://en.wikipedia.org/wiki/2018%E2%80%9319_UEFA_Champions_League_group_stage&#34;&gt;the group stages of the Champions/Europa Leagues&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;First we need to scrape the final tables for the last 8 years of data from both competitions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rvest)

#website to scrape group stage data from
fb_data &amp;lt;- &amp;quot;https://footballdatabase.com&amp;quot;
ucl_links &amp;lt;- sprintf(
  &amp;quot;/league-scores-tables/uefa-champions-league-20%s-%s&amp;quot;,
  10:18, 11:19
)
europa_links &amp;lt;- sprintf(
  &amp;quot;/league-scores-tables/uefa-europa-league-20%s-%s&amp;quot;,
  10:18, 11:19
)
#function to scrape the data from these links
get_competition_data &amp;lt;- function(competition, links) {
  data &amp;lt;- links %&amp;gt;%
    paste0(fb_data, .) %&amp;gt;%
    map_df(., function(year) {
      page_read &amp;lt;- read_html(year)
      
      groups &amp;lt;- letters[1:8] %&amp;gt;%
        map_df(., function(group) {
          page_read %&amp;gt;% 
            html_nodes(sprintf(&amp;quot;#total-group-%s &amp;gt; div &amp;gt; table&amp;quot;, group)) %&amp;gt;% 
            html_table(fill = TRUE) %&amp;gt;% 
            as.data.frame() %&amp;gt;%
            mutate(group)
        }) %&amp;gt;%
        mutate(year = gsub(&amp;quot;(.*-)([0-9]{4}-[0-9]{2})&amp;quot;, &amp;quot;\\2&amp;quot;, year))
    }) %&amp;gt;%
    mutate(competition)
}
#scrape and bind the data
uefa_data &amp;lt;- bind_rows(
  get_competition_data(&amp;quot;champions&amp;quot;, ucl_links),
  get_competition_data(&amp;quot;europa&amp;quot;, europa_links)
)
#print a cutdown version of the scraped data
head(uefa_data %&amp;gt;% select(club = Club, points = P, year, competition))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                club points    year competition
## 1 Tottenham Hotspur     11 2010-11   champions
## 2       Inter Milan     10 2010-11   champions
## 3         FC Twente      6 2010-11   champions
## 4     Werder Bremen      5 2010-11   champions
## 5        Schalke 04     13 2010-11   champions
## 6              Lyon     10 2010-11   champions&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So now we have 128 (8 groups x 8 years x 2 competitions) ‘mini-leagues’ each of 4 teams.&lt;/p&gt;
&lt;p&gt;We can then munge this data to find all the groups where the teams finish in alphabetical order. We’d expect 128/4! leagues to finish in alphabetical order (or 5.33 to be exact).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ordered_groups &amp;lt;- uefa_data %&amp;gt;%
  #select relevant informatiob
  select(team = Club, league_pos = X., group, year, competition) %&amp;gt;%
  #by group find where teams finish in alphabetical order
  group_by(year, group, competition) %&amp;gt;%
  mutate(alph_order = rank(team, ties.method = &amp;quot;first&amp;quot;)) %&amp;gt;%
  filter(league_pos == alph_order) %&amp;gt;%
  #keep only group where all (4) teams finish in order
  summarise(n = n()) %&amp;gt;%
  filter(n == 4) %&amp;gt;%
  #join and filter back data
  left_join(uefa_data, ., by = c(&amp;quot;group&amp;quot;, &amp;quot;year&amp;quot;, &amp;quot;competition&amp;quot;)) %&amp;gt;%
  filter(!is.na(n)) %&amp;gt;%
  #select useful information
  select(team = Club, points = P, gd = X..., league_pos = X.,
         group, year, competition) %&amp;gt;%
  #split groups up
  split(., list(.$year, .$group, .$competition)) %&amp;gt;%
  keep(function(x) nrow(x) &amp;gt; 0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which leaves us with 5 leagues that have finished in order! almost exactly what we’d predict by chance if the first letter of a teams name had no effect on the outcome.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ordered_groups&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $`2011-12.c.champions`
##                team points gd league_pos group    year competition
## 5           Benfica     12  4          1     c 2011-12   champions
## 6          FC Basel     11  1          2     c 2011-12   champions
## 7 Manchester United      9  3          3     c 2011-12   champions
## 8     Otelul Galati      0 -8          4     c 2011-12   champions
## 
## $`2015-16.c.champions`
##                team points gd league_pos group    year competition
## 9   Atlético Madrid     13  8          1     c 2015-16   champions
## 10          Benfica     10  2          2     c 2015-16   champions
## 11      Galatasaray      5 -4          3     c 2015-16   champions
## 12 Lokomotiv Astana      4 -6          4     c 2015-16   champions
## 
## $`2010-11.f.champions`
##             team points  gd league_pos group    year competition
## 1     Chelsea FC     15  10          1     f 2010-11   champions
## 2      Marseille     12   9          2     f 2010-11   champions
## 3 Spartak Moskva      9  -3          3     f 2010-11   champions
## 4         Žilina      0 -16          4     f 2010-11   champions
## 
## $`2015-16.g.champions`
##                   team points  gd league_pos group    year competition
## 13          Chelsea FC     13  10          1     g 2015-16   champions
## 14         Dynamo Kyiv     11   4          2     g 2015-16   champions
## 15            FC Porto     10   1          3     g 2015-16   champions
## 16 Maccabi Tel Aviv FC      0 -15          4     g 2015-16   champions
## 
## $`2018-19.h.champions`
##                 team points gd league_pos group    year competition
## 17          Juventus     12  5          1     h 2018-19   champions
## 18 Manchester United     10  3          2     h 2018-19   champions
## 19          Valencia      8  0          3     h 2018-19   champions
## 20        Young Boys      4 -8          4     h 2018-19   champions
## 
## $`2012-13.h.europa`
##                      team points gd league_pos group    year competition
## 21         FC Rubin Kazan     14  7          1     h 2012-13      europa
## 22            Inter Milan     11  2          2     h 2012-13      europa
## 23                 Neftçi      3 -4          3     h 2012-13      europa
## 24 Partizan Beograd (SRB)      3 -5          4     h 2012-13      europa&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can also do a larger test by randomly selecting teams out of the English league data we looked at earlier. To do this I need two quick functions: one to sample randomly from the data, and another to carry out the correlation test.&lt;/p&gt;
&lt;p&gt;The first takes a number of samples (how many tests to run) and then selects a number of teams from each league sample. For instance, if I chose 3 teams, it might select Liverpool, Manchester United, and Watford, from the &lt;a href=&#34;https://en.wikipedia.org/wiki/2018%E2%80%9319_Premier_League&#34;&gt;last season of the Premier League&lt;/a&gt;. These teams finished 2nd, 6th, and 11th respectively, so this ‘sampled league’ would fulfill the criteria of finishing in alphabetical order.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(3459)

#take a random sample of leagues and teams withing those leagues
sample_cutdown_leagues &amp;lt;- function(nteams, nsamples, data) {
  samples &amp;lt;- sample(length(data), nsamples, replace = TRUE)
  
  sampled_league_data &amp;lt;- data[samples]
  
  league_team_serials &amp;lt;- sampled_league_data %&amp;gt;%
    lapply(., nrow) %&amp;gt;%
    lapply(., sample, size = nteams)
  
  #carry out the correlation test
  league_cor_test &amp;lt;- map2_df(
    .x = sampled_league_data,
    .y = league_team_serials,
    .f = cor_test_data
  )
}
  
#function for correlation test
cor_test_data &amp;lt;- function(full_league_data, sampled_teams) {
  sampled_league &amp;lt;- full_league_data[sampled_teams,] %&amp;gt;%
    arrange(league_pos)
  cor_test &amp;lt;- cor.test(
    sampled_league$league_pos,
    sampled_league$alph_order,
    method = &amp;quot;spearman&amp;quot;
  ) %&amp;gt;%
    tidy() %&amp;gt;%
    #mutate on information about that season and teams chosen
    mutate(teams = paste(sampled_league$team, collapse = &amp;quot;, &amp;quot;),
           season = unique(sampled_league$season),
           division = unique(sampled_league$division))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So for instance if I just run it once, randomly selecting 4 teams:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test &amp;lt;- sample_cutdown_leagues(4, 1, league_data)
#print the teams selected
test$teams&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Brentford, Bristol Rovers, Brighton &amp;amp; Hove Albion, Chester&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 8
##   estimate statistic p.value method   alternative teams     season division
##      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;       &amp;lt;chr&amp;gt;      &amp;lt;int&amp;gt;    &amp;lt;int&amp;gt;
## 1      0.8      2.00   0.333 Spearma~ two.sided   Brentfor~   1994        3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It gives me 4 teams from the 1994 division 3 who didn’t finish in alphabetical order (though, amusingly, all have a very similar starting letter).&lt;/p&gt;
&lt;p&gt;We can then carry this out with 10000 samples for n_team numbers of 2:6 to see if we get roughly the expected numbers of exactly correlated league finish positions (this will take 1-2mins) by finding out how many tests give an estimate of 1 (finished exactly correlated with alphabetical order) or -1 (finished exactly anti-correlated with alphabetical order).&lt;/p&gt;
&lt;p&gt;Both these numbers should be roughly equal to the number of samples (10000) divided by the factorial of the number of teams selected.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test_n_numbers &amp;lt;- function(nteams) {
  #run sampling function n times
  #10k should do
  sampling &amp;lt;- sample_cutdown_leagues(nteams, 10000, league_data)
  
  #find exactly correlated and anti-correlated examples
  #where teams are in exact alphabetical order ascending or descending
  correlated &amp;lt;- length(which(sampling$estimate == max(sampling$estimate)))
  anti_correlated &amp;lt;- length(which(sampling$estimate == min(sampling$estimate)))
  expected &amp;lt;- nrow(sampling) / factorial(nteams)
  
  df &amp;lt;- data.frame(n = nteams,
                   sample_cor = correlated,
                   sample_anticor = anti_correlated,
                   sample_expected = expected)
}
#run the function
testing &amp;lt;- map_df(2:6, test_n_numbers)
#print results
print(testing)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   n sample_cor sample_anticor sample_expected
## 1 2       5010           4990      5000.00000
## 2 3       1676           1665      1666.66667
## 3 4        367            398       416.66667
## 4 5        101             81        83.33333
## 5 6         14             15        13.88889&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And the numbers line up, as we would expect if there is no effect of the first letter of a team’s name upon final league position.&lt;/p&gt;
&lt;p&gt;Finally, we can do a Kendall’s correlation test to really see if there is any relationship between alphabetical team name order and final league finish for all out our English league data. We use Kendall instead of a Spearman test here because we grouping all the data together we’re going to have a lot of ties (one team has to finish 1st in every league each year).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all_data &amp;lt;- league_data %&amp;gt;%
  bind_rows()

#do a big correlation test
kendall_test &amp;lt;- cor.test(all_data$alph_order,
                         all_data$league_pos,
                         alternative = &amp;quot;two.sided&amp;quot;,
                         method = &amp;quot;kendall&amp;quot;) %&amp;gt;%
  tidy() %&amp;gt;%
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 5
##   estimate statistic p.value method                         alternative
##      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;                          &amp;lt;chr&amp;gt;      
## 1   0.0135      1.74  0.0826 Kendall&amp;#39;s rank correlation tau two.sided&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And we can see that, even though our p-value is &lt;a href=&#34;https://mchankins.wordpress.com/2013/04/21/still-not-significant-2/&#34;&gt;‘approaching significance’&lt;/a&gt;, it’s not significant at our fairly liberal threshold of 0.05. Even then, the effect size (0.013) is tiny, so there’s no need for Watford to start worrying &lt;a href=&#34;https://www.bbc.co.uk/sport/football/50619972&#34;&gt;just yet&lt;/a&gt;.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;SMALL DIGRESSION: I love blogging on this site and it also has been a great help to me in numerous ways (practice coding/writing, feeling like a “programmer”, for job interviews), but quite a lot of the time feel posts are not quite where I want them (I’m sure this feeling isn’t restricted to me) and so won’t put them up and so that time (sometimes quite a few hours!) I put into them in my spare time feels wasted and makes me feel worse about myself. I’m hoping that pushing out fairly rushed/half formed ideas like this will help with this.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;rd-december---groan-rangers&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;3rd December - Groan Rangers&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.theguardian.com/football/2019/jul/24/which-teams-were-managed-by-their-all-time-leading-goalscorer&#34;&gt;“Berwick Rangers have conceded 42 goals in competitive matches – Scottish League 2, relegation play-off, Scottish League – since last scoring themselves, against Peterhead, on March 19th. Is this a record for a league club (I know they’ve now lost that status, but all of these matches are league level competition)?” asks Huw Richards.&lt;/a&gt;&lt;/p&gt;
&lt;div id=&#34;answer---it-beats-any-team-in-the-english-league.-reproducible-code-below-if-you-want-to-check-for-other-leagues.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Answer - It beats any team in the English league. Reproducible code below if you want to check for other leagues.&lt;/h2&gt;
&lt;p&gt;(I did check for most of them in the dataset, although this doesn’t include foreign cup competitions. Nothing seems to get close)&lt;/p&gt;
&lt;p&gt;This is quite a nice question from a data munging point of view. It’s extremely quantifiable and only involves a little grouping by.&lt;/p&gt;
&lt;p&gt;First we’ll load the libraries we’re relying on in this little project:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(engsoccerdata)
library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’m going to focus on the English league as it has the most data and also has data on the concurrent cup competitions. It’s super easy to sub in whichever competitions in the engsoccerdata package you want.&lt;/p&gt;
&lt;p&gt;We want to first bind the data from the league, league cup, fa cup, and league playoffs together with a little munging. Then we want to gather the data to get the goals scored and goals conceded in each game for each team.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#bind all the match data together with relevant variables
scoring_data &amp;lt;- bind_rows(
  engsoccerdata::england %&amp;gt;%
    select(date = Date, tier, home, visitor, hgoal, vgoal) %&amp;gt;%
    mutate(date = as.Date(date),
           competition = &amp;quot;league&amp;quot;),
  engsoccerdata::facup %&amp;gt;%
    select(date = Date, home, visitor, hgoal, vgoal) %&amp;gt;%
    mutate(date = as.Date(date),
           tier = NA, 
           competition = &amp;quot;fa_cup&amp;quot;),
  engsoccerdata::leaguecup %&amp;gt;%
    select(date = Date, home, visitor, hgoal, vgoal) %&amp;gt;%
    mutate(date = as.Date(date),
           tier = NA,
           competition = &amp;quot;league_cup&amp;quot;),
  engsoccerdata::englandplayoffs %&amp;gt;%
    select(date = Date, home, visitor, hgoal, vgoal, htier, vtier) %&amp;gt;%
    mutate(date = as.Date(date), 
           tier = (htier+vtier)/2, 
           competition = &amp;quot;league_playoffs&amp;quot;) %&amp;gt;%
    select(-htier, -vtier),
) %&amp;gt;%
  #gather and find matches for each team
  gather(&amp;quot;location&amp;quot;, &amp;quot;team&amp;quot;, -date, -hgoal, -vgoal, -competition, -tier) %&amp;gt;%
  split(f = .$location) %&amp;gt;%
  map2_df(., rev(.), function(df, vs_data) 
    mutate(df, opponent = vs_data$team)
  ) %&amp;gt;%
  #add in goals for and against
  mutate(goals_for = case_when(
    location == &amp;quot;home&amp;quot; ~ hgoal,
    TRUE ~ vgoal
  )) %&amp;gt;%
  mutate(goals_against = case_when(
    location == &amp;quot;visitor&amp;quot; ~ hgoal,
    TRUE ~ vgoal
  )) %&amp;gt;%
  arrange(team, date) %&amp;gt;%
  group_by(team)

head(scoring_data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 10
## # Groups:   team [1]
##   date        tier hgoal vgoal competition location team  opponent
##   &amp;lt;date&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;       &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;   
## 1 1875-11-06    NA     0     0 fa_cup      home     105t~ Crystal~
## 2 1875-11-20    NA     3     0 fa_cup      visitor  105t~ Crystal~
## 3 1876-11-11    NA     3     0 fa_cup      home     105t~ 1st Sur~
## 4 1876-12-14    NA     6     1 fa_cup      visitor  105t~ Oxford ~
## 5 1877-11-07    NA     0     2 fa_cup      home     105t~ Old Har~
## 6 NA            NA    NA    NA fa_cup      visitor  105t~ Minerva 
## # ... with 2 more variables: goals_for &amp;lt;dbl&amp;gt;, goals_against &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next we need to find the start of each run of games where a team has failed to score. We can do this by finding the first instance of 0 goals scored using lag(). We’ll then give an id to each ‘run’ of finishing games without scoring.&lt;/p&gt;
&lt;p&gt;(I’m aware that teams can also concede goals in a run having scored first in a match but there’s no way to factor that in with the data)&lt;/p&gt;
&lt;p&gt;We then use the na.locf() function from the very useful &lt;a href=&#34;https://cran.r-project.org/web/packages/zoo/zoo.pdf&#34;&gt;zoo&lt;/a&gt; package to fill in the runs where no goals have been scored.&lt;/p&gt;
&lt;p&gt;We can then finish answering the question (already!) by grouping by run and summing the total number of goals conceded in that time.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#load the zoo library for helping filling NA values
library(zoo)

dry_runs &amp;lt;- scoring_data %&amp;gt;%
  #find the start of runs
  mutate(run_start = case_when(
    goals_for == 0 &amp;amp; lag(goals_for, default = 1) != 0 ~ 1:n()
  )) %&amp;gt;%
  #only care about games where didn&amp;#39;t score
  filter(goals_for == 0) %&amp;gt;%
  #fill in NAs to get full runs
  mutate(run_id = na.locf(run_start, na.rm = FALSE)) 

longest_dry_runs &amp;lt;- dry_runs %&amp;gt;%
  #group runs by id
  group_by(run_id, team) %&amp;gt;%
  #find total conceeded over n games
  mutate(total_conceeded = sum(goals_against),
         run_start_date = min(date),
         matches = n()) %&amp;gt;%
  #take only the last instance
  filter(!duplicated(run_id, fromLast = TRUE)) %&amp;gt;%
  select(run_start_date, run_end_date = date, team, run_id, total_conceeded, matches) %&amp;gt;%
  #find the most &amp;#39;impressive&amp;#39; runs
  filter(total_conceeded &amp;gt; 15) %&amp;gt;%
  arrange(-total_conceeded)

head(longest_dry_runs)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 6
## # Groups:   run_id, team [6]
##   run_start_date run_end_date team           run_id total_conceeded matches
##   &amp;lt;date&amp;gt;         &amp;lt;date&amp;gt;       &amp;lt;chr&amp;gt;           &amp;lt;int&amp;gt;           &amp;lt;dbl&amp;gt;   &amp;lt;int&amp;gt;
## 1 1899-01-14     1899-03-11   Darwen            273              38       7
## 2 1898-11-12     1898-12-26   Darwen            263              35       7
## 3 1891-12-12     1892-01-09   Darwen             60              31       5
## 4 2019-04-09     2019-08-31   Bolton Wander~   5447              29      11
## 5 1877-12-22     1886-10-23   1st Surrey Ri~      8              27       3
## 6 1880-12-18     1894-01-27   Reading             6              27       3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And can see that two 7 game runs from the (now-defunct) &lt;a href=&#34;https://en.wikipedia.org/wiki/Darwen_F.C.&#34;&gt;Darwen FC&lt;/a&gt; are top of the list. Around 1898/1899 the team conceded 35 and 38 goals without scoring themselves.&lt;/p&gt;
&lt;p&gt;Manually &lt;a href=&#34;https://www.11v11.com/teams/darwen/tab/matches/season/1899/&#34;&gt;looking at the data&lt;/a&gt;, we can see that these two streaks are broken only by a few losses over Christmas 1898, a losing run of 18 games! Indeed, Darwen only won 2 games that season and set the record for most goals conceded (141).&lt;/p&gt;
&lt;p&gt;7 Years earlier, the same team managed an impressive run of letting in 31 goals in just 5 matches, without scoring. If we want to check out the game in this, we can do by left_join() ing our data together&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#joni data to inspect individual games
dry_run_matches &amp;lt;- dry_runs %&amp;gt;%
  left_join(longest_dry_runs, by = c(&amp;quot;team&amp;quot;, &amp;quot;run_id&amp;quot;)) %&amp;gt;%
  filter(!is.na(total_conceeded)) %&amp;gt;%
  select(date, team, opponent, goals_for, goals_against,
         competition, tier, total_conceeded, run_id) %&amp;gt;%
  arrange(-total_conceeded)

#print this
print(filter(dry_run_matches, run_id == 60))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 9
## # Groups:   team [1]
##   date       team  opponent goals_for goals_against competition  tier
##   &amp;lt;date&amp;gt;     &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;
## 1 1891-12-12 Darw~ Sunderl~         0             7 league          1
## 2 1891-12-25 Darw~ Blackbu~         0             4 league          1
## 3 1891-12-26 Darw~ Aston V~         0             7 league          1
## 4 1892-01-01 Darw~ Preston~         0             4 league          1
## 5 1892-01-09 Darw~ Burnley          0             9 league          1
## # ... with 2 more variables: total_conceeded &amp;lt;dbl&amp;gt;, run_id &amp;lt;int&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Also, congratulations to the &lt;a href=&#34;https://www.boltonwanderers.news/news/efl-discinplinary-panels-decision-on-wanderers-delayed-again/&#34;&gt;oft-trouble Bolton Wanderers&lt;/a&gt; who have got closest to this in modern times, failing to score in 11 straight matches, while conceding 29 goals in the process.&lt;/p&gt;
&lt;p&gt;I also wanted to find out the opposite: the team that has scored the most goals without conceding any. It’s super easy with our pipeline- just switch goals_against and goals_for in the chain.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#do the inverse
scoring_runs &amp;lt;- scoring_data %&amp;gt;%
  mutate(run_start = case_when(
    goals_against == 0 &amp;amp; lag(goals_against, default = 1) != 0 ~ 1:n()
  )) %&amp;gt;%
  filter(goals_against == 0) %&amp;gt;%
  mutate(run_id = na.locf(run_start, na.rm = FALSE)) 

longest_scoring_runs &amp;lt;- scoring_runs %&amp;gt;%
  group_by(run_id, team) %&amp;gt;%
  mutate(total_scored = sum(goals_for),
         run_start_date = min(date),
         matches = n()) %&amp;gt;%
  filter(!duplicated(run_id, fromLast = TRUE)) %&amp;gt;%
  select(run_start_date, run_end_date = date, team, run_id, total_scored, matches) %&amp;gt;%
  filter(total_scored &amp;gt; 15) %&amp;gt;%
  arrange(-total_scored)

head(longest_scoring_runs)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 6
## # Groups:   run_id, team [6]
##   run_start_date run_end_date team            run_id total_scored matches
##   &amp;lt;date&amp;gt;         &amp;lt;date&amp;gt;       &amp;lt;chr&amp;gt;            &amp;lt;int&amp;gt;        &amp;lt;dbl&amp;gt;   &amp;lt;int&amp;gt;
## 1 2010-04-25     2010-08-28   Chelsea           4372           32       7
## 2 1929-03-06     1929-03-30   Bradford City      919           29       5
## 3 2019-01-06     2019-01-26   Manchester City   5194           28       6
## 4 1903-04-10     1903-10-03   Arsenal            328           26       8
## 5 1880-01-17     1880-11-13   Clapham Rovers      25           26       5
## 6 1885-10-24     1885-12-12   Notts County        32           26       3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Where we can see that Chelsea’s impressive end to the 2009-2010 season puts them top, having scored 32 goals without reply. Almost all the other top examples are from pre-war football, except Manchester City coming close last year with 28 goals scored without conceding.&lt;/p&gt;
&lt;p&gt;When we look at this run we can see it was greatly helped along by some demolitions in the cups, winning 5-0, 9-0 and 7-0 against Burnley, Burton Albion, and Rotherham United.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;scoring_run_matches &amp;lt;- scoring_runs %&amp;gt;%
  left_join(longest_scoring_runs, by = c(&amp;quot;team&amp;quot;, &amp;quot;run_id&amp;quot;)) %&amp;gt;%
  filter(!is.na(total_scored)) %&amp;gt;%
  select(date, team, opponent, goals_for, goals_against,
         competition, tier, total_scored, run_id) %&amp;gt;%
  arrange(-total_scored)

#print this
print(filter(scoring_run_matches, run_id == 5194))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 9
## # Groups:   team [1]
##   date       team  opponent goals_for goals_against competition  tier
##   &amp;lt;date&amp;gt;     &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;
## 1 2019-01-06 Manc~ Rotherh~         7             0 fa_cup         NA
## 2 2019-01-09 Manc~ Burton ~         9             0 league_cup     NA
## 3 2019-01-14 Manc~ Wolverh~         3             0 league          1
## 4 2019-01-20 Manc~ Hudders~         3             0 league          1
## 5 2019-01-23 Manc~ Burton ~         1             0 league_cup     NA
## 6 2019-01-26 Manc~ Burnley          5             0 fa_cup         NA
## # ... with 2 more variables: total_scored &amp;lt;dbl&amp;gt;, run_id &amp;lt;int&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;th-december---were-going-to-wembley&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;5th December - We’re going to Wembley&lt;/h1&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
Which team has had to travel the shortest combined distance in a cup run? (excluding regional competitions, just to make it interesting)
&lt;/p&gt;
— Chris van Thomas (&lt;span class=&#34;citation&#34;&gt;@chrisvanthomas&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/chrisvanthomas/status/1148879896430731266?ref_src=twsrc%5Etfw&#34;&gt;July 10, 2019&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;div id=&#34;answer---multiple-teams-have-played-5-fa-cup-matches-all-at-home.-to-answer-the-inverse-question-queens-park-in-18831884-and-18841885-have-had-the-farthest-to-travel&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Answer - Multiple teams have played 5 FA cup matches all at home. To answer the inverse question, Queen’s Park in 1883/1884 and 1884/1885 have had the farthest to travel&lt;/h2&gt;
&lt;p&gt;For this question, I’m actually going to answer the opposite topic- which team have traveled the farthest in a cup run? The reason being is that multiple teams have had cup runs (of 5 matches in the FA cup) without travelling away from home at all. The code below could easily be changed to analyse other cup competitions, for simplicity, I’m sticking with the FA cup which has the most complete data in the engsoccerdata set.&lt;/p&gt;
&lt;p&gt;Once again, we’ll start by loading libraries. We also want the &lt;a href=&#34;https://r-spatial.github.io/sf/articles/sf1.html&#34;&gt;sf&lt;/a&gt; package that makes working with spatial data a bit cleaner.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(engsoccerdata)
library(tidyverse)
#also want sf to manipulate spatial features
library(sf)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we want to grab the data. In a &lt;a href=&#34;https://github.com/jalapic/engsoccerdata/commit/6133cf9f6fd77574a5a03097a6d2db4d213c508c&#34;&gt;recent update of the engsoccerdata package&lt;/a&gt; I added the location of grounds for teams in England which will let us find the distances teams have traveled to matches.&lt;/p&gt;
&lt;p&gt;I also download a shapefile of the UK from &lt;a href=&#34;https://gadm.org/&#34;&gt;GADM&lt;/a&gt; for plotting and to filter out any bad data in ground location (which still is very much in beta).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#download a map of the uk to plot with
shape_url &amp;lt;- &amp;quot;https://biogeo.ucdavis.edu/data/gadm3.6/Rsf/gadm36_GBR_0_sf.rds&amp;quot;
temp_dir &amp;lt;- tempdir()
download.file(shape_url, destfile = file.path(temp_dir, &amp;quot;shapefiles.rds&amp;quot;), mode = &amp;quot;wb&amp;quot;)
uk &amp;lt;- st_as_sf(readRDS(file.path(temp_dir, &amp;quot;shapefiles.rds&amp;quot;)))

#the location of football grounds in the dataset
grounds &amp;lt;- engsoccerdata::england_locations %&amp;gt;%
  st_as_sf(coords = c(&amp;quot;lon&amp;quot;, &amp;quot;lat&amp;quot;), crs = st_crs(&amp;quot;+init=epsg:4326&amp;quot;)) %&amp;gt;%
  st_transform(crs = st_crs(uk)) %&amp;gt;%
  #remove those that are bad data-outside the uk
  .[seq(nrow(.)) %in% unlist(st_contains(uk, .)),]
#get the fa cup match data
matches &amp;lt;- engsoccerdata::facup&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There’s some ambiguity in the question as to how the distance of a cup run should be measured. There’s really two ways we can do this, which I will henceforth refer to as a ‘routing’ as ‘spoking’. To illustrate the two different approaches, I’ll use Southampton’s 2017/2018 FA cup run&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#e.g. with Southampton&amp;#39;s semi final run in 2017/2018
Southampton &amp;lt;- matches %&amp;gt;%
    filter(Season == 2017 &amp;amp; 
             (home == &amp;quot;Southampton&amp;quot; | 
                visitor == &amp;quot;Southampton&amp;quot;)
           ) %&amp;gt;%
  select(Venue, Date, home, visitor, neutral) %&amp;gt;%
  gather(&amp;quot;location&amp;quot;, &amp;quot;team&amp;quot;, -Venue, -Date, -neutral) %&amp;gt;%
  filter(location == &amp;quot;home&amp;quot; | neutral == &amp;quot;yes&amp;quot;) %&amp;gt;%
  filter(!duplicated(Date)) %&amp;gt;%
  mutate(location = case_when(
    neutral == &amp;quot;yes&amp;quot; ~ Venue,
    TRUE ~ team
  ))

#print matches
Southampton&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 5
##   Venue            Date       neutral location           team              
##   &amp;lt;chr&amp;gt;            &amp;lt;date&amp;gt;     &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;              &amp;lt;chr&amp;gt;             
## 1 Craven Cottage   2018-01-06 &amp;lt;NA&amp;gt;    Fulham             Fulham            
## 2 St Mary&amp;#39;s Stadi~ 2018-01-27 &amp;lt;NA&amp;gt;    Southampton        Southampton       
## 3 The Hawthorns    2018-02-17 &amp;lt;NA&amp;gt;    West Bromwich Alb~ West Bromwich Alb~
## 4 DW Stadium       2018-03-18 &amp;lt;NA&amp;gt;    Wigan Athletic     Wigan Athletic    
## 5 Wembley Stadium  2018-04-22 yes     Wembley Stadium    Chelsea&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’ll join the ground geography data to this to figure out distances traveled&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#will need the location of southamptons ground
Southampton_home &amp;lt;- grounds %&amp;gt;%
  filter(location == &amp;quot;Southampton&amp;quot;)
#and the locations of all their matches
match_locations &amp;lt;- Southampton %&amp;gt;%
  left_join(., select(grounds, location, geometry), by = &amp;quot;location&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first method of calculating distance traveled per match (‘spoking’) takes the location of each match, and finds the distance from that team’s home ground. E.g. for Southampton:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#find the line from southampton&amp;#39;s ground to the match location
spoke_lines &amp;lt;- st_coordinates(match_locations$geometry) %&amp;gt;%
  split(f = rownames(.)) %&amp;gt;%
  #create line from geometry1 to geometry2
  lapply(function(x) {
    mat &amp;lt;- rbind(x, st_coordinates(Southampton_home$geometry))
    line &amp;lt;- st_linestring(mat)
    return(line)
  }) %&amp;gt;%
  #cast to multiline and add projection
  st_multilinestring() %&amp;gt;%
  st_sfc(crs = st_crs(&amp;quot;+init=epsg:4326&amp;quot;))

#plot over uk
p &amp;lt;- ggplot() +
  geom_sf(data = uk) +
  geom_sf(data = spoke_lines, colour = &amp;quot;blue&amp;quot;, size = 1.5) +
  theme_minimal()

plot(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-01-advent_calendar_knowledge_files/figure-html/southampton_spokes-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#get the total length in metres
st_length(spoke_lines)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 698614.6 [m]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For any home games, the distance traveled is taken to be 0m.&lt;/p&gt;
&lt;p&gt;The second method of calculating distance traveled takes the distance from each match &lt;em&gt;to&lt;/em&gt; the next match in run. I.e. it assumes a team stays in their past location until the next round (obviously not true in real life) and finds the distance to the ground for the next round game:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#need coords separate
coords &amp;lt;- st_coordinates(match_locations$geometry) %&amp;gt;%
  split(f = rownames(.))

#find distance from one coords to next
travel_lines &amp;lt;- mapply(coords, lead(coords), FUN = function(x, y) {
  #for last match no further path
  if(is.na(y)) {
    return(NULL)
  } else {
    mat &amp;lt;- rbind(x, y)
    line &amp;lt;- st_linestring(mat)
    return(line)
  }
}) %&amp;gt;%
  #filter null last element
  .[-which(lengths(.) == 0)] %&amp;gt;%
  st_multilinestring() %&amp;gt;%
  st_sfc(crs = st_crs(&amp;quot;+init=epsg:4326&amp;quot;))

#plot over uk
p &amp;lt;- ggplot() +
  geom_sf(data = uk) +
  geom_sf(data = travel_lines, colour = &amp;quot;blue&amp;quot;, size = 1.5) +
  theme_minimal()

plot(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-01-advent_calendar_knowledge_files/figure-html/southampton_travel-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#get the length
st_length(travel_lines)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 684586.7 [m]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So Southampton here begin in London away to Fulham, before travelling to their home in Southampton, then on to Birmingham (West Brom), Wigan, and back to London to play at Wembley.&lt;/p&gt;
&lt;p&gt;Now we have the two methods, we need to prep the data we’re going to analyse. As before, this is done by gathering a df of match data so we have one row per match per team in the FA cup. We then group by team-season’s and find how many matches they played in the cup that year. For a ‘cup run’ we assume more than 3 matches have to played.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#gather each match per team into a separate row
long_campaigns &amp;lt;- matches %&amp;gt;%
  filter(!is.na(Date)) %&amp;gt;%
  select(Season, home, visitor) %&amp;gt;%
  gather(&amp;quot;location&amp;quot;, &amp;quot;team&amp;quot;, -Season) %&amp;gt;%
  #remove rows with missing teams
  filter(!is.na(team)) %&amp;gt;%
  #get the number of fa cup matches per season per team
  group_by(team, Season) %&amp;gt;%
  summarise(matches = n()) %&amp;gt;%
  #assume you need at least 3 matches for a &amp;#39;run&amp;#39;
  filter(matches &amp;gt; 3) %&amp;gt;%
  ungroup() %&amp;gt;%
  arrange(Season) %&amp;gt;%
  mutate(id = 1:n())

long_campaign_matches &amp;lt;- matches %&amp;gt;%
  select(., Season, Date, round, 
         neutral, Venue,
         team = home, opponent = visitor) %&amp;gt;%
  mutate(location = &amp;quot;home&amp;quot;) %&amp;gt;%
  #bind in the opposite data for away teams
  bind_rows(., mutate(select(., Season, Date, round,
                             neutral, Venue,
                             team = opponent, opponent = team),
                      location = &amp;quot;away&amp;quot;)) %&amp;gt;%
  filter(!is.na(team)) %&amp;gt;%
  #left join the data for long campaigns
  left_join(., long_campaigns, by = c(&amp;quot;Season&amp;quot;, &amp;quot;team&amp;quot;)) %&amp;gt;%
  #remove non-long campaigns
  filter(!is.na(matches)) %&amp;gt;%
  #get the location of the match
  mutate(location = case_when(
    neutral == &amp;quot;yes&amp;quot; ~ Venue,
    location == &amp;quot;home&amp;quot; ~ team,
    location == &amp;quot;away&amp;quot; ~ opponent,
  )) %&amp;gt;%
  #left join in the location for the corresponding ground
  left_join(grounds, c(&amp;quot;location&amp;quot;)) %&amp;gt;%
  #select columns
  select(season = Season, date = Date, round, 
         neutral, team, opponent, 
         location, matches, id, geometry)

#print 
head(long_campaign_matches)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 10
##   season date       round neutral team  opponent location matches    id
##    &amp;lt;dbl&amp;gt; &amp;lt;date&amp;gt;     &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;      &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;
## 1   1871 1871-12-16 2     &amp;lt;NA&amp;gt;    Crys~ Maidenh~ Crystal~       5     1
## 2   1871 1871-12-16 2     &amp;lt;NA&amp;gt;    Wand~ Clapham~ Wandere~       4     3
## 3   1871 1872-01-20 3     &amp;lt;NA&amp;gt;    Wand~ Crystal~ Wandere~       4     3
## 4   1871 1872-01-27 3     &amp;lt;NA&amp;gt;    Roya~ Hampste~ Royal E~       5     2
## 5   1871 1872-02-17 s     yes     Crys~ Royal E~ Kenning~       5     1
## 6   1871 1872-03-09 s     yes     Roya~ Crystal~ Kenning~       5     2
## # ... with 1 more variable: geometry &amp;lt;POINT [°]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can then find the routing distance using a nice trick I found on &lt;a href=&#34;https://github.com/r-spatial/sf/issues/799&#34;&gt;Stack Overflow&lt;/a&gt; to find the distance between each location and the next in the data.frame.&lt;/p&gt;
&lt;p&gt;Finally, this is grouped by id and summed to get the total distance traveled in that cup campaign (when judging by the ‘routing’ metric).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#taken from
#https://github.com/r-spatial/sf/issues/799
#init an empty sfc
empty &amp;lt;- st_as_sfc(&amp;quot;POINT(EMPTY)&amp;quot;)
routing_distances &amp;lt;- long_campaign_matches %&amp;gt;%
  arrange(id, date) %&amp;gt;%
  filter(!is.na(date)) %&amp;gt;%
  group_by(id) %&amp;gt;%
  #find the distance from one game to the next
  mutate(
    distance_to_next = sf::st_distance(
      geometry, 
      lag(geometry, default = empty), 
      by_element = TRUE)
    ) 

#sum the distances
grouped_routing_distances &amp;lt;- routing_distances %&amp;gt;%
  summarise(travel_distance = sum(distance_to_next, na.rm = TRUE)) %&amp;gt;%
  merge(long_campaigns, by = &amp;quot;id&amp;quot;) %&amp;gt;%
  #conver to km
  mutate(total_distance = travel_distance / 1000) %&amp;gt;%
  select(id, team, matches, season = Season, total_distance) %&amp;gt;%
  mutate(av_distance = total_distance / matches) %&amp;gt;%
  arrange(-total_distance)

head(grouped_routing_distances)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     id             team matches season total_distance av_distance
## 1  111      Queens Park       8   1884       2684.363    335.5454
## 2  668      Exeter City       8   1930       2362.073    295.2592
## 3  293 Newcastle United       8   1904       2316.524    289.5655
## 4  512 Newcastle United       9   1923       2112.232    234.6924
## 5 1182 Newcastle United      10   1954       2017.824    201.7824
## 6 1090        Gateshead       8   1951       2015.698    251.9623&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By functionalising our code from earlier, we can easily plot these well-traveled runs. Using the recently-added-to-CRAN &lt;a href=&#34;https://github.com/thomasp85/patchwork&#34;&gt;patchwork&lt;/a&gt; package, we can make multiple plots and stitch them together, e.g. for the 6 FA cup runs with the longest distances traveled we get:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#functionalise our code from earlier to plot travel routes easier
plot_travel_lines &amp;lt;- function(run_team_year, plot_type) {
  run_matches &amp;lt;- long_campaign_matches %&amp;gt;%
    mutate(id = paste(team, season)) %&amp;gt;%
    filter(id == run_team_year) %&amp;gt;%
    arrange(date)
  coords &amp;lt;- st_coordinates(run_matches$geometry) %&amp;gt;%
    split(f = rownames(.))
  if(plot_type == &amp;quot;travel&amp;quot;) {
    lines &amp;lt;- mapply(coords, lead(coords), FUN = function(x, y) {
    if(is.na(y)) {
      return(NULL)
    } else {
      mat &amp;lt;- rbind(x, y)
      line &amp;lt;- st_linestring(mat)
      return(line)
    }
    }) %&amp;gt;%
    .[-which(lengths(.) == 0)] %&amp;gt;%
    st_multilinestring() %&amp;gt;%
    st_sfc(crs = st_crs(&amp;quot;+init=epsg:4326&amp;quot;))
  } else if(plot_type == &amp;quot;spokes&amp;quot;) {
    home &amp;lt;- grounds %&amp;gt;%
      filter(location == unique(run_matches$team)) %&amp;gt;%
      st_coordinates()
    lines &amp;lt;- lapply(coords, function(x) {
      mat &amp;lt;- rbind(x, home)
      line &amp;lt;- st_linestring(mat)
      return(line)
    }) %&amp;gt;%
      #cast to multiline and add projection
      st_multilinestring() %&amp;gt;%
      st_sfc(crs = st_crs(&amp;quot;+init=epsg:4326&amp;quot;))
  }
  plot &amp;lt;- ggplot() +
    geom_sf(data = uk) +
    geom_sf(data = lines, colour = &amp;quot;blue&amp;quot;, size = 1.5) +
    labs(title = paste(run_team_year)) +
    theme_minimal()
  return(plot)
}

#plot the top six
library(patchwork)
paste(grouped_routing_distances$team[1:6],
      grouped_routing_distances$season[1:6]) %&amp;gt;%
  lapply(., plot_travel_lines, plot_type = &amp;quot;travel&amp;quot;) %&amp;gt;%
  wrap_plots(.)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-01-advent_calendar_knowledge_files/figure-html/plot_run_travel-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We then need to check this against our other method of evaluating distances in a cup run- the ‘spoking’ method. This is much easier to calculate- all we have to do is left_join() in the location for each team’s home ground, and find the distance between this and the match location.&lt;/p&gt;
&lt;p&gt;Then we simply sum the total distances per campaign and plot the longest of these:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spoke_distances &amp;lt;- long_campaign_matches %&amp;gt;%
  #left join in location data for each team
  left_join(grounds, by = c(&amp;quot;team&amp;quot; = &amp;quot;location&amp;quot;)) %&amp;gt;%
  #calculate distance between each teams home ground and the match location
  mutate(distance = st_distance(geometry.x, geometry.y, by_element = TRUE))

#group by and sum the cup run distances
grouped_spoke_distances &amp;lt;- spoke_distances %&amp;gt;%
  group_by(team, season) %&amp;gt;%
  summarise(total_distance = sum(distance/1000, na.rm = TRUE),
            av_distance = mean(distance/1000, na.rm = TRUE)) %&amp;gt;%
  arrange(-total_distance)

#print
head(grouped_spoke_distances)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 4
## # Groups:   team [3]
##   team             season total_distance av_distance
##   &amp;lt;chr&amp;gt;             &amp;lt;dbl&amp;gt;            [m]         [m]
## 1 Queens Park        1883       2150.504    307.2149
## 2 Newcastle United   1923       1974.430    219.3811
## 3 Newcastle United   1951       1957.196    279.5994
## 4 Fulham             1974       1810.676    150.8897
## 5 Newcastle United   1973       1781.279    178.1279
## 6 Queens Park        1884       1702.166    170.2166&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#plot
paste(grouped_spoke_distances$team[1:6],
      grouped_spoke_distances$season[1:6]) %&amp;gt;%
  lapply(., plot_travel_lines, plot_type = &amp;quot;spokes&amp;quot;) %&amp;gt;%
  wrap_plots(.)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-01-advent_calendar_knowledge_files/figure-html/find_spoke_distances-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;th-december---this-town-aint-big-enough-for-a-league-football-team&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;10th December - This Town Ain’t Big Enough For a League Football Team&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.theguardian.com/football/2003/may/29/theknowledge.sport&#34;&gt;“What’s the largest town/city without a League club? I reckon Maidstone takes some beating (population 139,000 - about the same as Blackburn). Unlike Blackburn Rovers, Maidstone United play in the Kent League (of course Blackburn would not actually be eligible) which is some way below the Conference and Dr Martins Leagues. But being Maidstone United of course they play all their fixtures 12 miles away in Sittingbourne,” writes Peter Driver. IN 2003&lt;/a&gt;&lt;/p&gt;
&lt;div id=&#34;answer--&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Answer -&lt;/h2&gt;
&lt;p&gt;To answer this question, first we need data on towns and cities in England. We’re going to rank by population so can download the population table found &lt;a href=&#34;http://lovemytown.co.uk/populations/TownsTable1.asp&#34;&gt;here&lt;/a&gt; to start with&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#scrape data on town/city ppulations in UK
pops &amp;lt;- &amp;quot;http://lovemytown.co.uk/populations/TownsTable1.asp&amp;quot; %&amp;gt;%
  read_html() %&amp;gt;%
  html_nodes(&amp;quot;#mainContent &amp;gt; table:nth-child(3)&amp;quot;) %&amp;gt;%
  html_table(fill = TRUE, header = TRUE) %&amp;gt;%
  as.data.frame() %&amp;gt;%
  #some munging to match datasets later
  mutate(tcity15nm = case_when(
    grepl(&amp;quot;^St\\. &amp;quot;, Town) ~ gsub(&amp;quot;^St\\. &amp;quot;, &amp;quot;St &amp;quot;, Town),
    grepl(&amp;quot;^Hull$&amp;quot;, Town) ~ &amp;quot;Kingston upon Hull&amp;quot;,
    grepl(&amp;quot;^Burton$&amp;quot;, Town) ~ &amp;quot;Burton upon Trent&amp;quot;,
    grepl(&amp;quot;^Newcastle$&amp;quot;, Town) ~ &amp;quot;Newcastle upon Tyne&amp;quot;,
    grepl(&amp;quot;^Southend$&amp;quot;, Town) ~ &amp;quot;Southend-on-Sea&amp;quot;,
    grepl(&amp;quot;^Stoke$&amp;quot;, Town) ~ &amp;quot;Stoke-on-Trent&amp;quot;,
    TRUE ~ Town
  )) %&amp;gt;%
  #convert population to numeric
  mutate(population = as.numeric(gsub(&amp;quot;,&amp;quot;, &amp;quot;&amp;quot;, Population))) %&amp;gt;%
  select(tcity15nm, population, status = Status)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’re then going to want the geographic data on these towns. The UK government provides shapefiles for the outlines of ‘Major Towns and Cities’ from a few years ago which should be sufficient for the question. They’re provided as geoJSON files so I’m going to use the geojsonsf package to load them straight as sf objects.&lt;/p&gt;
&lt;p&gt;To reproduce this script, you’ll need to download the data from the &lt;a href=&#34;https://data.gov.uk/dataset/7879ab82-2863-401e-8a29-a56e264d2182/major-towns-and-cities-december-2015-boundaries&#34;&gt;UK government achives&lt;/a&gt; and point the file object towards it&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#to read in geojson data as an sf file
library(geojsonsf)

#download the shapefile from
#https://data.gov.uk/dataset/7879ab82-2863-401e-8a29-a56e264d2182/major-towns-and-cities-december-2015-boundaries
file &amp;lt;- &amp;quot;path/to/downloaded/file.geojson&amp;quot;
#load data
towns &amp;lt;- geojson_sf(file) %&amp;gt;%
  left_join(., pops, by = &amp;quot;tcity15nm&amp;quot;) %&amp;gt;%
  st_transform(st_crs(27700)) %&amp;gt;%
  #buff the town shapefiles by 2.5km to catch all clubs within
  #reasonable distance of the town
  st_buffer(., 2500)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we want the club data. In the latest release of &lt;a href=&#34;https://github.com/jalapic/engsoccerdata/pull/61&#34;&gt;engsoccer data&lt;/a&gt; I added some (very beta) non-league data so we have a greater number of teams to pick from. We’ll take the league the team played in in 2018 as this on league data hasn’t been updated to 2019 (the current season) yet.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#get all league and non-league clubs
#non league clubs in new release of engsoccerdata
clubs &amp;lt;- rbind(
  select(england, home, Season, tier), 
  select(england_nonleague, home, Season, tier)) %&amp;gt;%
  #no 2019 data for non league yet
  filter(Season == 2018) %&amp;gt;%
  select(home, tier) %&amp;gt;%
  unique()

#get the locations of each of these clubs in
club_locations &amp;lt;- england_club_data %&amp;gt;%
  st_as_sf(coords = c(&amp;quot;lon&amp;quot;, &amp;quot;lat&amp;quot;), crs = st_crs(4326)) %&amp;gt;%
  #on uk grid projection
  st_transform(st_crs(27700)) %&amp;gt;%
  left_join(., clubs, by = c(&amp;quot;team&amp;quot; = &amp;quot;home&amp;quot;)) %&amp;gt;%
  select(team, tier) %&amp;gt;%
  filter(!is.na(tier))

#plot these clubs over major towns in uk
p_town_clubs &amp;lt;- ggplot() +
  geom_sf(data = uk) +
  geom_sf(data = towns, fill = &amp;quot;red&amp;quot;) +
  geom_sf(data = club_locations, alpha = 0.15, colour = &amp;quot;blue&amp;quot;) +
  labs(title = &amp;quot;location of English football teams relative to major towns&amp;quot;) +
  theme_minimal()

p_town_clubs&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-01-advent_calendar_knowledge_files/figure-html/towns_get_clubs-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can then run a very quick function to find the clubs that are location within each town using sf::st_contains and arrange by our parameters to answer the question!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#function to find which towns contain clubs
town_data &amp;lt;- st_contains(towns, club_locations) %&amp;gt;%
  map_df(., function(x) {
    n_clubs &amp;lt;- length(x)
    if(n_clubs == 0) {
      max_tier &amp;lt;- NA
      tiers &amp;lt;- NA
    } else {
      #get the tiers of the english footballing pyramid that clubs play in
      tiers &amp;lt;- I(list(club_locations$tier[x]))
      max_tier &amp;lt;- min(club_locations$tier[x])
    }
    return(data.frame(n_clubs,
                      max_tier,
                      tiers))
  }) %&amp;gt;%
  #bind to the town data
  bind_cols(towns, .) %&amp;gt;%
  select(town = tcity15nm, pop = population, n_clubs, max_tier) %&amp;gt;%
  #arrange to answer question
  arrange(n_clubs, -max_tier, -pop)

#get rid of unnessecary geometry
st_geometry(town_data) &amp;lt;- NULL

#print answer
head(town_data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##               town    pop n_clubs max_tier
## 1       Gloucester 136362       0       NA
## 2      Basingstoke 107355       0       NA
## 3        Worcester 100153       0       NA
## 4 Stockton-on-Tees  82729       0       NA
## 5        Guildford  77057       0       NA
## 6 Sutton Coldfield 109015       1        8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So it appears Gloucester, Worcester and Basingstoke are the largest towns without a football club in their city limits. We can double check this using a quick grep function for the clubs (it’s possible this could miss some clubs but is probably accurate enough)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;empty_towns &amp;lt;- c(&amp;quot;Gloucester&amp;quot;, &amp;quot;Basingstoke&amp;quot;, &amp;quot;Worcester&amp;quot;, &amp;quot;Stockton&amp;quot;, &amp;quot;Guildford&amp;quot;)

lapply(empty_towns, grep, x = clubs$home) %&amp;gt;%
  unlist() %&amp;gt;%
  clubs$home[.]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Gloucester City&amp;quot;  &amp;quot;Basingstoke Town&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So we can see that Gloucester and Basingstoke &lt;em&gt;do&lt;/em&gt; in fact have football teams, however a quick Wikipedia search shows that &lt;a href=&#34;https://en.wikipedia.org/wiki/Gloucester_City_A.F.C.&#34;&gt;they&lt;/a&gt; &lt;a href=&#34;https://en.wikipedia.org/wiki/Basingstoke_Town_F.C.&#34;&gt;both&lt;/a&gt; play outside their town (so I’m not sure if these count). The largest town* without a football team, down to the 8th tier of English football, is therefore Worcester with 100,000 people, but a team only in the &lt;a href=&#34;https://en.wikipedia.org/wiki/Worcester_City_F.C.&#34;&gt;9th tier&lt;/a&gt; of the football pyramid.&lt;/p&gt;
&lt;p&gt;The question actually does specify &lt;em&gt;‘League’&lt;/em&gt; teams, which generally only refers to the top 4 flights on English football. We can then run the function for each tier, finding the largest town without a team in that tier or above.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#find the largest town without a club above tiers 5:8
by_tier &amp;lt;- lapply(4:7, function(x) {
    data &amp;lt;- town_data %&amp;gt;%
      filter(!is.na(max_tier) &amp;amp; max_tier &amp;gt; x) %&amp;gt;%
      arrange(-pop)
  })

#print by max tier
lapply(by_tier, head, n = 5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
##         town    pop n_clubs max_tier
## 1   Coventry 325949       1        7
## 2 Warrington 165456       1        7
## 3     Slough 155298       2        5
## 4      Poole 154718       2        7
## 5       York 152841       1        6
## 
## [[2]]
##         town    pop n_clubs max_tier
## 1   Coventry 325949       1        7
## 2 Warrington 165456       1        7
## 3      Poole 154718       2        7
## 4       York 152841       1        6
## 5    Telford 142723       1        6
## 
## [[3]]
##               town    pop n_clubs max_tier
## 1         Coventry 325949       1        7
## 2       Warrington 165456       1        7
## 3            Poole 154718       2        7
## 4         Worthing 109120       1        7
## 5 Sutton Coldfield 109015       1        8
## 
## [[4]]
##               town    pop n_clubs max_tier
## 1 Sutton Coldfield 109015       1        8
## 2         Basildon 107123       2        8
## 3        St Helens 102885       1        8
## 4        Wakefield  99251       1        8
## 5         Hastings  91053       1        8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And the City of Coventry takes it, having a population of 325,000 and a team only in the 7th tier (&lt;a href=&#34;https://en.wikipedia.org/wiki/Bedworth_United_F.C.&#34;&gt;Bedworth United, who play just outside the city&lt;/a&gt;). This is only because the city’s main team &lt;a href=&#34;https://en.wikipedia.org/wiki/Coventry_City_F.C.&#34;&gt;Coventry City&lt;/a&gt; are playing in Birmingham due to &lt;a href=&#34;https://en.wikipedia.org/wiki/Coventry_City_F.C.#St_Andrew&amp;#39;s&#34;&gt;ongoing difficulties finding a stadium within their own city&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I think in the spirit of the question, the true answer is one of Warrington (165k), Poole (154k), York (152k), of Telford (142k). Of which York is probably the most major and independent as a town/city.&lt;/p&gt;
&lt;p&gt;Finally the article in which the question was shared posted the follow-up: what is the smallest town to hold a league club?&lt;/p&gt;
&lt;p&gt;We can answer this using the directory of population places produced by the &lt;a href=&#34;https://github.com/alasdairrae/gb-places&#34;&gt;Ordnance Survey&lt;/a&gt;. Again, download the .csv and point the script at it to reproduce.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#load the .csv of small places in the uk
small_places &amp;lt;- read.csv(&amp;quot;path/to.csv&amp;quot;, stringsAsFactors = FALSE) %&amp;gt;%
  #only interested in England
  filter(COUNTRY == &amp;quot;England&amp;quot;) %&amp;gt;%
  select(name = NAME1, x = X, y = Y) %&amp;gt;%
  st_as_sf(coords = c(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;), crs = st_crs(27700)) %&amp;gt;%
  #find small places outside of the large towns
  .[-unique(unlist(st_contains(towns, .))),] %&amp;gt;%
  #buffer by 500m
  st_buffer(., 100)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#plot these for a cool map
plot(select(small_places))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-01-advent_calendar_knowledge_files/figure-html/plot_small_places-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It’s then simple to find the small places to hold football clubs using sf::st_contains and indexing&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#find clubs that are in these remaining places
small_town_clubs &amp;lt;- st_contains(small_places, filter(club_locations, tier &amp;lt; 5))
small_places[which(lengths(small_town_clubs) &amp;gt; 0),]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Simple feature collection with 6 features and 1 field
## geometry type:  POLYGON
## dimension:      XY
## bbox:           xmin: 351959.9 ymin: 116300 xmax: 391793 ymax: 430665
## epsg (SRID):    27700
## proj4string:    +proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +ellps=airy +towgs84=446.448,-125.157,542.06,0.15,0.247,0.842,-20.489 +units=m +no_defs
##             name                       geometry
## 3454    Laneside POLYGON ((376361 429724, 37...
## 3474     Enfield POLYGON ((375759 430165, 37...
## 8843   Moss Lane POLYGON ((391793 371719, 39...
## 17646 Houndstone POLYGON ((353128 117093.1, ...
## 17691     Lufton POLYGON ((352959.9 116800, ...
## 19419  Newmarket POLYGON ((384471.3 199698.6...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Enfield and Moss Lane are in London and Manchester, so don’t count. Houndstone and Lufton are actually in the same town (Yeovil) but still are valid answers.&lt;/p&gt;
&lt;p&gt;Laneside is located just outside Accrington, where &lt;a href=&#34;https://en.wikipedia.org/wiki/Accrington_Stanley_F.C.&#34;&gt;Accrington Stanley&lt;/a&gt; play in the third tier (population 35,000).&lt;/p&gt;
&lt;p&gt;Yeovil (population 45,000) is home to &lt;a href=&#34;https://en.wikipedia.org/wiki/Yeovil_Town_F.C.&#34;&gt;Yeovil Town&lt;/a&gt; who play in the 4th tier.&lt;/p&gt;
&lt;p&gt;But the far and away winner is 4th tier &lt;a href=&#34;https://en.wikipedia.org/wiki/Forest_Green_Rovers_F.C.&#34;&gt;Forest Green Rovers&lt;/a&gt; who play in Nailsworth, with a population of just 5,700 people. Even more, the only remotely near town, Stroud, has a population of just 32,000 people. Most incredible of all, &lt;a href=&#34;https://en.wikipedia.org/wiki/The_New_Lawn&#34;&gt;the stadium for Forest Green Rovers&lt;/a&gt; can hold ~5,000 people, or almost the entire surrounding population.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>R-inforcement Learning Part One- Tic Tac Toe</title>
      <link>/post/r-inforcement_learning_one/</link>
      <pubDate>Thu, 28 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/r-inforcement_learning_one/</guid>
      <description>


&lt;p&gt;I’m extremely biased, but to me, one of the real success* stories in neuroscience over the last (just over) two decades has been in studying reward signals. Since the &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pubmed/9054347&#34;&gt;seminal 1997 paper&lt;/a&gt;, a lot of work has gone into figuring out how the brain assigns value to outcomes.&lt;/p&gt;
&lt;p&gt;*ugh, maybe. This isn’t a blog post about that&lt;/p&gt;
&lt;p&gt;My PhD project looks at novel ways of eliciting valuation behaviour to study these signals, but as a key part of the modelling involved in this work, it’s important to get a handle on &lt;a href=&#34;https://en.wikipedia.org/wiki/Reinforcement_learning&#34;&gt;reinforcement learning&lt;/a&gt;. When originally working through the &lt;a href=&#34;http://incompleteideas.net/book/the-book.html&#34;&gt;Sutton and Barto books&lt;/a&gt;, I threw together some code a few years ago for the problem sets- mostly in python and MATLAB. As someone who runs a blog nominally about coding in R, however, I thought there might be some value in going through said code and refactoring into R. As R can struggle with the speed necessary for reinforcement learning (which typically relies on large numbers of iterating behaviour), it also provided a good chance to crack out some C++ code using the always excellent &lt;a href=&#34;http://adv-r.had.co.nz/Rcpp.html&#34;&gt;Rcpp package&lt;/a&gt;, which is always worth practicing.&lt;/p&gt;
&lt;p&gt;In this first example of Reinforcement Learning in R (and C++), we’re going to train our computers to play Noughts and Crosses (or tic tac toe for Americans) to at least/super human level.&lt;/p&gt;
&lt;p&gt;Let’s get started with the libraries we’ll need. I want to stick to base for speed here, as well as obviously Rcpp. In theory you can easily generalise all the code here to any size board, but I only have tested in with 3x3 boards so YMMV.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#will use ggplot
#everything else Ive used base of listed packages
library(ggplot2)
#Rcpp for some vroom vroom
library(Rcpp)

#in theory this stuff should work for boards of any size
#but I haven&amp;#39;t tested that
board_cols = 3
board_rows = 3
squares &amp;lt;- board_cols * board_rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The very first thing we’ll want to do is find a way to store the information in a game state and convert between this, and a human readable form.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#function to plot boards in a human readable way
#not generalised to all board sizes but easy enough to
plot_board &amp;lt;- function(string) {
  pieced &amp;lt;- rep(&amp;quot;&amp;quot;, length(string))
  pieced[which(string == 1)] &amp;lt;- &amp;quot;x&amp;quot;
  pieced[which(string == -1)] &amp;lt;- &amp;quot;o&amp;quot;
  pieced[which(string == 0)] &amp;lt;- &amp;quot;*&amp;quot;
  board &amp;lt;- gsub(&amp;quot; \\|$&amp;quot;, &amp;quot;&amp;quot;, paste(pieced, &amp;quot;|&amp;quot;, collapse = &amp;quot; &amp;quot;))
  board_lines &amp;lt;- gsub(&amp;quot;(. \\| . \\| . )\\|( . \\| . \\| . )\\|( . \\| . \\| .)&amp;quot;, 
                      &amp;quot;\n \\1\n-----------\n\\2\n-----------\n\\3&amp;quot;,
                      board
                      )
  return(writeLines(board_lines))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next we’re going to want to find every possible state we might encounter so we can test for any exceptions. I’m storing strings as a list of 9 0s (unused), 1s (Xs) and -1s (Os) representing the squares 1-&amp;gt;9 from the top left corner.&lt;/p&gt;
&lt;p&gt;It’s simple and fast enough to do this with a quick R function&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#get all possible boards
possible_boards &amp;lt;- gtools::permutations(
  board_cols, squares,
  c(-1,0,1),
  repeats.allowed = TRUE
  )

#can only have a sum of 1 or 0
possible_boards &amp;lt;- possible_boards[which(rowSums(possible_boards) %in% c(0,1)),]

#plot a random example
plot_board(c(1,0,0,-1,0,0,0,0,1))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  x | * | * 
## -----------
##  o | * | * 
## -----------
##  * | * | x&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we have the representations of any possible board, we want to find a way to store this is a more compressed format as a hash. I originally wrote a pretty quick function to do this in R and then threw up a quick one underneath compiled in Rcpp for comparison.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#get a unique hash for each board
calc_hash &amp;lt;- function(board) {
  hash &amp;lt;- 0
  for(piece in seq(squares)) {
    hash &amp;lt;- (hash*board_cols) + board[piece] + 1
  }
  return(hash)
}

#and the equivalent in Cpp
cppFunction(&amp;#39;int calc_hashCpp(NumericVector board, int squaresize) {
    //need to init vals in C++
    int hash = 0;
    int boardsize = squaresize * squaresize;
    
    //C++ for loops have start, end, and by
    for (int i=0; i &amp;lt;= boardsize - 1; ++i) {
      hash = (hash * squaresize) + board[i] + 1;
    }
    
    //always have to declare a return
    return hash;
}&amp;#39;)

#get a list of all the possible hashes
hashes &amp;lt;- lapply(purrr::array_tree(possible_boards, margin = 1),
                 calc_hashCpp, squaresize = 3)

#should all be unique
which(duplicated(hashes))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## integer(0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In order to play noughts and crosses, we then need some way for a game to end. An easy way to check this is when our board string (0s,1s,and-1s) add up to 3/-3 along any row, column or diagonal.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#first we need a function to check when a game has been won
cppFunction(&amp;#39;int check_winnerCpp(NumericVector board) {
  int winner = 0;

  int vec_length = board.size();
  int square_size = sqrt(vec_length);

  //check rows and columns for a winner
  for (int i=0; i &amp;lt;= square_size - 1; ++i) {
    //check row i
    NumericVector row_squares = NumericVector::create(0,1,2);
    row_squares = row_squares + (square_size * i);
    NumericVector row_elements = board[row_squares];
    int row_sum = sum(row_elements);
    if(abs(row_sum) == square_size) {
      if(row_sum &amp;gt; 0) {
        winner = 1;
      } else {
        winner = -1;
      }
    }
    
    //check col i
    NumericVector col_squares = NumericVector::create(0,3,6);
    col_squares = col_squares + i;
    NumericVector col_elements = board[col_squares];
    int col_sum = sum(col_elements);
    if(abs(col_sum) == square_size) {
      if(col_sum &amp;gt; 0) {
        winner = 1;
      } else {
        winner = -1;
      }
    }
  }
  
  //check the diagonalsNumericVector 
  NumericVector rising_diag_squares = NumericVector::create();
  NumericVector falling_diag_squares = NumericVector::create();
  for (int i=0; i &amp;lt;= square_size - 1; ++i) {
    int rising_diag_square = (square_size * i) + i;
    rising_diag_squares.push_back(rising_diag_square);
    
    int falling_diag_square = (square_size - 1) * (i+1);
    falling_diag_squares.push_back(falling_diag_square);
  }
  
  NumericVector rising_diag_elements = board[rising_diag_squares];
  NumericVector falling_diag_elements = board[falling_diag_squares];
  int rising_sum = sum(rising_diag_elements);
  int falling_sum = sum(falling_diag_elements);
  
  if(abs(falling_sum) == square_size) {
    if(falling_sum &amp;gt; 0) {
      winner = 1;
    } else {
      winner = -1;
    }
  }
  if(abs(rising_sum) == square_size) {
    if(rising_sum &amp;gt; 0) {
      winner = 1;
    } else {
      winner = -1;
    }
  }
    
  //return the winner
  //0 for no winner, 999 for draw
  return winner;
}&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can then apply this function to every possible board and find the ones that indicate a winning state. We also init a data frame containing all possible boards, their hash, and their ‘value’ (0 for all for now, more on this later). Finally, I plot the first one in this set just because why not?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#find which boards are winning positions
winning &amp;lt;- purrr::map(purrr::array_tree(possible_boards, margin = 1), check_winnerCpp)

#going to create a df to store the values of all moves
moves_df &amp;lt;- data.frame(hash = unlist(hashes),
                       value = 0,
                       winning = unlist(winning))

#store all boards as a list
#purrr::aray_tree is a really nice way to convert matrix to lists
moves_df$board = purrr::array_tree(possible_boards, margin = 1)

#plot the first board just why not
plot_board(unlist(moves_df$board[1]))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  o | o | o 
## -----------
##  o | * | x 
## -----------
##  x | x | x&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we can see, we still have some impossible boards here. This particular board will never occur in actual play because X wins before O can make a move to complete the top row. It doesn’t matter, but useful to keep in mind for a plot later.&lt;/p&gt;
&lt;p&gt;We then need a function telling the computer how to make a move. For this post we’re going to use what’s called ‘E (epsilon)-greedy’ selection. A computer has a parameter epsilon such that&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{cases}
    v &amp;amp;\text{if } \epsilon \leq \rho\\
    V_{max} &amp;amp;\text{if } \epsilon &amp;gt; \rho\\
\end{cases} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;if epsilon is greater than a random number rho, the computer makes the most valuable choice possible. It chooses whatever it thinks (rightly or wrongly) will lead to the best outcome. This is called &lt;em&gt;exploitation&lt;/em&gt;. If epsilon is less than or equal to rho, the computer randomly chooses any possible action v. This is known as &lt;em&gt;exploration&lt;/em&gt; to test any possibly rewarding but unvalued paths.&lt;/p&gt;
&lt;p&gt;(I may have gotten epsilon the wrong way round here. It really doesn’t matter at all.)&lt;/p&gt;
&lt;p&gt;Let’s implement this in C++&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cppFunction(&amp;#39;int choose_moveCpp(NumericVector epsilon, NumericVector values) {
  //random number to decide if computer should explore or exploit
  NumericVector random_number = runif(1);
  int move_choice = 0;
  NumericVector choices = NumericVector::create();
  
  //exploit the best move
  if(epsilon[0] &amp;gt; random_number[0]) {
    double max = Rcpp::max(values);
    std::vector&amp;lt; int &amp;gt; res;
    
    int i;
    for(i = 0; i &amp;lt; values.size(); ++i) {
      if(values[i] == max) { 
        res.push_back(i);
      }
    }
    IntegerVector max_indexes(res.begin(), res.end());
    if(max_indexes.size() &amp;gt; 1) {
      std::random_shuffle(max_indexes.begin(), max_indexes.end());
      move_choice = max_indexes[0] + 1;
    } else {
      move_choice = max_indexes[0] + 1;
    }
   //explore all moves randomly
  } else {
    int potential_choices = values.size();
    choices = seq(1, potential_choices);
    std::random_shuffle(choices.begin(), choices.end());
    move_choice = choices[0];
  }
  
  return move_choice;
}&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We also want a little helper func to find all the possible hashes so we can look up which moves a computer can make before choosing between them.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#find all possible next moves
get_next_hashes &amp;lt;- function(board, piece) {
  unused &amp;lt;- which(board == 0)
  
  next_boards &amp;lt;- lapply(unused, function(x, piece) {
    board[x] &amp;lt;- piece
    return(board)
  }, piece = piece)
  #get the hashes of the next boards
  hashes &amp;lt;- lapply(next_boards, calc_hashCpp, squaresize = 3)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we need to reward the computer for making good actions, and punish it for making bad ones. We’ll do this using Temporal Difference (TD) error learning.&lt;/p&gt;
&lt;p&gt;The computer looks at how good an end point was (for noughts and crosses this can be a win, lose, or draw) and then decides if that outcome is better or worse than it was expecting. It then re-evaluates its beliefs about the choices it made to lead to that end state. It can be formulated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[V_{state} = V_{state} + TD  error \cdot scalar \]&lt;/span&gt;
the scalar here is the &lt;em&gt;learning rate&lt;/em&gt; of the computer. Do we want it to forget everything it new about the world seconds earlier and take only the most recent information (1), or update it’s beliefs very slowly (~0). We’ll refer to this as lr in subsequent equations.&lt;/p&gt;
&lt;p&gt;The TD error itself is calculated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[TD error = (\gamma \cdot reward - V_{state}) \]&lt;/span&gt;
Where gamma acts to make sure we don’t overfit too far back into the past. It reduces the reward as you go further back and is set between 0 and 1. The reward here will (e.g.) be 1 if the computer has just won with it’s latest move, otherwise it will be the value of the state the computer might move into.&lt;/p&gt;
&lt;p&gt;Putting these together we get&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ V_{state} = V_{state} + lr \cdot (\gamma \cdot V_{state+1} - V_{state}) \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Let’s implement this using Rcpp&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#function to feed reward back to the agent based on results
cppFunction(&amp;#39;NumericVector backfeed_rewardCpp(NumericVector values, double reward, double learning_rate, double gamma) {
  int states = values.size();
  NumericVector new_values = NumericVector::create();
  
  //go from last state backwards
  for( int state = states-1; state &amp;gt;= 0; state--) {
    double new_value = values[state] + learning_rate * ((gamma * reward) - values[state]);
    new_values.push_back(new_value);
    //recurse the reward
    reward = new_value;
  }
  return new_values;
}&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can start actually playing games! I wrote out a long function in R to play through the various bits. It surely could be refactored a little more concisely but it works for now and I was getting tired by this point.&lt;/p&gt;
&lt;p&gt;We first add two functions (one to make moves/play the game, and one to update the values using the formula above) then put it all into to one uber-function&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#function to choose and implement computer moves
computer_move &amp;lt;- function(piece, board, epsilon) {
  #get potential moves
  potential_move_hashes &amp;lt;- get_next_hashes(board, piece)
  #get the values of the potential moves
  potential_move_vals &amp;lt;- moves_df$value[
    unlist(lapply(potential_move_hashes, function(x) which(moves_df$hash == x)))]
  #choose move based on rewards
  player_move &amp;lt;- choose_moveCpp(epsilon, potential_move_vals)
  #update the board with the new move
  updated_board &amp;lt;- unlist(moves_df$board[
    moves_df$hash == unlist(potential_move_hashes)[player_move]])
  return(updated_board)
}

#function to get the values for each state based on the reward
update_move_vals &amp;lt;- function(player1_reward, player2_reward, 
                             player1_hashes, player2_hashes,
                             learning_rate,gamma) {
  player1_newvals &amp;lt;- backfeed_rewardCpp(moves_df$value[
    unlist(lapply(player1_hashes, function(x) which(moves_df$hash == x)))],
    player1_reward, learning_rate, gamma)
  player2_newvals &amp;lt;- backfeed_rewardCpp(moves_df$value[
    unlist(lapply(player2_hashes, function(x) which(moves_df$hash == x)))],
    player2_reward, learning_rate, gamma)
  new_vals &amp;lt;- list(player1_newvals, player2_newvals)
  return(new_vals)
}

#function to get two computers to play each other
play_game_computers &amp;lt;- function(player1_epsilon, 
                                player2_epsilon,
                                learning_rate, gamma) {
  #init board
  board &amp;lt;- rep(0, squares)
  winner &amp;lt;- 0
  moves &amp;lt;- 0
  #init hash storage
  player1_hashes &amp;lt;- c()
  player2_hashes &amp;lt;- c()
  
  #keep moving until game is over
  while(winner == 0 &amp;amp; moves &amp;lt; 9) {
    #iterate moves
    moves &amp;lt;- moves + 1
    #player 1 moves
    board &amp;lt;- computer_move(1, board, player1_epsilon)
    player1_hashes &amp;lt;- append(calc_hashCpp(board, board_cols), player1_hashes)
    winner &amp;lt;- check_winnerCpp(board)
    
    #same for player 2
    if(winner == 0  &amp;amp; moves &amp;lt; 9) {
      moves &amp;lt;- moves + 1
      board &amp;lt;- computer_move(-1, board, player1_epsilon)
      player2_hashes &amp;lt;- append(calc_hashCpp(board, board_cols), player2_hashes)
      winner &amp;lt;- check_winnerCpp(board)
    }
  }
  
  #update policies
  if(winner == 1) {
    message &amp;lt;- &amp;quot;x wins!&amp;quot;
    new_vals &amp;lt;- update_move_vals(1, 0, player1_hashes, player2_hashes,
                                 learning_rate, gamma)
  } else if(winner == -1) {
    message &amp;lt;- &amp;quot;o wins!&amp;quot;
    new_vals &amp;lt;- update_move_vals(0, 1, player1_hashes, player2_hashes, 
                                 learning_rate, gamma)
  } else {
    message &amp;lt;- &amp;quot;draw!&amp;quot;
    new_vals &amp;lt;- update_move_vals(0.1, 0.5, player1_hashes, player2_hashes, learning_rate, gamma)
  }
  #push the values back into the dictionary data frame
  moves_df$value[unlist(lapply(player1_hashes, function(x) which(moves_df$hash == x)))] &amp;lt;&amp;lt;- new_vals[[1]]
  moves_df$value[unlist(lapply(player2_hashes, function(x) which(moves_df$hash == x)))] &amp;lt;&amp;lt;- new_vals[[2]]
  return(message)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So that the computer can learn the value of moves, we first want to run this on a training epoch. We’ll get the computer to play 100000 games against itself with an epsilon &amp;lt; 1 so that it explores the game state and learns by reinforcement. We’ll then plot the values it’s learn for all moves based upon if they are winning or not.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#test on 10000 games with a little randomness thrown in
train &amp;lt;- purrr::rerun(100000, play_game_computers(0.8, 0.8, 0.35, 0.9))

#test how fast our function is
microbenchmark::microbenchmark(play_game_computers(0.8, 0.8, 0.35, 0.9), times = 1000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Unit: microseconds
##                                      expr   min      lq     mean median
##  play_game_computers(0.8, 0.8, 0.35, 0.9) 838.7 1061.05 1352.258 1222.2
##       uq    max neval
##  1361.45 4548.4  1000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#plot the updated values of moves
p1 &amp;lt;- ggplot(moves_df, aes(x = value, group = as.character(winning))) +
  geom_density(alpha = 0.5, aes(fill = as.character(winning))) +
  scale_fill_manual(values = c(&amp;quot;red&amp;quot;, &amp;quot;blue&amp;quot;, &amp;quot;green&amp;quot;), name = &amp;quot;winning move&amp;quot;) +
  theme_minimal()
p1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-28-Rinforcement_learning_part_1_files/figure-html/train_computer-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Thankfully the computer has learned that winning moves are more valuable than non-winning moves! The reason there are peaks at 0 is because these are ‘winning’ moves that are impossible as referenced nearer the top of the post.&lt;/p&gt;
&lt;p&gt;We’ll then run 2500 testing games where the computer is trying to play optimally. Noughts and crosses is a &lt;a href=&#34;https://en.wikipedia.org/wiki/Solved_game&#34;&gt;solved&lt;/a&gt; game. Unless a play chooses a non-optimal move, the game should end in a draw. Let’s see what proportion actually do end in a draw by grouping every 500 games of the testing set.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#run on an extra 2500 games with no exploration (just exploit)
test &amp;lt;- purrr::rerun(2500, play_game_computers(1, 1, 0.35, 0.9))

#group by each 500 games
test_df &amp;lt;- data.frame(result = unlist(test),
                      group = rep(1:5, each = 500))

#plot percentage of games that are drawn
p2 &amp;lt;- ggplot(test_df, aes(x = group, fill = result)) +
  geom_bar(stat = &amp;quot;count&amp;quot;) +
  labs(x = &amp;quot;group (every 500 games)&amp;quot;) +
  theme_minimal()
p2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-28-Rinforcement_learning_part_1_files/figure-html/test_computer-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And it seems like the computer learns after a final bit of optimisation to always draw! hooray!!&lt;/p&gt;
&lt;p&gt;Finally, because obviously this post wouldn’t be complete without human testing, I wrote a quick and dirty function to play a game against the now proficient computer. Enjoy below!!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;player_move &amp;lt;- function(board){
  #find free spaces a move can be made into
  free_spaces &amp;lt;- which(board == 0)
  cat(&amp;quot;Please move to one of the following board spaces: [&amp;quot;, free_spaces,  &amp;quot;]\n&amp;quot;)
  #user input
  submitted_move &amp;lt;- as.integer(readline(prompt = &amp;quot;&amp;quot;))
  #need valid input
  while(!submitted_move %in% free_spaces) {
    if(submitted_move == 0) {
      break
    } else {
      cat(&amp;quot;Illegal Move! Please move to one of the following board spaces: [&amp;quot;, free_spaces,  &amp;quot;] or press 0 to quit\n&amp;quot;)
      submitted_move &amp;lt;- as.integer(readline(prompt = &amp;quot;&amp;quot;))
    }
  }
  #return move
  return(submitted_move)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#only need a computer epsilon and which piece (turn order)
play_game_human &amp;lt;- function(human_piece, computer_epsilon = 1) {
  board &amp;lt;- rep(0, 9)
  moves &amp;lt;- 0
  winner &amp;lt;- 0
  
  #play the game as before but with a human player
  if (human_piece == 1) {
    while (winner == 0 &amp;amp; moves &amp;lt; 9) {
      moves &amp;lt;- moves + 1
      plot_board(board)
      human_move &amp;lt;- player_move(board)
      
      if (human_move == 0) {
        break
      } else {
        board[human_move] &amp;lt;- human_piece
      }
      i &amp;lt;&amp;lt;- board
      j &amp;lt;&amp;lt;- board
      winner &amp;lt;- check_winnerCpp(board)
      if (winner == 0 &amp;amp; moves &amp;lt; 9) {
        moves &amp;lt;- moves + 1
        piece &amp;lt;- human_piece * -1

        board &amp;lt;- computer_move(-1, board, computer_epsilon)
        winner &amp;lt;- check_winnerCpp(board)
      }
    }
  } else {
    while (winner == 0 &amp;amp; moves &amp;lt; 9) {
      moves &amp;lt;- moves + 1
      piece &amp;lt;- human_piece * -1

      board &amp;lt;- computer_move(-1, board, player1_epsilon)
      winner &amp;lt;- check_winnerCpp(board)

      if (winner == 0 &amp;amp; moves &amp;lt; 9) {
        moves &amp;lt;- moves + 1
        plot_board(board)
        human_move &amp;lt;- player_move(board)
        if (human_move == 0) {
          break
        } else {
          board[human_move] &amp;lt;- human_piece
        }
        winner &amp;lt;- check_winnerCpp(board)
      }
    }
  }
  #little ending flavour
  if (winner == human_piece) {
    print(&amp;quot;you win!!&amp;quot;)
  } else if(winner == -human_piece) {
    print(&amp;quot;oh no! you lost!&amp;quot;)
  } else {
    print(&amp;quot;a draw..&amp;quot;)
  }
  plot_board(board)
}

#run like:
play_game_human(1, 1)&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Predicting the Unpredictable- Analysing Rowing in Cambridge pt. 1</title>
      <link>/post/cam_rowing_1/</link>
      <pubDate>Sun, 24 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/cam_rowing_1/</guid>
      <description>


&lt;p&gt;In my free time away from PhD and data science work, I (used to) enjoy rowing. Aside from obvious benefits like socialising, providing a (very intense) workout, seeing the outdoors at least a few times a week… there are really two things that I love(d) about rowing:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;It’s the sport that is closest to a simple engineering problem. Going fast basically boils down to how in time and how hard you can get 1-8 guys to move an oar through the water. Realistically, you could probably model how good a boat of guys will row just by tracking them on a rowing machine (and I have suspicions that this is what British Rowing etc. do for national teams).&lt;/li&gt;
&lt;li&gt;I learnt to row as an undergraduate at Oxford, and really got serious about it as a postgraduate student at Cambridge. This might seem like a irrelevant detail but it’s not.&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;how-rowing-usually-works&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How rowing usually works&lt;/h1&gt;
&lt;p&gt;Generally when racing boats, some n number of rowing crews line up alongside each other, and row straight down a lake (usually ~2km). The first boat to cross the finish line is generally considered the winner. For an example of such a race, see this Olympic final from 2012:&lt;/p&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://youtu.be/x6wHZNWF7pA?t=655&#34; frameborder=&#34;0&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;p&gt;You might notice that there are four men in each boat here, each of whom are rowing. This works well on a reservoir where this race was held, but not so well on (e.g.) the River Cam that flows through Cambridge, which is both a pretty thin river, and has lots of tight corners.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/img/river_cam.png&#34; alt=&#34;the river cam&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;the river cam&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;how-rowing-in-cambridgeoxford-works&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How rowing in Cambridge/Oxford works&lt;/h1&gt;
&lt;p&gt;Instead of these rivers, boat typically contain 8 rowers, and one cox, who is responsible for steering the boat. In lieu of the space needed to row side by side, various races across the year are run as time trials down a portion of the river. The &lt;em&gt;real&lt;/em&gt; highlight of the year however, are two four day competitions in which crews line up one-behind-the-other and attempt to chase down and ‘bump’ the crew ahead (before being chased down themselves).&lt;/p&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/watch?v=x6N6-B_ob2k&#34; frameborder=&#34;0&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;p&gt;Upon hitting the boat that starts ahead, the two crews switch places the next day and then the race is run again, until hopefully, the positions roughly reflect the speeds of the boats.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;predicting-bumps-races&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Predicting bumps races&lt;/h1&gt;
&lt;p&gt;Generally therefore, if two boats line up for a bumps race, the faster one should catch the slower boat (or if the positions are reversed, the faster boat should fail to be caught by the slower boat behind). It &lt;em&gt;should&lt;/em&gt; be fairly easy to predict bumps races, but it isn’t. The nature of the relative inexperience of lots of crews, the panic of the races, and the pretty tight course means mistakes are made early and often.&lt;/p&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://youtu.be/SCaeOsQmpTs?t=59&#34; frameborder=&#34;0&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;p&gt;However, I wanted to see how possible it was. The only real data to train predictions on are the time-trial races that happen before bumps, so I’m going to see how well it’s possible to model a bumps race using the implied speeds of crews from these previous time trials.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;libraries-and-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Libraries and Data&lt;/h1&gt;
&lt;p&gt;For this post, I’m only going to do some simple munging and logistic regression, so I only need the (new) version of the Tidyverse (as I’m also going to play with pivot_longer and pivot_shorter for the &lt;a href=&#34;&#34;&gt;first time&lt;/a&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The data comes from my own scraping of race results on the river cam over the last ten years. I’ll eventually package this up properly. For now it can be found at &lt;a href=&#34;https://github.com/RobWHickman/CamStroker&#34;&gt;my Github&lt;/a&gt;. Today I’ll just read in the raw .csv files.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#download the raw data
#wil lbe packages eventually
race_results &amp;lt;- read.csv(&amp;quot;https://raw.githubusercontent.com/RobWHickman/CamStroker/master/data-raw/cambridge_race_results.csv&amp;quot;,
                         stringsAsFactors = FALSE)
bumps_results &amp;lt;- read.csv(&amp;quot;https://raw.githubusercontent.com/RobWHickman/CamStroker/master/data-raw/cambridge_bumps_results.csv&amp;quot;,
                          stringsAsFactors = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;data-munging&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data Munging&lt;/h1&gt;
&lt;p&gt;We then want to lengthen out the bumps data by days to squeeze as much data as possible out of possible combinations of boats we have data for. I need to line boats up by the start position each day, so I also init a column for this at the end&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bumps_long &amp;lt;- bumps_results %&amp;gt;%
  #pivot bumps results to longer so we can model each day of racing
  pivot_longer(., starts_with(&amp;quot;Day&amp;quot;),
               names_to = &amp;quot;Day&amp;quot;, values_to = &amp;quot;Bump&amp;quot;) %&amp;gt;%
  mutate(Bump = case_when(
    is.na(Bump) ~ 0,
    TRUE ~ as.numeric(Bump)
  )) %&amp;gt;%
  group_by(Competition, College, Year, Crew, Gender) %&amp;gt;%
  #calculate day start and end positions
  mutate(day_end = StartPos - cumsum(Bump)) %&amp;gt;%
  mutate(day_start = day_end + Bump)

head(bumps_long)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 10
## # Groups:   Competition, College, Year, Crew, Gender [2]
##   Competition College  Year  Crew Gender StartPos Day    Bump day_end
##   &amp;lt;chr&amp;gt;       &amp;lt;chr&amp;gt;   &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;     &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 Lent        Caius    2016    NA M             1 Day1      0       1
## 2 Lent        Caius    2016    NA M             1 Day2      0       1
## 3 Lent        Caius    2016    NA M             1 Day3      0       1
## 4 Lent        Caius    2016    NA M             1 Day4      0       1
## 5 Lent        Downing  2016    NA M             2 Day1      0       2
## 6 Lent        Downing  2016    NA M             2 Day2      0       2
## # ... with 1 more variable: day_start &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And we want to do the opposite for the race data so we can efficiently join this onto the bumps data. As the speed of the crew is all we care about I calculate this as the course distance / seconds taken to get an idea of roughly how fast each crew is.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;race_wide &amp;lt;- race_results %&amp;gt;%
  #calculate implied racing speed
  mutate(race_id = paste(race, leg),
         av_speed = distance / seconds) %&amp;gt;%
  select(Year = year, College = college, Crew = crew, Gender = gender,
         race_id, av_speed) %&amp;gt;%
  pivot_wider(., id_cols = c(&amp;quot;Year&amp;quot;, &amp;quot;College&amp;quot;, &amp;quot;Crew&amp;quot;, &amp;quot;Gender&amp;quot;),
              names_from = race_id, values_from = av_speed) %&amp;gt;%
  #rename to tidy up
  rename(NSC = `Newnham Short Course NA`,
         Frbrn = `Fairbairns NA`,
         WH2H1 = `Winter Head 2 Head leg1`,
         WH2H2 = `Winter Head 2 Head leg2`,
         Rbnsn = `Robinson Head NA`) %&amp;gt;%
  #not much data for Robinson regatta so leave out
  select(-Rbnsn)

head(race_wide)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 8
##    Year College    Crew Gender   NSC Frbrn WH2H1 WH2H2
##   &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;     &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1  2010 Catz          1 M       5.42    NA    NA    NA
## 2  2010 Robinson      1 M       5.41    NA    NA    NA
## 3  2010 Sidney        1 M       5.39    NA    NA    NA
## 4  2010 Caius         1 M       5.38    NA    NA    NA
## 5  2010 Girton        1 M       5.22    NA    NA    NA
## 6  2010 Churchill     1 M       5.21    NA    NA    NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we simply join the data and calculate the implied speed differential between two crew who start a bumps race behind each other.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;regression_data &amp;lt;- bumps_long %&amp;gt;%
  ungroup() %&amp;gt;%
  #join datasets
  left_join(race_wide, by = c(&amp;quot;Year&amp;quot;, &amp;quot;College&amp;quot;, &amp;quot;Crew&amp;quot;, &amp;quot;Gender&amp;quot;)) %&amp;gt;%
  group_by(Competition, Year, Gender, Day) %&amp;gt;%
  arrange(Competition, Year, Gender, Day, day_start) %&amp;gt;%
  #calculate speed difference between boats starting bumps data behind each other
  mutate(frbrn_diff = Frbrn - lag(Frbrn),
         NSC_diff = NSC - lag(NSC),
         WH2H1_diff = WH2H1 - lag(WH2H1),
         WH2H2_diff = WH2H2 - lag(WH2H2)) %&amp;gt;%
  select(-NSC, -Frbrn, -WH2H1, -WH2H2) %&amp;gt;%
  #pivot longer for plotting
  pivot_longer(., frbrn_diff:WH2H2_diff,
               names_to = &amp;quot;race&amp;quot;, values_to = &amp;quot;speed_difference&amp;quot;) %&amp;gt;%
  filter(!is.na(speed_difference)) %&amp;gt;%
  #tidy up plotting data
  filter(Bump %in% c(1, 0)) %&amp;gt;%
  filter(Competition == &amp;quot;Lent&amp;quot;)

head(regression_data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 12
## # Groups:   Competition, Year, Gender, Day [2]
##   Competition College  Year  Crew Gender StartPos Day    Bump day_end
##   &amp;lt;chr&amp;gt;       &amp;lt;chr&amp;gt;   &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;     &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 Lent        Sidney   2010     2 F            40 Day1      1      39
## 2 Lent        Christs  2010     2 F            41 Day1      0      41
## 3 Lent        Sidney   2010     2 F            40 Day2      0      39
## 4 Lent        Christs  2010     2 F            41 Day2      1      40
## 5 Lent        Magdal~  2010     2 F            46 Day2      0      45
## 6 Lent        Newnham  2010     3 F            52 Day2      0      51
## # ... with 3 more variables: day_start &amp;lt;dbl&amp;gt;, race &amp;lt;chr&amp;gt;,
## #   speed_difference &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;plotting-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Plotting Data&lt;/h1&gt;
&lt;p&gt;We can then plot the data and see if the speed differential of races earlier in theyear is a useful predictor of bumping a boat ahead of you. We can model this as a logistic problem where bumping is either a 1 (to catch the boat ahead) or a 0 (did not catch). This does cut out some data in weird ways that I’ll get onto in later posts, but will do for now.&lt;/p&gt;
&lt;p&gt;For the logistic regression I use geom_smooth and a binomial generalised linear model. Again, there’s more we can explore here, but this is just a quick intro post so we won’t worry about standrad error etc. I also split out by Male/Female crews as I imagine gender might play a role.&lt;/p&gt;
&lt;p&gt;Given that this week is the first race of the 2019/2020 calendar (Fairbairns) I first limited myself to only data from that race.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p1 &amp;lt;- regression_data %&amp;gt;%
  #filter only Fairbairns results
  filter(race == &amp;quot;frbrn_diff&amp;quot;) %&amp;gt;%
  ggplot(., aes(x = speed_difference, y = Bump)) +
  geom_point() +
  #model as a logistic event
  geom_smooth(method = &amp;quot;glm&amp;quot;, 
    method.args = list(family = &amp;quot;binomial&amp;quot;), 
    se = FALSE) +
  facet_wrap(~Gender, scales = &amp;quot;free_x&amp;quot;) +
  theme_minimal()

#plot
p1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-24-cambridge_rowing_1_files/figure-html/plot_fairbairns-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And it seems being faster than a boat ahead of you does increase your chance of bumping, but not a huge amount.&lt;/p&gt;
&lt;p&gt;There’s good reason to beleive Fairbairns regatta might not be the best predictor of performance later in the year. It’s the first race, where many collges are still testing out their crew. It also takes place during a weekday, so many students cannot take part, and is a 4.5km race, instead of the usual 2km of later races and bumps itself.&lt;/p&gt;
&lt;p&gt;If we look at how all races predict later bumps success we can see much nicer logistic curves:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#do the same but for all race data
p2 &amp;lt;- regression_data %&amp;gt;%
  ggplot(., aes(x = speed_difference, y = Bump)) +
  geom_point() +
  geom_smooth(method = &amp;quot;glm&amp;quot;, 
    method.args = list(family = &amp;quot;binomial&amp;quot;), 
    se = FALSE) +
  geom_vline(xintercept = 0, colour = &amp;quot;red&amp;quot;, linetype = &amp;quot;dashed&amp;quot;) +
  facet_grid(race~Gender, scales = &amp;quot;free_x&amp;quot;) +
  theme_minimal()

p2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-24-cambridge_rowing_1_files/figure-html/plot_all_races-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Especially Newnham Short Course and the two legs of Winter Head 2 Head show nice curves where boats that are faster on these races have a greater chance of bumping later in the year.&lt;/p&gt;
&lt;p&gt;There’s a lot more to do to properly model a bumps regatta, but the first step of validating our ideas and data seems to show promising results!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Could Yorkshire Win the World Cup</title>
      <link>/project/yorkshire_world_cup/</link>
      <pubDate>Thu, 21 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/project/yorkshire_world_cup/</guid>
      <description>

&lt;p&gt;In 2018, after watching the &lt;a href=&#34;https://en.wikipedia.org/wiki/2018_CONIFA_World_Football_Cup&#34; target=&#34;_blank&#34;&gt;CONIFA World Cup&lt;/a&gt; final live, I wondered if an Independent Yorkshire could win the FIFA World Cup. This resulted in a few blogposts that were turned into an article in &lt;a href=&#34;https://www.citymetric.com/horizons/football-could-independent-yorkshire-win-world-cup-3961&#34; target=&#34;_blank&#34;&gt;Citymetric magazine&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This page lists the blog posts and a one line description of techniques therein. The copies the article text below.&lt;/p&gt;

&lt;h1 id=&#34;blog-posts&#34;&gt;Blog Posts&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.robert-hickman.eu/post/yorkshire_world_cup_1/&#34; target=&#34;_blank&#34;&gt;Data and Scraping&lt;/a&gt; - Grabbing the FIFA video game player data and UK maps&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.robert-hickman.eu/post/yorkshire_world_cup_2/&#34; target=&#34;_blank&#34;&gt;Player Position LASSO&lt;/a&gt; - Using LASSO regression to calculate player abilities in various positions&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.robert-hickman.eu/post/yorkshire_world_cup_3/&#34; target=&#34;_blank&#34;&gt;Finding Birthplaces&lt;/a&gt; - Scraping the birthplaces of British players and binning by county&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.robert-hickman.eu/post/yorkshire_world_cup_4/&#34; target=&#34;_blank&#34;&gt;Picking Teams&lt;/a&gt; - Simulating various lineups to find the best team each nation/county can put out on the field&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.robert-hickman.eu/post/yorkshire_world_cup_5/&#34; target=&#34;_blank&#34;&gt;Simulating World Cup&lt;/a&gt; - Calculate implied county ELO and simulate World Cups to get a sense of the chance of a county winning it&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.robert-hickman.eu/post/yorkshire_world_cup_6/&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Bonus&lt;/em&gt; UK/Rest of the World teams&lt;/a&gt; - Doing the same but for an all UK team/ players from Nations who did not qualify for the World Cup&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;article-text&#34;&gt;Article Text&lt;/h1&gt;

&lt;p&gt;With less than a week until the start of the 2018 World Cup in Russia, it’s worth remembering, that another World Cup – the 2018 ConIFA World Cup for stateless people, minorities, and regions unaffiliated with FIFA - is also taking place in London.&lt;/p&gt;

&lt;p&gt;Though happening in the UK, neither of the local ConIFA members will be competing. The Ellan Vannin team from the Isle of Man withdrew midway; and the latest ConIFA member, Yorkshire, only gained membership earlier this year.&lt;/p&gt;

&lt;p&gt;One of Yorkshire’s most obvious characteristics, is that it’s absolutely huge compared to most other UK counties. It also – probably – has the highest contemporary population of any of the historic British counties. Indeed, as recently as this February the region resisted attempts to split control of the region up, demanding a “One Yorkshire” devolution deal instead of the proposed control to regions surrounding four of it’s major cities – and in May, a vocal proponent of such a “One Yorkshire” devolution, Dan Jarvis, the Labour MP for Barnsley, was elected as mayor of one of the Sheffield City region.&lt;/p&gt;

&lt;p&gt;Given its size, ConIFA membership, and pushes for further devolution, I was wondering how Yorkshire would do as an independent full FIFA member. If it seceded as a whole from the rest of the UK could it field a team that could challenge internationally? Could any of the historic British counties?&lt;/p&gt;

&lt;p&gt;Overall, there are 88 historic counties in Great Britain, plus the 6 counties of Northern Ireland (I couldn’t find shapefiles for the older subdivisions) which could be potential independent FIFA members.&lt;/p&gt;

&lt;p&gt;Once I had these, I needed some way to rate potential players, and therefore teams. Luckily, the popular video game FIFA18 maintains up to date ratings of thousands of players across 36 different stats (e.g. dribbling, heading, pace etc.). After scraping an online database of players, I’m left with 18,058 players of various nationalities and abilities.&lt;/p&gt;

&lt;p&gt;Using a simple regression model, I can use these abilities and the player’s listed preferred positions to predict what each players rating for each position, and use these position ratings to train a computer to pick optimal teams across a variety of formations. If we do this do for every nation that has at least 11 players in the database (10 outfield + 1 goalkeeper), the best 4 national teams that can be fielded are from Brazil, Germany, Spain, and Belgium.&lt;/p&gt;

&lt;p&gt;To pick the teams for each county, though, I first had to find the birthplace of player. To simplify things a bit I only check players listed as English, Scottish, Welsh, Northern Irish, or Irish (due to the weirdness of the Irish FA) in my database of FIFA players. For each of these I ran a script to look the player up on wikipedia and scrape their birthplace. Once this was geocoded, I had a map of each British player and their birthplace, and therefore, the county of their birth.&lt;/p&gt;

&lt;p&gt;Unsurprisingly, it basically shows a population density map of the UK, with more players born in the urban centres of London, Birmingham, the Lancashire cities and the West Yorkshire urban centres. After binning the players by county of birth, twenty historic counties have enough players to field a team.&lt;/p&gt;

&lt;p&gt;On this chart, ‘FIFA_ability’ is the perceived ability of the optimal 11 players in a starting line up for that county, as judged by FIFA stats.&lt;/p&gt;

&lt;p&gt;Perhaps a little surprisingly, the Lancashire team is rated slightly higher than the Yorkshire team – though looking at the sheer number of players they can select from it makes sense. Elsewhere, the home counties do well, as do Glasgow and Warwickshire (which contains much of contemporary Birmingham).&lt;/p&gt;

&lt;p&gt;Looking at the selections the alogirthm chooses, it’s pretty clear some of these teams tend to be a bit flawed but overall make sense. The Yorkshire/Lancashire teams in particular are full of England international players and are lacking only an experienced top level goalkeeper.&lt;/p&gt;

&lt;p&gt;In order to predict how these teams would do at a World Cup, I needed some form of quantifiable rating of a team;s ability. Luckily, ELO ratings in chess can do exactly that: the likelihood of any team A beating a team B is a direct function in the difference in their ELO rating.&lt;/p&gt;

&lt;p&gt;Plotting the ELO ratings of each actual national team (an up to date calculation is maintained at ELOrating.net) against the ability of each national team as judged by FIFA18 shows a pretty clear linear trend. Using a regression model of this relationship, we can predict the ability of each hypothetical county national team.&lt;/p&gt;

&lt;p&gt;When plotted, these ELO ratings show that some of the counties are definitely in the ball park of established world cup qualifiers – and so we might expected a post-super-devolution Britain to be sending multiple teams to the World Cup.&lt;/p&gt;

&lt;p&gt;In fact, Yorkshire and Lancashire are predicted to be about as good as the national teams of Serbia and Sweden. Lagging a bit behind, Essex and Surrey – both of which take in large chunks of what is now London – could expect to be competititve with teams like Turkey and Morocco.&lt;/p&gt;

&lt;p&gt;However, just finding out how good these teams would be wasn’t what I wanted to know. I wanted to see if an independent British county could win the World Cup.&lt;/p&gt;

&lt;p&gt;To do this, I swapped each of these counties in for the national English team and ran 10000 simulations of the post-devolution 2018 World Cup, uusing the same draws and fixtures as the real tournament uses.&lt;/p&gt;

&lt;p&gt;The bad news is, the real-life favourites tend to dominate the simulations. Brazil or Germany were predicted to win the tournament in almost half of all the simulations. On the graph, it;s just possible to make out the red bars of Yorkshire and Lancashire, both of which won 41 out of 10000 simulations (a 0.41 per cent chance of winning any random World Cup).&lt;/p&gt;

&lt;p&gt;This seems pretty low – but is comparable to pretty respectable teams like Denmark (0.775 per cent), Senegal (0.217 per cent), and even higher than the Iceland team which knocked england out of Euro2016 (0.339 per cent). It’s way higher than the chances the simulation gives the Russian hosts (0.07 per cent).&lt;/p&gt;

&lt;p&gt;Scaling down to just these pretty hopeless nations/counties really shows how little hope the independent British counties would have at an international tournament. However, the best four counties (Lancashire, Yorkshire, Essex, and Surrey) all have about a 0.2 per cent or higher chance, or 500-1 odds, at winning the 2018 World Cup were they to replace England at the last minute. This is an order of magnitude greater than the 5000-1 odds given to Leicester City at the start of 2015-2016 Premier League season, so there’s always a chance.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Guardian: The Knowledge</title>
      <link>/project/guardian_knowledge/</link>
      <pubDate>Thu, 21 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/project/guardian_knowledge/</guid>
      <description>

&lt;p&gt;When I have a free afternoon, I enjoy answering the questions listed on The Guardian&amp;rsquo;s &lt;a href=&#34;https://www.theguardian.com/football/series/theknowledge&#34; target=&#34;_blank&#34;&gt;The Knowledge&lt;/a&gt; blog. This munging generally ends up as &lt;a href=&#34;http://www.robert-hickman.eu/post/&#34; target=&#34;_blank&#34;&gt;blogposts&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Here are the current examples I have published:&lt;/p&gt;

&lt;h1 id=&#34;august-2018-http-www-robert-hickman-eu-post-the-knowledge-4th-august-2018&#34;&gt;&lt;a href=&#34;http://www.robert-hickman.eu/post/the-knowledge-4th-august-2018/&#34; target=&#34;_blank&#34;&gt;August 2018&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;Looked at successive runs of fixtures for English clubs against identical suffix/prefixes. Also scraped FIFA World Cup squads and looked at players who played in a lower shirt number than their age.&lt;/p&gt;

&lt;h1 id=&#34;january-2019-http-www-robert-hickman-eu-post-counties-league-points&#34;&gt;&lt;a href=&#34;http://www.robert-hickman.eu/post/counties_league_points/&#34; target=&#34;_blank&#34;&gt;January 2019&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;Grouped football teams by their county and looked at which counties had won the most points over the past 140 years of league football&lt;/p&gt;

&lt;h1 id=&#34;febuary-2019-http-www-robert-hickman-eu-post-the-knowledge-7th-february-2019&#34;&gt;&lt;a href=&#34;http://www.robert-hickman.eu/post/the-knowledge-7th-february-2019/&#34; target=&#34;_blank&#34;&gt;Febuary 2019&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;Answered 4 questions:
- which football players have scored on the most unique days of the year (Cristiano Ronaldo)
- which football teams had finished 2nd in a league the most times (Manchester United in the 1st Division - 14times)
- what is the earliest a team has been relegated from a league the earliest (Rochdale, with 8 games to go in &lt;sup&gt;1973&lt;/sup&gt;&amp;frasl;&lt;sub&gt;1974&lt;/sub&gt;)
- what is the longest run of games without a draw in the English leagues (Aston Villa with 50 games in &lt;sup&gt;1891&lt;/sup&gt;&amp;frasl;&lt;sub&gt;1892&lt;/sub&gt;)&lt;/p&gt;

&lt;h1 id=&#34;june-2019-http-www-robert-hickman-eu-post-guardian-knowledge-june&#34;&gt;&lt;a href=&#34;http://www.robert-hickman.eu/post/guardian_knowledge_june/&#34; target=&#34;_blank&#34;&gt;June 2019&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;A pretty fun post trying to work out the players who had played in the Premier League while representing low ranked countries. It turns out it&amp;rsquo;s pretty difficult to answer conclusively, but it seems that Zesh Rehman (Fulham/Pakistan) in 2005 is the lowest ranked, whereas Christpher Wreh seems to be the player with the lowest ranked nationality to actually win the league&lt;/p&gt;

&lt;p&gt;For these questions I tend to rely on the &lt;a href=&#34;https://github.com/jalapic/engsoccerdata&#34; target=&#34;_blank&#34;&gt;engsoccerdata&lt;/a&gt; package in R, to which I am a frequent contributor. I also tend to do a fair bit of web scraping using simple (and sometimes &lt;a href=&#34;http://www.robert-hickman.eu/post/dynamic_web_scraping/&#34; target=&#34;_blank&#34;&gt;not so simple&lt;/a&gt;) methods.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>R Packages</title>
      <link>/project/r_packages/</link>
      <pubDate>Thu, 21 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/project/r_packages/</guid>
      <description>

&lt;p&gt;Some R packages I have authored. Most/all can be found at my &lt;a href=&#34;https://github.com/RobWHickman&#34; target=&#34;_blank&#34;&gt;Github page&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;karpov&#34;&gt;KaRpov&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;/img/packages/immortal_game.gif&#34; alt=&#34;Immortal Game GIF&#39;d using kaRpov&#34; /&gt;&lt;/p&gt;

&lt;p&gt;A small package in base R to read pgn files of chess matches and turn them into animations of the game using ggplot2. &lt;a href=&#34;https://github.com/RobWHickman/kaRpov&#34; target=&#34;_blank&#34;&gt;https://github.com/RobWHickman/kaRpov&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;ggparliament&#34;&gt;ggparliament&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/RobWHickman/ggparliament/master/man/figures/HexSticker.png&#34; alt=&#34;ggparliament&#34; /&gt;&lt;/p&gt;

&lt;p&gt;An extension to ggplot2 written with Thomas Leeper and Zoe Meers to plot the layour of various parliamentary chambers and their composition by party. Resulted in a &lt;a href=&#34;https://www.theoj.org/joss-papers/joss.01313/10.21105.joss.01313.pdf&#34; target=&#34;_blank&#34;&gt;JOSS paper&lt;/a&gt;. Over 4000 downloads from CRAN and 115 Github stars as of November 2019.&lt;/p&gt;

&lt;h1 id=&#34;jeb&#34;&gt;Jeb!&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/RobWHickman/Jeb/master/man/figure/HexSticker.png&#34; alt=&#34;Jeb!&#34; /&gt;&lt;/p&gt;

&lt;p&gt;A small joke package written to quickly generate maps akin to the &lt;a href=&#34;https://knowyourmeme.com/memes/jeb-wins&#34; target=&#34;_blank&#34;&gt;Jeb wins meme&lt;/a&gt; using sf and ggplot2.&lt;/p&gt;

&lt;h1 id=&#34;epv&#34;&gt;EPV&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/RobWHickman/EPV/master/hex_sticker/HexSticker2.png&#34; alt=&#34;EPV&#34; /&gt;&lt;/p&gt;

&lt;p&gt;A small package to include code from the my work for the 2019 Statsbomb Conference on Expected Threat Models. To be extended into other Expected Posession Value models when time allows.&lt;/p&gt;

&lt;h1 id=&#34;camstroke&#34;&gt;CamStroke&lt;/h1&gt;

&lt;p&gt;A package to download data related to Cambridge collegiate rowing. Contains cleaned results files for various races and data on the various college boat clubs.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Statsbomb Conference</title>
      <link>/project/statsbomb_conference/</link>
      <pubDate>Thu, 21 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/project/statsbomb_conference/</guid>
      <description>

&lt;p&gt;In August 2019, I won the oppurtunity to present a research talk at the inagural &lt;a href=&#34;https://statsbomb.com/conference/&#34; target=&#34;_blank&#34;&gt;Statsbomb football analytics conference&lt;/a&gt;. My proposal focused on &lt;a href=&#34;https://karun.in/blog/expected-threat.html&#34; target=&#34;_blank&#34;&gt;Markov models&lt;/a&gt; of possession value when playing football, and incorporating a risk factor into these models.&lt;/p&gt;

&lt;p&gt;I presented a 25 minute talk on my work at the conference in October 2019. Below is a list of resources related to the project.&lt;/p&gt;

&lt;h1 id=&#34;original-application&#34;&gt;Original Application&lt;/h1&gt;

&lt;p&gt;&amp;lt; to be added &amp;gt;&lt;/p&gt;

&lt;h1 id=&#34;the-talk&#34;&gt;The Talk&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=nzaHaWEa9BA&#34; title=&#34;my talk&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;/img/statsbomb_talk.png&#34; alt=&#34;My Statsbomb Talk Video&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;talk-slides&#34;&gt;Talk Slides&lt;/h1&gt;

&lt;p&gt;&amp;lt; to be added &amp;gt;&lt;/p&gt;

&lt;h1 id=&#34;white-paper&#34;&gt;White Paper&lt;/h1&gt;

&lt;p&gt;currently in the process of writing up a white paper based on the research. Will upload here when completed.&lt;/p&gt;

&lt;h1 id=&#34;r-package&#34;&gt;R Package&lt;/h1&gt;

&lt;p&gt;alongside the white paper, I am putting together an R package to easily reproduce the findings, and also extend into other similar models of possession value. The code can be found &lt;a href=&#34;https://github.com/RobWHickman/EPV&#34; target=&#34;_blank&#34;&gt;on Github&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Racing Bar Charts and Some data.table Munging</title>
      <link>/post/racing_bar_charts/</link>
      <pubDate>Sun, 17 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/racing_bar_charts/</guid>
      <description>


&lt;p&gt;A while ago (and also still a bit) &lt;a href=&#34;https://app.flourish.studio/@flourish/bar-chart-race&#34;&gt;racing bar charts&lt;/a&gt; were all the rage on data visualisation forums/twitter. Perhaps one of the real breakout examples is this tweet from the, always excellent, John Burn-Murdochat the Financial Times, looking at the most populous cities in the world since the middle ages:&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
New project:&lt;br&gt; &lt;br&gt;A “Bar Chart Race” animation showing the changing ranks of the 10 biggest cities in the world since 1500.&lt;br&gt;&lt;br&gt;Fascinating to watch giant cities vanish after falling in conquests, and amazing that three UK cities were in the top 8 in the late 1800s. &lt;a href=&#34;https://t.co/KglMZbYobr&#34;&gt;pic.twitter.com/KglMZbYobr&lt;/a&gt;
&lt;/p&gt;
— John Burn-Murdoch (&lt;span class=&#34;citation&#34;&gt;@jburnmurdoch&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/jburnmurdoch/status/1107552367795412992?ref_src=twsrc%5Etfw&#34;&gt;March 18, 2019&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;As with most things I blog about here I wondered if I could make them in R, and how easy that would be. The first half of this post is basically recreating the aforementioned gif pretty simply using &lt;a href=&#34;https://github.com/thomasp85/gganimate&#34;&gt;gganimate&lt;/a&gt;. However, I also wanted to see if I could use the format to look at the strongest English football teams across history in &lt;a href=&#34;&#34;&gt;link to second half of blogpost&lt;/a&gt; which gave me an unexpected lesson in using &lt;a href=&#34;https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html&#34;&gt;data.table&lt;/a&gt; and especially some lesser used facets of it- ones that might require more complex multiline solutions in the tidyverse.&lt;/p&gt;
&lt;div id=&#34;reproducing-racing-bar-charts-in-r&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Reproducing Racing Bar Charts in R&lt;/h1&gt;
&lt;p&gt;Getting on with actually producing racing bar charts, first we want to load up the libraries we’ll need.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(gganimate)
library(tweenr)
library(stringi)
#for getting the continents of various cities
library(countrycode)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then also grab the data. This isn’t exactly all the data used by John in his tweet but it’s close enough. I can’t remember where I got the data from but similar datasets can be found by googling “world cities populations csv” e.g. &lt;a href=&#34;https://datahub.io/core/population-city&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#read in data from blog repo
city_data &amp;lt;- read.csv(&amp;quot;https://raw.githubusercontent.com/RobWHickman/netlify_blog/race_bar_charts/static/files/racing_bar_charts/city_populations.csv&amp;quot;, 
                 encoding = &amp;quot;UTF-8&amp;quot;, stringsAsFactors = FALSE)

head(city_data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Country.Code Country.or.area City.Code               Urban.Agglomeration
## 1          392           Japan     21671                             Tokyo
## 2          356           India     21228                             Delhi
## 3          156           China     20656                          Shanghai
## 4           76          Brazil     20287                      S&amp;lt;e3&amp;gt;o Paulo
## 5          356           India     21206                   Mumbai (Bombay)
## 6          484          Mexico     21853 Ciudad de M&amp;lt;e9&amp;gt;xico (Mexico City)
##   Note  Latitude Longitude  X1950  X1955  X1960  X1965  X1970  X1975
## 1  325  35.68950 139.69171 11,275 13,713 16,679 20,284 23,298 26,615
## 2  318  28.66667  77.21667  1,369  1,782  2,283  2,845  3,531  4,426
## 3  202  31.22000 121.46000  4,301  5,846  6,820  6,428  6,036  5,627
## 4   NA -23.55000 -46.64000  2,334  3,044  3,970  5,494  7,620  9,614
## 5   NA  19.07398  72.88084  2,857  3,432  4,060  4,854  5,811  7,082
## 6  330  19.42732 -99.14187  3,365  4,294  5,479  6,969  8,831 10,734
##    X1980  X1985  X1990  X1995  X2000  X2005  X2010  X2015  X2020  X2025
## 1 28,549 30,304 32,530 33,587 34,450 35,622 36,834 38,001 38,323 37,876
## 2  5,558  7,325  9,726 12,407 15,732 18,670 21,935 25,703 29,348 32,727
## 3  5,966  6,847  7,823 10,450 13,959 16,763 19,980 23,741 27,137 29,442
## 4 12,089 13,395 14,776 15,913 17,014 18,288 19,660 21,066 22,119 22,899
## 5  8,658 10,391 12,436 14,310 16,367 17,891 19,422 21,043 22,838 25,207
## 6 13,028 14,278 15,642 17,017 18,457 19,276 20,132 20,999 21,868 22,916
##    X2030
## 1 37,190
## 2 36,060
## 3 30,751
## 4 23,444
## 5 27,797
## 6 23,865&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we want to pull out the relevant data and do some melting to get a nice long format data frame of our data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;city_data &amp;lt;- city_data %&amp;gt;%
  #select out relevant columns
  select(country_id = Country.Code, country = Country.or.area,
         city_id = City.Code, city = Urban.Agglomeration,
         X1950, X1955, X1960, X1965, X1970, X1975, X1980, X1985, X1990,
         X1995, X2000, X2005, X2010, X2015, X2020, X2025, X2030) %&amp;gt;%
  #melt the data to long format
  reshape2::melt(id.vars = c(&amp;quot;country_id&amp;quot;, &amp;quot;country&amp;quot;, &amp;quot;city_id&amp;quot;, &amp;quot;city&amp;quot;),
                 variable.name = &amp;quot;year&amp;quot;, value.name = &amp;quot;population&amp;quot;) %&amp;gt;%
  #conver the data into usuable numbers
  mutate(year = as.numeric(gsub(&amp;quot;^X&amp;quot;, &amp;quot;&amp;quot;, year)),
         population = as.numeric(gsub(&amp;quot;,&amp;quot;, &amp;quot;&amp;quot;, population)),
         #convert the text into utf-8 readable
         city = stri_trans_general(city, &amp;quot;latin-ascii&amp;quot;)) %&amp;gt;%
  #extract the english names for cities
  mutate(city_name = case_when(
    grepl(&amp;quot;\\(&amp;quot;, city) ~ str_extract(city,  &amp;quot;(?&amp;lt;=\\().+?(?=\\))&amp;quot;),
    grepl(&amp;quot;-&amp;quot;, city) ~ gsub(&amp;quot;-.*&amp;quot;, &amp;quot;&amp;quot;, city),
    TRUE ~ as.character(city)
  ))

head(city_data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   country_id country city_id                                  city year
## 1        392   Japan   21671                                 Tokyo 1950
## 2        356   India   21228                                 Delhi 1950
## 3        156   China   20656                              Shanghai 1950
## 4         76  Brazil   20287                      S&amp;lt;U+FFFD&amp;gt;o Paulo 1950
## 5        356   India   21206                       Mumbai (Bombay) 1950
## 6        484  Mexico   21853 Ciudad de M&amp;lt;U+FFFD&amp;gt;xico (Mexico City) 1950
##   population        city_name
## 1      11275            Tokyo
## 2       1369            Delhi
## 3       4301         Shanghai
## 4       2334 S&amp;lt;U+FFFD&amp;gt;o Paulo
## 5       2857           Bombay
## 6       3365      Mexico City&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As the y axis of our racing bar chart is going to be the cities rank in terms of population for any given observation year, we need to list cities in order. Using the Tidyverse a simple group_by() and mutating an order column will do the trick&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;city_data &amp;lt;- city_data %&amp;gt;%
  #group by and find order at any point
  group_by(year) %&amp;gt;%
  arrange(-population) %&amp;gt;%
  mutate(order = row_number()) %&amp;gt;%
  ungroup()

head(city_data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 8
##   country_id country city_id city   year population city_name order
##        &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;     &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;     &amp;lt;int&amp;gt;
## 1        392 Japan     21671 Tokyo  2020      38323 Tokyo         1
## 2        392 Japan     21671 Tokyo  2015      38001 Tokyo         1
## 3        392 Japan     21671 Tokyo  2025      37876 Tokyo         1
## 4        392 Japan     21671 Tokyo  2030      37190 Tokyo         1
## 5        392 Japan     21671 Tokyo  2010      36834 Tokyo         1
## 6        356 India     21228 Delhi  2030      36060 Delhi         2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I also wanted to colour the bars by the continent of the city for a little extra aesthetic. Easy to do by joining with the data from countrycode.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#get the id data for each unique city
id_data &amp;lt;- city_data %&amp;gt;%
  select(city_id, city_name, country_id, country) %&amp;gt;%
  unique() %&amp;gt;%
  #find the continent of each city
  mutate(continent = countrycode(.$country, origin = &amp;quot;country.name&amp;quot;, destination = &amp;quot;continent&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we just need to do a final bit of munging on our data. I think in theory it’s possible to do this purely within the gganimate plotting machinery, but I prefer to munge the data outside.&lt;/p&gt;
&lt;p&gt;First we want to select the columns that will be ‘animated’- i.e. the population and the order, and then also the time information (year), and group (city_id). We pre-specify a linear ease (i.e that between time points the numbers increase/decrease linearly per frame).&lt;/p&gt;
&lt;p&gt;Finally I merge in our id data we prepared above and also round off the population numbers to leave a data frame ready for plotting!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#the number of frames the output will contain
frames &amp;lt;- 500

#use tweenr to manually make the naimation frame data
frame_data &amp;lt;- city_data %&amp;gt;%
  group_by(year) %&amp;gt;%
  arrange(-population) %&amp;gt;%
  mutate(order = row_number()) %&amp;gt;%
  #tweenr stuff here
  select(city_id, year, population, order) %&amp;gt;%
  mutate(ease = &amp;quot;linear&amp;quot;) %&amp;gt;%
  tween_elements(., &amp;quot;year&amp;quot;, &amp;quot;city_id&amp;quot;, &amp;quot;ease&amp;quot;, nframes= frames) %&amp;gt;%
  #select out columns
  select(population, order, year, .frame, city_id = .group) %&amp;gt;%
  #merge in id data
  merge(., id_data, by = &amp;#39;city_id&amp;#39;) %&amp;gt;%
  #munge population numbers
  mutate(pop = round(population/1000, 2))

head(frame_data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   city_id population    order     year .frame city_name country_id
## 1   20001    82.0000  849.000 1950.000      0     Herat          4
## 2   20001   565.0000 1213.000 2030.000    500     Herat          4
## 3   20001   101.1290 1141.129 1969.516    122     Herat          4
## 4   20001   245.2500 1510.250 2001.875    324     Herat          4
## 5   20001   178.2581 1314.000 1988.871    243     Herat          4
## 6   20001   335.7419 1516.419 2014.839    405     Herat          4
##       country continent  pop
## 1 Afghanistan      Asia 0.08
## 2 Afghanistan      Asia 0.56
## 3 Afghanistan      Asia 0.10
## 4 Afghanistan      Asia 0.25
## 5 Afghanistan      Asia 0.18
## 6 Afghanistan      Asia 0.34&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we just want to filter out only the information we want to plot (the top 10 cities per year, I use 10.8 so you see cities as they enter the top 10) and use the lesser-spotted geom_tile() geom from ggplot2 which I found is the easiest to manually move about. After some extra aesthetics we then specify the transition_states()- in our case transition based on the year- and some cool little extras like dynamically adjusting the y axis, and also fading bars as they enter and exit the plot.&lt;/p&gt;
&lt;p&gt;At the bottom we then turn this plot into a gif using animate and add a little pause at the start and end.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p_cities &amp;lt;- frame_data %&amp;gt;%
  #only want to plot the top 10
  filter(order &amp;lt; 10.8) %&amp;gt;%
  ggplot(aes(y = order, x = pop)) +
  #hack to plot the moving bars
  #from v helpful answer at
  #https://stackoverflow.com/questions/53162821/
  #animated-sorted-bar-chart-with-bars-overtaking-each-other/53163549
  geom_tile(aes(x = pop/2, width = pop, fill = continent),
            alpha = 0.8, colour = &amp;quot;black&amp;quot;, height = 0.9) +
  geom_text(aes(label = sprintf(&amp;quot;%1.2f&amp;quot;,pop)), hjust = 1) +
  geom_text(aes(x = 0, label = paste(city_name, &amp;quot; &amp;quot;)),
            vjust = 0.2, hjust = 1) +
  #add labels to plot
  labs(title=&amp;#39;{round(as.numeric(closest_state))}&amp;#39;,
       x = &amp;quot;Population (millions)&amp;quot;, y = &amp;quot;&amp;quot;) +
  #y limits at 0-10.5
  #don&amp;#39;t clip as will screw the labels outside the plot
  coord_cartesian(ylim = c(0,10.5), clip = &amp;quot;off&amp;quot;) +
  #flip the y axis
  scale_y_reverse(position = &amp;quot;left&amp;quot;) +
  #theme stuff
  #taken from same stackoverflow answer
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0, size = 22),
        axis.ticks.y = element_blank(),
        axis.text.y  = element_blank(), 
        #make sure labels will be visible
        plot.margin = margin(0,0,0,2.5, &amp;quot;cm&amp;quot;)) +
  #transition by our calculated year
  transition_states(year, transition_length = 1, state_length = 0) +
  #scale x axis as pop increases
  view_follow(fixed_y = TRUE) +
  #fade as bares enter and exit the plot
  exit_fade() +
  enter_fade()

#animate the gif
city_gif &amp;lt;- animate(p_cities, frames, start_pause = 10, end_pause = 20)
#e.g. if you want to save the output
#anim_save(&amp;quot;city_gif.gif&amp;quot;, city_gif)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And voilà! here is our gif&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;city_gif&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-17-gnarly_data_table_bar_charts_files/figure-html/plot_city_gif-1.gif&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;soccer-through-the-ages&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Soccer Through the Ages&lt;/h1&gt;
&lt;p&gt;So as I mentioned, I wanted the example to be a plot of how English football teams have risen and fallen in strength over the ~150 years the league has been playing. This turned out to be more difficult than I anticipated so also gives a nice little extension to using data.table beyond the basic i,j,k syntax.&lt;/p&gt;
&lt;p&gt;For this we need James Curley’s engsoccerdata package and then also data.table and zoo for munging our data&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#use James Curley&amp;#39;s engsoccer data for the match data
#club data and updated english football dat ain latest release
#November 2019
library(engsoccerdata)

#data.table and zoo for munging
library(data.table)
library(zoo)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we want to select only the relevant bits of the data for calculating the &lt;a href=&#34;https://en.wikipedia.org/wiki/Elo_rating_system&#34;&gt;ELO&lt;/a&gt; ratings of teams on a match-by-match basis. For this I use the formula used by the folks who calculate the national football ELO ratings at &lt;a href=&#34;https://www.eloratings.net/about&#34;&gt;eloratings.net&lt;/a&gt; so if you’re confused by what K and G mean look there.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#some dates in the engsoccerdata::england data are off
#original should work by time of reading
#match_data &amp;lt;- engsoccerdata:;england %&amp;gt;%
match_data &amp;lt;- readRDS(&amp;quot;../../static/files/racing_bar_charts/england_data.rds&amp;quot;) %&amp;gt;%
  mutate(date = as.Date(Date)) %&amp;gt;%
  select(date, season = Season, home, visitor, tier, hgoal, vgoal, result) %&amp;gt;%
  mutate(K = (5-tier) * 10) %&amp;gt;%
  mutate(G = case_when(
    abs(hgoal-vgoal) &amp;lt; 2 ~ 1,
    abs(hgoal-vgoal) &amp;lt; 3 ~ 1.5,
    abs(hgoal-vgoal) &amp;gt;= 3 ~ (11 + abs(hgoal-vgoal)) / 8
  )) %&amp;gt;%
  mutate(result = case_when(
    result == &amp;quot;H&amp;quot; ~ 1,
    result == &amp;quot;A&amp;quot; ~ 0,
    result == &amp;quot;D&amp;quot; ~ 0.5
  )) %&amp;gt;%
  arrange(date)

head(match_data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         date season                    home              visitor tier
## 1 1888-09-08   1888        Bolton Wanderers         Derby County    1
## 2 1888-09-08   1888                 Everton      Accrington F.C.    1
## 3 1888-09-08   1888       Preston North End              Burnley    1
## 4 1888-09-08   1888              Stoke City West Bromwich Albion    1
## 5 1888-09-08   1888 Wolverhampton Wanderers          Aston Villa    1
## 6 1888-09-15   1888             Aston Villa           Stoke City    1
##   hgoal vgoal result  K     G
## 1     3     6    0.0 40 1.750
## 2     2     1    1.0 40 1.000
## 3     5     2    1.0 40 1.750
## 4     0     2    0.0 40 1.500
## 5     1     1    0.5 40 1.000
## 6     5     1    1.0 40 1.875&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can then define a quick function to update ELO ratings based on the match results and push out the updated ratings to a data frame holding the current rating over time. This will take a few minutes given how many matches we have so it’s worth going to make a cup of tea while it runs.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#start all teams with an ELO of 1000
team_ratings &amp;lt;- data.frame(team = unique(match_data$home),
                           rating = 1000)

#function to calculate team ELO and update back to the ratings df
calc_ELO &amp;lt;- function(row) {
  #get the difference in ratings
  hr &amp;lt;- team_ratings$rating[which(team_ratings$team == row$home)]
  vr &amp;lt;- team_ratings$rating[which(team_ratings$team == row$visitor)]
  dr &amp;lt;- (hr + 100) - vr
  
  e_result &amp;lt;- 1/ (10^(-dr/400)+1)
  new_hr &amp;lt;- hr + ((row$K*row$G) * (row$result - e_result))
  new_vr &amp;lt;- vr + ((row$K*row$G) * ((1-row$result) - (1-e_result)))
  
  team_ratings$rating[which(team_ratings$team == row$home)] &amp;lt;&amp;lt;- new_hr
  team_ratings$rating[which(team_ratings$team == row$visitor)] &amp;lt;&amp;lt;- new_vr
  
  output_row &amp;lt;- row %&amp;gt;%
    mutate(h_rating = new_hr, v_rating = new_vr)
  
  return(output_row)
}

#split and lapply function
elo_data &amp;lt;- match_data %&amp;gt;%
  split(f = seq(nrow(.))) %&amp;gt;%
  lapply(., calc_ELO) %&amp;gt;%
  do.call(rbind, .)

#melt the elo data
melted_elo_data &amp;lt;- elo_data %&amp;gt;%
  select(date, season, home, visitor, h_rating, v_rating) %&amp;gt;%
  reshape2::melt(id.vars = c(&amp;quot;date&amp;quot;, &amp;quot;season&amp;quot;, &amp;quot;h_rating&amp;quot;, &amp;quot;v_rating&amp;quot;),
                 variable.name = &amp;quot;location&amp;quot;, value.name = &amp;quot;team&amp;quot;) %&amp;gt;%
  mutate(rating = case_when(
    location == &amp;quot;home&amp;quot; ~ h_rating,
    location == &amp;quot;visitor&amp;quot; ~ v_rating
  )) %&amp;gt;%
  select(date, season, team, rating)

#df of each teams rating after each game day
head(melted_elo_data)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we have our ELO ratings for each team updated after every match, we can start munging the data to plot the racing bar chart. Most of this is fairly standard data.table munging but there’s an operation up top that I was pretty pleased with.&lt;/p&gt;
&lt;p&gt;The English football season typically runs from mid August until mid May. Given that teams do not play competitive matches in this time, it gives 3 months of dead space where team ratings shouldn’t change which is going to be pretty boring in our final gif.&lt;/p&gt;
&lt;p&gt;Therefore, I wanted to find out the total time within each season- i.e. the first match in any division in English football to the last match in any division (as different leagues may start and end on different dates). Therefore we need to find the minimum and maximum date value for each season and seq between them.&lt;/p&gt;
&lt;p&gt;You could in theory do this using ddply- see &lt;a href=&#34;https://stackoverflow.com/questions/16573995/subset-by-group-with-data-table&#34;&gt;a question asked by Hadley Wickham on Stack Overflow&lt;/a&gt; but it’s a) quicker in data.table and also I think the one line aspect to do everything is super pleasing.&lt;/p&gt;
&lt;p&gt;We know once we have the row numbers for the min date we can easily subset based using them in data.table such as&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dt_data[subset_condition, values_needed]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;but we need to actually find the row numbers for the subset condition to use in i. We can do this in a 3.5 step process as follows:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;re supply the data (melted_elo_data)&lt;/li&gt;
&lt;li&gt;add a column of the condition of the minimum data using .I[which.min(date)]
(2.5) do this by season as we need it for every season&lt;/li&gt;
&lt;li&gt;keep only this new minimum date information by selecting the newly initialised V1 column&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;/img/datatableI.png&#34; /&gt;
We then also do this for the max date in each sequence and use map2 to sequence between each min and max date (could also use mapply but I just prefer map2s syntax).&lt;/p&gt;
&lt;p&gt;We then have to make sure that every team is listed for every date so after joining the data.table of team rating information with the data.table of dates, we want to cross-join (CJ) by date and team. I;d never actually used cross-join before, but it’s essentially the equivalent of tidyr::complete().&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;setDT(melted_elo_data)

#get the min and max date for each season and seq between them
days &amp;lt;- map2(melted_elo_data[melted_elo_data[, .I[which.min(date)], by = &amp;quot;season&amp;quot;]$V1, date], 
             melted_elo_data[melted_elo_data[, .I[which.max(date)], by = &amp;quot;season&amp;quot;]$V1, date],
             seq.Date, by = &amp;quot;day&amp;quot;) %&amp;gt;%
  #unlist screws up dates
  do.call(&amp;quot;c&amp;quot;, .) %&amp;gt;%
  #convert to dt for joining
  data.table(date = .)

#expand the dt by dates
#join each date first
munged_football_data &amp;lt;- melted_elo_data[days, on = &amp;quot;date&amp;quot;] %&amp;gt;%
  #cross-join so that every team is represented on every date
  #equivelant of tidyr::complete
  .[CJ(date = date, team = team, unique=TRUE), 
    on=.(date, team)] %&amp;gt;%
  #filter out the completion of NA team for dates
  .[!is.na(team)] %&amp;gt;%
  #also a a column for the calendar year by rejoining based on date
  .[days[, year := as.numeric(gsub(&amp;quot;-.*&amp;quot;, &amp;quot;&amp;quot;, date))], 
    on = &amp;quot;date&amp;quot;, allow.cartesian = TRUE]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we need to use gganimate::tween() again to fill in the missing ratings in the days where teams aren’t playing. Luckily, gganimate contains tween_fill which is perfect for this and plays nicely with data.table. I tween the ratings linearly between matches (and also take a rolling mean), and tween the positions using a cubic function so teams spend a little more time roughly in a nice plotting order.&lt;/p&gt;
&lt;p&gt;After that, all that’s left is to order the frames properly and we’re almost read for plotting!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;munged_football_data &amp;lt;- munged_football_data %&amp;gt;%
  .[order(date)] %&amp;gt;%
  #use tween fill for each team to get intermediate ratings
  .[, rating := tween_fill(rating, ease = &amp;quot;linear&amp;quot;), by = team] %&amp;gt;%
  .[, rating := na.locf(rating, na.rm = FALSE), by = &amp;quot;team&amp;quot;] %&amp;gt;%
  .[, frame := .GRP, by = date] %&amp;gt;%
  #take every 5th frame to cut down on final gif size
  #not strictly necessary
  .[frame %% 5 == 1] %&amp;gt;%
  #take the rolling mean over 30 days to smooth out jumps
  .[order(date), 
    roll_rating := frollmean(rating, n = 6, algo = &amp;quot;exact&amp;quot;, align = &amp;quot;left&amp;quot;),
    by = &amp;quot;team&amp;quot;] %&amp;gt;%
  #remove unrated rows
  .[!is.na(roll_rating)] %&amp;gt;%
    #order by rolling rating
  .[order(-roll_rating)] %&amp;gt;%
  #rating stransition over a 10 day window
  #order by rating (as with the cities when rating by size)
  .[frame %% 30 == 1, team_order := 1:.N, by = date] %&amp;gt;%
  #use tweenr to make transitions smooth
  .[order(date), 
    order_fill := tween_fill(team_order, ease = &amp;quot;cubic-in-out&amp;quot;),
    by = team] %&amp;gt;%
  .[!is.na(order_fill)] %&amp;gt;%
  .[order(date)] %&amp;gt;%
  .[frame != lag(frame, default = 0), year_frame := 1:.N, by = year] %&amp;gt;%
  #fill down
  .[, year_frame := na.locf(year_frame)] %&amp;gt;%
  #frame is the season plus the amount through that season
  #could probably do something fancy and label as unique days but this suffices
  .[, year_frame := year + year_frame/(max(year_frame) + 1)] %&amp;gt;%
  .[, c(&amp;quot;date&amp;quot;, &amp;quot;team&amp;quot;, &amp;quot;roll_rating&amp;quot;, &amp;quot;order_fill&amp;quot;, &amp;quot;year_frame&amp;quot;)]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To plot, first I join in data from engosccerdata::club_data which is a new dataset of some basic information for English football clubs that’s new to the package. It contains a primary and secondary colour for each club so adds a little bit of extra aesthetic to the final gif. Then I basically plot as before using geom_tile() from ggplot()&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#use the newly added club data from engsoccerdata
plotting_data &amp;lt;- engsoccerdata::england_club_data %&amp;gt;%
  #filter only teams we have in our dataset
  filter(team %in% munged_football_data$team) %&amp;gt;%
  #join
  munged_football_data[., on = &amp;quot;team&amp;quot;] %&amp;gt;%
  #only plot a cutdown here as gifs are large
  filter(date &amp;gt; &amp;quot;2015-07-01&amp;quot;) %&amp;gt;%
  #only want to plot the top 10
  filter(order_fill &amp;lt; 10.8)

#get the colour and fill palettes from the plotting data
palette &amp;lt;- plotting_data %&amp;gt;%
  filter(!duplicated(team)) 
fills &amp;lt;- palette %&amp;gt;%
  .$col1 %&amp;gt;%
  as.character() %&amp;gt;%
  `names&amp;lt;-`(palette$team)
cols &amp;lt;- palette %&amp;gt;%
  .$col2 %&amp;gt;%
  as.character() %&amp;gt;%
  `names&amp;lt;-`(palette$team)

#plot roughly as before
p_football &amp;lt;- plotting_data %&amp;gt;%
  ggplot(aes(y = order_fill, x = roll_rating, fill = team, colour = team)) +
  geom_tile(aes(x = roll_rating/2, width = roll_rating),
            alpha = 0.8, height = 0.9, size = 1) +
  geom_text(aes(x = 0, label = paste(short_name, &amp;quot; &amp;quot;)),
            vjust = 0.2, hjust = 1, colour = &amp;quot;black&amp;quot;) +
  geom_text(aes(label = sprintf(&amp;quot;%1.2f&amp;quot;,roll_rating)), 
            hjust = 1.5, colour = &amp;quot;black&amp;quot;) +
  scale_fill_manual(values = fills, guide = FALSE) +
  scale_colour_manual(values = cols, guide = FALSE) +
  labs(title=&amp;#39;{as.character(current_frame)}&amp;#39;,
       x = &amp;quot;ELO rating&amp;quot;, y = &amp;quot;&amp;quot;) +
  coord_cartesian(ylim = c(0,10.5), clip = &amp;quot;off&amp;quot;) +
  scale_y_reverse(position = &amp;quot;left&amp;quot;) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0, size = 22),
        axis.ticks.y = element_blank(),
        axis.text.y  = element_blank(), 
        plot.margin = margin(0,0,0,2.5, &amp;quot;cm&amp;quot;)) +
  transition_manual(date) +
  view_follow(fixed_y = TRUE)

#animate the gif
football_gif &amp;lt;- animate(p_football, 
                        nframes = length(unique(plotting_data$year_frame)),
                        fps = 10,
                        end_pause = 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;football_gif&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-17-gnarly_data_table_bar_charts_files/figure-html/football_gif-1.gif&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Anyway, cheers. It was a fun one to play around with. I’ll put the full gifs of 1880-2019 online at some point!&lt;/p&gt;
&lt;p&gt;Best,&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Considering Defensive Risk in Expected Threat Models</title>
      <link>/talk/statsbomb_conference_talk/</link>
      <pubDate>Fri, 11 Oct 2019 00:00:00 +0100</pubDate>
      
      <guid>/talk/statsbomb_conference_talk/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Scraping Dynamic Websites with PhantomJS</title>
      <link>/post/dynamic_web_scraping/</link>
      <pubDate>Sat, 06 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/dynamic_web_scraping/</guid>
      <description>


&lt;p&gt;For &lt;a href=&#34;http://www.robert-hickman.eu/post/guardian_knowledge_june&#34;&gt;a recent blogpost&lt;/a&gt;, I required data on the ELO ratings of national football teams over time. Such a list exists online at &lt;a href=&#34;https://eloratings.net/&#34;&gt;eloratings.net&lt;/a&gt; and so in theory this was just a simple task for &lt;a href=&#34;https://blog.rstudio.com/2014/11/24/rvest-easy-web-scraping-with-r/&#34;&gt;rvest&lt;/a&gt; to read the html pages on that site and then fish out the data I wanted. However, while this works for the static websites which make up the vast majority of sites containing tables of data, it struggles with websites that use JavaScript to dynamically generate pages.&lt;/p&gt;
&lt;p&gt;Eloratings.net is one such website which rvest is unable to scrape. E.g.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(rvest)

# url to data on Brazil&amp;#39;s ELO rating over time
url &amp;lt;- &amp;quot;https://eloratings.net/Brazil&amp;quot;

read &amp;lt;- read_html(url) %&amp;gt;%
  # this is the CSS selector for the page title
  html_nodes(&amp;quot;#mainheader&amp;quot;)

read&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## {xml_nodeset (1)}
## [1] &amp;lt;h1 id=&amp;quot;mainheader&amp;quot; class=&amp;quot;mainheader&amp;quot;&amp;gt;&amp;lt;/h1&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;does not manage to capture the data displayed in the page mainheader (it ‘should’ return “World Football Elo Ratings: Brazil” from the title of that page).&lt;/p&gt;
&lt;p&gt;Instead, what we want to do is save a copy of the generated page as a .html file and then read that into R using read_html(). Luckily, a way exists to do just that, using the (now deprecated, but still working) &lt;a href=&#34;http://phantomjs.org/&#34;&gt;PhantomJS headless browser&lt;/a&gt;. Much of the code I used to get going with this is adapted from a tutorial &lt;a href=&#34;https://velaco.github.io/how-to-scrape-data-from-javascript-websites-with-R/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;First you want to install PhantomJS from the above website and run through it’s &lt;a href=&#34;http://phantomjs.org/quick-start.html&#34;&gt;quick start guide&lt;/a&gt;. This is a pretty thorough guide, I would say that there are really only three steps from installation to getting going:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;a href=&#34;https://www.howtogeek.com/118594/how-to-edit-your-system-path-for-easy-command-line-access/&#34;&gt;Add phantomjs to the system PATH&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Open a text editor and save one of the &lt;a href=&#34;https://phantomjs.org/quick-start.html&#34;&gt;tutorial scripts&lt;/a&gt; as filename.js&lt;/li&gt;
&lt;li&gt;run &amp;gt; phantomjs C:/Users/usr/path/to/file.js
in a command line console&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The file we’re going to use to render the js pages and then save the html is below:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;// scrapes a given url (for eloratings.net)

// create a webpage object
var page = require(&amp;#39;webpage&amp;#39;).create(),
  system = require(&amp;#39;system&amp;#39;)

// the url for each country provided as an argument
country= system.args[1];

// include the File System module for writing to files
var fs = require(&amp;#39;fs&amp;#39;);

// specify source and path to output file
// we&amp;#39;ll just overwirte iteratively to a page in the same directory
var path = &amp;#39;elopage.html&amp;#39;

page.open(country, function (status) {
  var content = page.content;
  fs.write(path,content,&amp;#39;w&amp;#39;)
  phantom.exit();
});&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(which, again, is stolen and adapted from &lt;a href=&#34;https://velaco.github.io/how-to-scrape-data-from-javascript-websites-with-R/&#34;&gt;here&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;This is saved as scrape_ELO.js in the static directory of my blog folder.&lt;/p&gt;
&lt;p&gt;To keep everything in R, we can use the system() family of functions, which provides access to the OS command line. Though the referenced tutorial uses system(), it relies on scraping a single referenced page. To iteratively scrape every country, we’ll need to provide an argument (country) which will contain the link to the page on eloratings.net for that country.&lt;/p&gt;
&lt;p&gt;E.g. for Brazil we will provide “&lt;a href=&#34;https://www.eloratings.net/Brazil&#34; class=&#34;uri&#34;&gt;https://www.eloratings.net/Brazil&lt;/a&gt;” as the country argument&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;phantom_dir &amp;lt;- &amp;quot;C:/Users/path/to/scrape_ELO/&amp;quot;
country_url &amp;lt;- &amp;quot;https://www.eloratings.net/Brazil&amp;quot;

# use system2 to invoke phantomjs via it&amp;#39;s executable
system2(&amp;quot;C:/Users/path/to/phantomjs-2.1.1-windows/bin/phantomjs.exe&amp;quot;,
        #provide the path to the scraping script and the country url as argument
        args = c(file.path(phantom_dir, &amp;quot;scrape_ELO.js&amp;quot;), country_url))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can then read in this saved html page using rvest as per usual and recover the information therein.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# read in the saved html file
page &amp;lt;- read_html(&amp;quot;elopage.html&amp;quot;)

# scrape with rvest as normal
country_name &amp;lt;- page %&amp;gt;%
  html_nodes(&amp;quot;#mainheader&amp;quot;) %&amp;gt;%
  html_text() %&amp;gt;%
  gsub(&amp;quot;Elo Ratings: &amp;quot;, &amp;quot;&amp;quot;, .)

country_name&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Brazil&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’m not going to include my full script for scraping eloratings.net as usually a reason for doing this obscuring of the data is to prevent exactly what I’m doing. Instead I’ll give a skeleton function of the one I use. If you are having problems with setting up phantomjs to scrape pages, my contact details are listed on my &lt;a href=&#34;http://www.robert-hickman.eu/&#34;&gt;blog homepage&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;scrape_nation &amp;lt;- function(country) {
  # download the page
  url &amp;lt;- paste0(&amp;quot;https://eloratings.net/&amp;quot;, country)
  system2(&amp;quot;C:/Users/path/to/phantomjs-2.1.1-windows/bin/phantomjs.exe&amp;quot;, 
          args = c(file.path(phantom_dir, &amp;quot;scrape_ELO.js&amp;quot;), url))
  
  # read in downloaded page
  page &amp;lt;- read_html(&amp;quot;elopage.html&amp;quot;)
  
  # recover information
  country_name &amp;lt;- page %&amp;gt;%
    html_nodes(&amp;quot;#mainheader&amp;quot;) %&amp;gt;%
    html_text() %&amp;gt;%
    gsub(&amp;quot;Elo Ratings: &amp;quot;, &amp;quot;&amp;quot;, .)
  
  opposing &amp;lt;- page %&amp;gt;%
      html_nodes(&amp;quot;.r1 a&amp;quot;) %&amp;gt;%
      html_text()
  
  teams &amp;lt;- page %&amp;gt;%
      html_nodes(&amp;quot;.r1&amp;quot;)
  
  fixtures &amp;lt;- map2_df(teams, opposing, split_teams)

  ratings &amp;lt;- page %&amp;gt;%
    html_nodes(&amp;quot;.r4&amp;quot;) %&amp;gt;%
    html_text() %&amp;gt;%
    map_df(., split_ratings)
  
  rankings &amp;lt;- page %&amp;gt;%
    html_nodes(&amp;quot;.r6&amp;quot;) %&amp;gt;%
    map_df(., split_rankings)

  dates &amp;lt;- page %&amp;gt;%
    html_nodes(&amp;quot;.r0&amp;quot;) %&amp;gt;%
    html_text() %&amp;gt;%
    map_df(., convert_date)

  # bind into a data frame
  df &amp;lt;- fixtures %&amp;gt;%
    cbind(., ratings) %&amp;gt;%
    cbind(., rankings) %&amp;gt;%
    cbind(., dates) %&amp;gt;%
    mutate(table_country = country_name)
}

elO_data &amp;lt;- map_df(country_links, scrape_nation)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we want to convert this to long format. We have two observations per country and any point in time- the rating, and the ranking. For &lt;a href=&#34;http://www.robert-hickman.eu/post/guardian_knowledge_june&#34;&gt;the blogpost I needed the data for&lt;/a&gt; I took just the ranking data in the end. Here, I’m going to do the opposite and take only the rating data to make a nice little plot of national teams ratings over time&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;elo_data %&amp;lt;&amp;gt;%
  mutate(date = as.Date(date)) %&amp;gt;%
  # rename and select variables
  select(
    date,
    home, away,
    rating_home = r1, rating_away = r2,
    ranking_home = ranking1, ranking_away = ranking2
  ) %&amp;gt;%
  # melt twice to convert to long format
  gather(
    &amp;quot;location&amp;quot;, &amp;quot;nation&amp;quot;,
    -rating_home, -rating_away, -ranking_home, -ranking_away, -date
  ) %&amp;gt;%
  gather(&amp;quot;measure&amp;quot;, &amp;quot;value&amp;quot;, -nation, -date, -location) %&amp;gt;%
  # take only relevant information
  filter(
    (location == &amp;quot;home&amp;quot; &amp;amp; measure %in% c(&amp;quot;rating_home&amp;quot;, &amp;quot;ranking_home&amp;quot;)) |
      (location == &amp;quot;away&amp;quot; &amp;amp; measure %in% c(&amp;quot;rating_away&amp;quot;, &amp;quot;ranking_away&amp;quot;))
  ) %&amp;gt;%
  separate(measure, into = c(&amp;quot;measure&amp;quot;, &amp;quot;location&amp;quot;), &amp;quot;_&amp;quot;) %&amp;gt;%
  # filter out relevant data
  filter(!duplicated(.)) %&amp;gt;%
  filter(date &amp;gt; &amp;quot;1950-01-01&amp;quot;) %&amp;gt;%
  filter(measure == &amp;quot;rating&amp;quot;) %&amp;gt;%
  select(-measure, rating = value, -location)

# print the df
head(elo_data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         date nation rating
## 1 1950-05-06 Brazil   1957
## 2 1950-05-07 Brazil   1969
## 3 1950-05-13 Brazil   1961
## 4 1950-05-14 Brazil   1965
## 5 1950-05-18 Brazil   1969
## 6 1950-06-24 Brazil   1991&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To cap off this little post, I decided to use &lt;a href=&#34;https://github.com/thomasp85/gganimate&#34;&gt;gganimate&lt;/a&gt; to show how the ratings of some nations have changed over time. It’s a nice little sanity test that we’ve scraped data correctly, but also, as a football nerd, I enjoy seeing how nations have risen and fallen over the years&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(gganimate)

p &amp;lt;- elo_data %&amp;gt;%
  # select out a few nations
  filter(nation %in% c(
    &amp;quot;Brazil&amp;quot;,
    &amp;quot;England&amp;quot;,
    &amp;quot;Canada&amp;quot;,
    &amp;quot;Hungary&amp;quot;,
    &amp;quot;Nigeria&amp;quot;,
    &amp;quot;Japan&amp;quot;
  )) %&amp;gt;%
  # going to take the average over every 4 months
  # could use zoo::rollmean but also want to cut down plotting
  mutate(month = as.numeric(format(date, &amp;quot;%m&amp;quot;)),
         year = as.numeric(format(date, &amp;quot;%Y&amp;quot;))) %&amp;gt;%
  mutate(third = case_when(
    month &amp;lt; 5 ~ 0,
    month &amp;lt; 9 ~ 33,
    TRUE ~ 66
  )) %&amp;gt;%
  mutate(year = as.numeric(paste0(year, &amp;quot;.&amp;quot;, third))) %&amp;gt;%
  group_by(nation, year) %&amp;gt;%
  summarise(rating_av = mean(rating)) %&amp;gt;%
  ungroup() %&amp;gt;%
  # pipe into ggplot
  ggplot(aes(x = year, y = rating_av, group = nation)) +
  # coloured line per nations
  geom_line(size = 1.5, aes(colour = nation)) +
  scale_colour_manual(values = c(&amp;quot;goldenrod&amp;quot;, &amp;quot;red&amp;quot;, &amp;quot;grey60&amp;quot;, &amp;quot;green&amp;quot;, &amp;quot;darkblue&amp;quot;, &amp;quot;forestgreen&amp;quot;)) +
  labs(title = &amp;quot;ELO Rating of Selected Nations over Time&amp;quot;,
       subtitle = &amp;quot;date from eloratings.net&amp;quot;,
       x = &amp;quot;year&amp;quot;,
       y = &amp;quot;ELO rating&amp;quot;) +
  theme_minimal() +
  theme(legend.position=&amp;quot;bottom&amp;quot;) +
  # gganimate reveal
  transition_reveal(year)

# save the gif
gif &amp;lt;- animate(p, nframes = 20)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Which if we render gives us&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/img/nation_elo_gif.gif&#34; alt=&#34;nation elo&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;nation elo&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;And the data looks good! The &lt;a href=&#34;https://en.wikipedia.org/wiki/Golden_Team&#34;&gt;Mighty Magyar&lt;/a&gt; Hungary team of the 1950s can be seen to peak before the nations long decline, whereas the opposite is true for Japan. Overall, I’m pretty happy with the result. It could surely be cleaned up using rolling means and more careful plotting, but for a small example to plot the output from the scraping (the real point for this post) it serves a purpose.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Guardian Knowledge June 2019</title>
      <link>/post/guardian_knowledge_june/</link>
      <pubDate>Sat, 06 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/guardian_knowledge_june/</guid>
      <description>


&lt;p&gt;Most Wednesday’s I enjoy reading &lt;a href=&#34;https://www.theguardian.com/football/series/theknowledge&#34;&gt;The Knowledge&lt;/a&gt; blog on the Guardian’s website and reading the football trivia therein. When time (and questions) allow, I like to answer some of the questions posed, example of which are &lt;a href=&#34;http://www.robert-hickman.eu/post/the-knowledge-4th-august-2018/&#34;&gt;here&lt;/a&gt;, &lt;a href=&#34;http://www.robert-hickman.eu/post/counties_league_points/&#34;&gt;here&lt;/a&gt;, and &lt;a href=&#34;http://www.robert-hickman.eu/post/the-knowledge-7th-february-2019/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;league-of-nations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;League of Nations&lt;/h1&gt;
&lt;p&gt;The first question comes from&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;en&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
Which player had the nationality with the lowest FIFA World Ranking at the time of him winning the Premier League?
&lt;/p&gt;
— The Tin Boonie (&lt;span class=&#34;citation&#34;&gt;@TheTinBoonie&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/TheTinBoonie/status/1140936272862691328?ref_src=twsrc%5Etfw&#34;&gt;June 18, 2019&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;a similar question is also answered in this weeks column:&lt;/p&gt;
&lt;p&gt;‘&lt;em&gt;“Fulham defender Zesh Rehman made his debut for Pakistan, who are ranked 168 by Fifa. Is that the lowest-ranked country a Premier League player has played for?”&lt;/em&gt; wondered Zulfiqar Shah in January 2006.’&lt;/p&gt;
&lt;div id=&#34;answers&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Answers&lt;/h2&gt;
&lt;p&gt;The latter question is more clear cut- noone has beaten the record set by Zesh Rehman in December 205 when he made his debut for Pakistan. Using ELO ratings which are more consistent over time, Pakistan were ranked as teh 197th best team in the world at that time. The nearest someone has gotten to this is Neil Etheridge in 2018 when playing for 165th ranked Philippines.&lt;/p&gt;
&lt;p&gt;For the first question, it depends how you take the rankings and if you require players to have appeared a certain number of time in the season, but Chistopher Wreh who represented 110th ranked Liberia whilst plaing for Arsenal in the 1997/1998 season is probably the winner with Jonny Evans (Northern Ireland and Manchester United, 2012/2013) and Igors Stepanovs (Latvia and Arsenal, 2001/2002) close behind.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;working&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Working&lt;/h2&gt;
&lt;p&gt;First some libraries we’ll need, and also set a seed for reproducibility.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(magrittr)
library(rvest)

set.seed(3459)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first thing we need to answer these is the nationality of EPL players. For this two good sources are &lt;a href=&#34;https://www.transfermarkt.co.uk/&#34;&gt;transfermarkt.co.uk&lt;/a&gt; and &lt;a href=&#34;https://www.11v11.com/&#34;&gt;11v11.com&lt;/a&gt;. I’m going to opt for the later, just because the tables are a little easier to scrape.&lt;/p&gt;
&lt;p&gt;To start, we need to get the links to every team to have competed in the premier league&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get years of EPL seasons
years &amp;lt;- 1993:2019
# base url we&amp;#39;ll scrape from
base_url &amp;lt;- &amp;quot;https://www.11v11.com&amp;quot;

# cat together
tables &amp;lt;- paste0(base_url, &amp;quot;/league-tables/premier-league/01-june-&amp;quot;, years)

competing_teams &amp;lt;- tables %&amp;gt;%
  # get a list of the links to every teams squad page
  map(., function(x) {
    x %&amp;gt;%
      read_html() %&amp;gt;%
      html_nodes(&amp;quot;#table-league &amp;gt; tbody:nth-child(2) &amp;gt; tr &amp;gt; td:nth-child(2) &amp;gt; a:nth-child(1)&amp;quot;) %&amp;gt;%
      html_attr(&amp;quot;href&amp;quot;) %&amp;gt;%
      # paste into working link for year and competition (EPL)
      paste0(base_url, ., &amp;quot;tab/players/season/&amp;quot;, gsub(&amp;quot;.*01-june-&amp;quot;, &amp;quot;&amp;quot;, x), &amp;quot;/comp/1/&amp;quot;)
  }) %&amp;gt;%
  unlist()

head(competing_teams, n = 5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can then scrape the squads for these teams in that specific season. We want the players, their nationality and also the number of appearances they made in the league that season&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;squads &amp;lt;- competing_teams %&amp;gt;%
  # get the players/appearances/nationalities
  map_df(., function(y) {
    # read once to save server calls
    read &amp;lt;- y %&amp;gt;%
      read_html() 
    
    # get the squad info
    squad &amp;lt;- read %&amp;gt;%
      html_nodes(&amp;quot;.squad&amp;quot;) %&amp;gt;%
      html_table(fill = TRUE) %&amp;gt;%
      as.data.frame() %&amp;gt;%
      # get rid of rows without player info
      filter(!is.na(Player))
    
    # get the listed nationalities
    flags &amp;lt;- read %&amp;gt;%
      html_nodes(&amp;quot;.squad &amp;gt; tbody:nth-child(2) &amp;gt; tr &amp;gt; td:nth-child(3)&amp;quot;)
    
    # from here get the actual nationalities per player
    nations &amp;lt;- flags %&amp;gt;%
      html_nodes(&amp;quot;img&amp;quot;) %&amp;gt;%
      html_attr(&amp;quot;title&amp;quot;)
    
    # these might mismatch in length
    # in which case append NA
    if(length(flags) != length(nations)) {
      missing &amp;lt;- which(!grepl(&amp;quot;img&amp;quot;, flags))
      
      nations &amp;lt;- c(
        nations[1:(missing-1)],
        NA,
        nations[missing:length(nations)]
      )
    }
    
    # mutate nationality and team and season
    squad %&amp;gt;%
      mutate(
        nation = nations,
        year = gsub(&amp;quot;.*season\\/&amp;quot;, &amp;quot;&amp;quot;, gsub(&amp;quot;\\/comp.*&amp;quot;, &amp;quot;&amp;quot;, y)),
        team = gsub(&amp;quot;\\/tab\\/players.*&amp;quot;, &amp;quot;&amp;quot;, gsub(&amp;quot;.*teams\\/&amp;quot;, &amp;quot;&amp;quot;, y))
      ) %&amp;gt;%
      # select useful appearance information
      select(player = Player, position = Position,
             appearances = A, sub_appearances = S, 
             nation, year, team)
  }) %&amp;gt;%
  # manually add in some missing nationalities
  mutate(nation = case_when(
    grepl(&amp;quot;Steffen Karl&amp;quot;, player) ~ &amp;quot;Germany&amp;quot;,
    grepl(&amp;quot;Marc Muniesa&amp;quot;, player) ~ &amp;quot;Spain&amp;quot;,
    grepl(&amp;quot;Oriol Romeu&amp;quot;, player) ~ &amp;quot;Spain&amp;quot;,
    grepl(&amp;quot;Aleix García&amp;quot;, player) ~ &amp;quot;Spain&amp;quot;,
    grepl(&amp;quot;Martín Montoya&amp;quot;, player) ~ &amp;quot;Spain&amp;quot;,
    TRUE ~ nation
  ))

head(squads, n = 10)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To answer the question as asked, we’d want historical &lt;a href=&#34;https://www.fifa.com/fifa-world-ranking/ranking-table/men/&#34;&gt;FIFA ranking&lt;/a&gt; data. While it does exist going back to 2007, I’d prefer to have the full data set back to 1993, and in any case, there are also &lt;a href=&#34;https://en.wikipedia.org/wiki/World_Football_Elo_Ratings&#34;&gt;some problems&lt;/a&gt; with the historical calculation FIFA used for it’s ratings.&lt;/p&gt;
&lt;p&gt;Instead, we can use the ELO method of rating teams (most commonly used to rank chess players). There are two ways to do this- we can calculate the ratings ourselves using a dataframe of international results, or we can take the accepted ratings at &lt;a href=&#34;https://www.eloratings.net&#34;&gt;eloratings.net&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I’ll outline the first method here and then use the data from the second further below &lt;a href=&#34;&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;calculating-elo-ratings&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Calculating ELO ratings&lt;/h2&gt;
&lt;p&gt;To calculate our ratings, first we need to to load up a dataframe of international football results. The one I’m using comes from &lt;a href=&#34;https://www.kaggle.com/martj42/international-football-results-from-1872-to-2017&#34;&gt;kaggle&lt;/a&gt; and has 40k matches listed since the start of international football in 1872:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# https://www.kaggle.com/martj42/international-football-results-from-1872-to-2017
international_results &amp;lt;- readRDS(&amp;quot;../../static/files/international_results.rds&amp;quot;)

head(international_results)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         date home_team away_team home_score away_score tournament    city
## 1 1872-11-30  Scotland   England          0          0   Friendly Glasgow
## 2 1873-03-08   England  Scotland          4          2   Friendly  London
## 3 1874-03-07  Scotland   England          2          1   Friendly Glasgow
## 4 1875-03-06   England  Scotland          2          2   Friendly  London
## 5 1876-03-04  Scotland   England          3          0   Friendly Glasgow
## 6 1876-03-25  Scotland     Wales          4          0   Friendly Glasgow
##    country neutral
## 1 Scotland   FALSE
## 2  England   FALSE
## 3 Scotland   FALSE
## 4  England   FALSE
## 5 Scotland   FALSE
## 6 Scotland   FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We only need a few of these variables- enough to know who wins each match and when/where it was played. We can then use this data to initialise several parameters to be used in our ELO calculation. For team i (in a match of teams i and j), this is &lt;a href=&#34;https://eloratings.net/about&#34;&gt;calculated as&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ rating_{i_{t}} = rating_{i_{t-1}} + K \cdot G \cdot (R - E(R)) \]&lt;/span&gt;
The rating of team i is their old rating plus the difference between the actual result (R = 1 for a win, 0.5 for a draw, 0 for a loss) and the expected result (where 1 means certain win for team i).&lt;/p&gt;
&lt;p&gt;The unexpectedness of the result is then multiplied by two parameters. The first K, is to account for the importance of the match, with more important matches having a higher K factor, and a greater influence of team rating.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{equation}
K = 
\begin{cases} 
60 &amp;amp; \text{if World Cup Final} \\
50 &amp;amp; \text{if World Cup/ Major Intercontinental Matches} \\
40 &amp;amp; \text{if World Cup/Continental Competition Qualifiers} \\
30 &amp;amp; \text{if Other Tournaments}\\
20 &amp;amp; \text{if Friendly} \\
\end{cases}

\end{equation}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The second parameter, G is controlled by the strength of the result&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{equation}
G = 
\begin{cases} 
1 &amp;amp; \text{if } N &amp;lt; 2 \\
1.5 &amp;amp; \text{if } N = 2 \\
1.75 &amp;amp; \text{if } N = 3 \\
1.75 + \frac{N-3}{8} &amp;amp; \text{if N &amp;gt; 3} \\
\end{cases}

\end{equation}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where N is the goal difference:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ N = Goals_{i} - Goals_{j} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The expected result is calculated based on the rankings of both teams going into the match&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ E(result) = \frac{1}{10 ^ \frac{-dr_{i,j}}{400} + 1} \]&lt;/span&gt;
where the difference in rankings (dr) is calculated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{equation}
dr_{i,j} = 
\begin{cases} 
rating_{i, t-1} + 100 - rating_{j, t-1} &amp;amp; \text{if i at home} \\
rating_{i, t-1} - 100 - rating_{j, t-1} &amp;amp; \text{if j at home} \\
rating_{i, t-1} - rating_{j, t-1} &amp;amp; \text{if neutral} \\
\end{cases}

\end{equation}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We then add K, G and R to each row of the data frame to make our calculations easier down the line. Unfortunately, my dataset doesn’t give the context of each game, so I’ve set K to 40 for every match. In theory this shouldn’t make a difference, but will affect the ratings of teams who over/under perform in big matches.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;international_results %&amp;lt;&amp;gt;%
  # select relevant columns
  select(
    date,
    home = home_team, away = away_team,
    hgoal = home_score, agoal = away_score,
    neutral
  ) %&amp;gt;%
  # convert date to date format
  mutate(date = as.Date(date)) %&amp;gt;%
  # K = match importance
  # don&amp;#39;t have competition data in this dataset so just set to 40
  mutate(K =  40) %&amp;gt;%
  # G = goal difference factor
  # takes into account how much a team is beaten by
  mutate(G = case_when(
    abs(hgoal-agoal) &amp;lt; 2 ~ 1,
    abs(hgoal-agoal) &amp;lt; 3 ~ 1.5,
    abs(hgoal-agoal) &amp;gt;= 3 ~ 1.75 + (abs(hgoal-agoal)-3)/8
  )) %&amp;gt;%
  # results = 1 for win and 0.5 for a draw
  mutate(result = case_when(
    hgoal &amp;gt; agoal ~ 1,
    hgoal &amp;lt; agoal ~ 0,
    hgoal == agoal ~ 0.5
  )) %&amp;gt;%
  # arrange by date so ELO can be updated sequentially
  arrange(date)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We still need to initialise our rating (R) for each team, which for simplicity I’ve set to 1200 to start with. That is, every team starts with the same rating and will gradually tend towards their ‘natural’ rating. Given There’s probably at least 50 years of data for most teams before the Premier League begins in 1992, hopefully it should be enough for this to level out.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;team_ratings &amp;lt;- international_results %&amp;gt;%
  # select date and teams
  select(date, home, away) %&amp;gt;%
  # melt
  gather(., &amp;quot;location&amp;quot;, &amp;quot;nation&amp;quot;, home, away) %&amp;gt;%
  select(-location) %&amp;gt;%
  arrange(date) %&amp;gt;%
  # set out unique teams with a rating of 1200
  filter(!duplicated(nation)) %&amp;gt;%
  mutate(rating = 1200) %&amp;gt;%
  select(-date)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Therefore, using the very first international fixture between England and Scotland in 1872 we have parameters of&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(international_results, n = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         date     home    away hgoal agoal neutral  K G result
## 1 1872-11-30 Scotland England     0     0   FALSE 40 1    0.5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ratings(t-1) = 1200 for both England and Scotland
K = 40
G = 1 for a draw
R = 0.5 for a draw&lt;/p&gt;
&lt;p&gt;the equal ratings, but home location for Scotland mean that for England:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ dr_{i,j} = 1200 + 100 - 1200  = 100 \]&lt;/span&gt;
and so an expected result (1- the expected home result)&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ E(R) = 1 - \frac{1}{10 ^ {100/400} + 1} = 1 - \frac{1}{2.78}  =  0.36\]&lt;/span&gt;
and so England will get a post match rating of&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ rating_{j} = 1200 + (40 \cdot 1 \cdot (0.5 - 0.36)) = 1207.2 \]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;calc_ELO &amp;lt;- function(date, home, away, K, G, result) {
  #get the difference in ratings
  hr &amp;lt;- team_ratings$rating[which(team_ratings$nation == home)]
  vr &amp;lt;- team_ratings$rating[which(team_ratings$nation == away)]
  dr &amp;lt;- vr - (hr + 100)
  
  # calculate expected results
  e_result &amp;lt;- 1/ ((10^(dr/400))+1)
  
  # calculate new ratings
  new_hr &amp;lt;- hr + ((K*G) * (result - e_result))
  new_vr &amp;lt;- vr + ((K*G) * ((1-result) - (1-e_result)))
  
  # pipe these back into a df of team ratings to sample from
  team_ratings$rating[which(team_ratings$nation == home)] &amp;lt;&amp;lt;- new_hr
  team_ratings$rating[which(team_ratings$nation == away)] &amp;lt;&amp;lt;- new_vr
  
  # return new ratings
  return(list(h_rating = new_hr, v_rating = new_vr))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which can be applied to the dataframe of match information using pmap_df from the &lt;a href=&#34;&#34;&gt;purrr&lt;/a&gt; package, which allows for some pleasing conciseness. It allows for the speed of applying a function, without needing to split the data frame by row and pass into lapply and rebind together.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;elo_data &amp;lt;- international_results %&amp;gt;%
  # select relevant variable
  # keep date so we know a teams ELO at specific date
  select(date, home, away, K, G, result) %&amp;gt;%
  bind_cols(pmap_df(., calc_ELO)) %&amp;gt;%
  # get rid of ELO parameters
  select(date, home, away, h_rating, v_rating) %&amp;gt;%
  # gather twice to get a long df of teams ratings after matches
  gather(&amp;quot;location&amp;quot;, &amp;quot;nation&amp;quot;, -date, -h_rating, -v_rating) %&amp;gt;%
  gather(&amp;quot;rating&amp;quot;, &amp;quot;value&amp;quot;, -date, -location, -nation) %&amp;gt;%
  # filter for home rating for teams at home and vice versa
  filter((location == &amp;quot;home&amp;quot; &amp;amp; rating == &amp;quot;h_rating&amp;quot;) |
           (location == &amp;quot;away&amp;quot; &amp;amp; rating == &amp;quot;v_rating&amp;quot;)) %&amp;gt;%
  select(date, nation, rating = value) %&amp;gt;%
  # we only care about ratings from August 1992
  filter(date &amp;gt; &amp;quot;1992-07-31&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’re left with a dataframe of 46992 observations for 3 variables: date, nation and the ranking of the nation at that time. We can plot a random selection of 5 teams just to sanity check and see that teams we know have historically been stronger (e.g. Argentina) show consistently higher rankings than weaker nations (e.g. Greece).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# randomly choose 5 teams with max ELOs &amp;gt; 1600
teams &amp;lt;- elo_data %&amp;gt;%
  filter(rating &amp;gt; 1600) %&amp;gt;%
  .$nation %&amp;gt;%
  unique() %&amp;gt;%
  .[sample(length(.), 5)]

# plot rating over time for these 5 teams
p1 &amp;lt;- elo_data %&amp;gt;%
  filter(nation %in% teams) %&amp;gt;%
  ggplot(aes(x = date, y = rating, colour = nation, group = nation)) +
  geom_point() +
  geom_line() +
  # colour by football shirt colour
  scale_colour_manual(values = c(&amp;quot;skyblue&amp;quot;, 
                                 &amp;quot;darkblue&amp;quot;,
                                 &amp;quot;darkorange&amp;quot;,
                                 &amp;quot;darkgreen&amp;quot;,
                                 &amp;quot;red&amp;quot;)) +
  labs(title = &amp;quot;ELO Ratings of Select Countries over Time&amp;quot;,
       subtitle = &amp;quot;ratings calculated using homebrew script&amp;quot;,
       x = &amp;quot;date&amp;quot;,
       y = &amp;quot;rating&amp;quot;) +
  theme_minimal()

plot(p1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-06-20-The_Knowledge_4_files/figure-html/plot_teams_elo-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I’m pretty happy with how the code works. With a more complete dataset of matches, and also the time to properly filter countries in and out as they are formed/dissolved, I think it would make a pretty viable answer, however, I wanted to be as accurate as possible, and I can’t compete with the official-unofficial ratings of &lt;a href=&#34;https://www.eloratings.net&#34;&gt;eloratings.net&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;dynamic-scraping&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Dynamic Scraping&lt;/h2&gt;
&lt;p&gt;When scraping data for blog posts, I typically rely on &lt;a href=&#34;&#34;&gt;rvest&lt;/a&gt; and it’s read_html(url) function. However, while this works for the static websites which make up the vast majority of sites containing tables of data, it struggles with websites that use JavaScript to dynamically generate pages.&lt;/p&gt;
&lt;p&gt;Eloratings.net is one such website which rvest is unable to scrape. E.g.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# url to data on Brazil&amp;#39;s ELO rating over time
url &amp;lt;- &amp;quot;https://eloratings.net/Brazil&amp;quot;

read &amp;lt;- read_html(url) %&amp;gt;%
  # this is the CSS selector for the page title
  html_nodes(&amp;quot;#mainheader&amp;quot;)

read&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## {xml_nodeset (1)}
## [1] &amp;lt;h1 id=&amp;quot;mainheader&amp;quot; class=&amp;quot;mainheader&amp;quot;&amp;gt;&amp;lt;/h1&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;does not manage to capture the data displayed in the page mainheader (it ‘should’ return “World Football Elo Ratings: Brazil” from the title of that page).&lt;/p&gt;
&lt;p&gt;Instead, what we want to do is save a copy of the generated page as a .html file and then read that into R using read_html(). Luckily, a way exists to do just that, using the (now deprecated, but still working) &lt;a href=&#34;http://phantomjs.org/&#34;&gt;PhantomJS headless browser&lt;/a&gt;. Much of the code I used to get going with this is adapted from a tutorial &lt;a href=&#34;https://velaco.github.io/how-to-scrape-data-from-javascript-websites-with-R/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;First you want to install PhantomJS from the above website and run through it’s &lt;a href=&#34;http://phantomjs.org/quick-start.html&#34;&gt;quick start guide&lt;/a&gt;. This is a pretty thorough guide, I would say that there are really only three steps from installation to getting going:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;a href=&#34;https://www.howtogeek.com/118594/how-to-edit-your-system-path-for-easy-command-line-access/&#34;&gt;Add phantomjs to the system PATH&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Open a text editor and save one of the &lt;a href=&#34;https://phantomjs.org/quick-start.html&#34;&gt;tutorial scripts&lt;/a&gt; as filename.js&lt;/li&gt;
&lt;li&gt;run &amp;gt; phantomjs C:/Users/usr/path/to/file.js
in a command line console&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The file we’re going to use to render the js pages and then save the html is below:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;// scrapes a given url (for eloratings.net)

// create a webpage object
var page = require(&amp;#39;webpage&amp;#39;).create(),
  system = require(&amp;#39;system&amp;#39;)

// the url for each country provided as an argument
country= system.args[1];

// include the File System module for writing to files
var fs = require(&amp;#39;fs&amp;#39;);

// specify source and path to output file
// we&amp;#39;ll just overwirte iteratively to a page in the same directory
var path = &amp;#39;elopage.html&amp;#39;

page.open(country, function (status) {
  var content = page.content;
  fs.write(path,content,&amp;#39;w&amp;#39;)
  phantom.exit();
});&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(which, again, is stolen and adapted from &lt;a href=&#34;https://velaco.github.io/how-to-scrape-data-from-javascript-websites-with-R/&#34;&gt;here&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;This is saved as scrape_ELO.js in the static directory of my blog folder.&lt;/p&gt;
&lt;p&gt;To keep everything in R, we can use the system() family of functions, which provides access to the OS command line. Though the referenced tutorial uses system(), it relies on scraping a single referenced page. To iteratively scrape every country, we’ll need to provide an argument (country) which will contain the link to the page on eloratings.net for that country.&lt;/p&gt;
&lt;p&gt;E.g. for Brazil we will provide “&lt;a href=&#34;https://www.eloratings.net/Brazil&#34; class=&#34;uri&#34;&gt;https://www.eloratings.net/Brazil&lt;/a&gt;” as the country argument&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;phantom_dir &amp;lt;- &amp;quot;C:/Users/path/to/scrape_ELO/&amp;quot;
country_url &amp;lt;- &amp;quot;https://www.eloratings.net/Brazil&amp;quot;

# use system2 to invoke phantomjs via it&amp;#39;s executable
system2(&amp;quot;C:/Users/path/to/phantomjs-2.1.1-windows/bin/phantomjs.exe&amp;quot;,
        #provide the path to the scraping script and the country url as argument
        args = c(file.path(phantom_dir, &amp;quot;scrape_ELO.js&amp;quot;), country_url))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can then read in this saved html page using rvest as per usual and recover the information therein.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# read in the saved html file
page &amp;lt;- read_html(&amp;quot;elopage.html&amp;quot;)

# scrape with rvest as normal
country_name &amp;lt;- page %&amp;gt;%
  html_nodes(&amp;quot;#mainheader&amp;quot;) %&amp;gt;%
  html_text() %&amp;gt;%
  gsub(&amp;quot;Elo Ratings: &amp;quot;, &amp;quot;&amp;quot;, .)

country_name&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Brazil&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’m not going to include my full script for scraping eloratings.net as usually a reason for doing this obscuring of the data is to prevent exactly what I’m doing. Instead I’ll give a skeleton function of the one I use. If you are having problems with setting up phantomjs to scrape pages, my contact details are listed on my &lt;a href=&#34;http://www.robert-hickman.eu/&#34;&gt;blog homepage&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;scrape_nation &amp;lt;- function(country) {
  # download the page
  url &amp;lt;- paste0(&amp;quot;https://eloratings.net/&amp;quot;, country)
  system2(&amp;quot;C:/Users/path/to/phantomjs-2.1.1-windows/bin/phantomjs.exe&amp;quot;, 
          args = c(file.path(phantom_dir, &amp;quot;scrape_ELO.js&amp;quot;), url))
  
  # read in downloaded page
  page &amp;lt;- read_html(&amp;quot;elopage.html&amp;quot;)
  
  # recover information
  country_name &amp;lt;- page %&amp;gt;%
    html_nodes(&amp;quot;#mainheader&amp;quot;) %&amp;gt;%
    html_text() %&amp;gt;%
    gsub(&amp;quot;Elo Ratings: &amp;quot;, &amp;quot;&amp;quot;, .)
  
  opposing &amp;lt;- page %&amp;gt;%
      html_nodes(&amp;quot;.r1 a&amp;quot;) %&amp;gt;%
      html_text()
  
  teams &amp;lt;- page %&amp;gt;%
      html_nodes(&amp;quot;.r1&amp;quot;)
  
  fixtures &amp;lt;- map2_df(teams, opposing, split_teams)

  ratings &amp;lt;- page %&amp;gt;%
    html_nodes(&amp;quot;.r4&amp;quot;) %&amp;gt;%
    html_text() %&amp;gt;%
    map_df(., split_ratings)
  
  rankings &amp;lt;- page %&amp;gt;%
    html_nodes(&amp;quot;.r6&amp;quot;) %&amp;gt;%
    map_df(., split_rankings)

  dates &amp;lt;- page %&amp;gt;%
    html_nodes(&amp;quot;.r0&amp;quot;) %&amp;gt;%
    html_text() %&amp;gt;%
    map_df(., convert_date)

  # bind into a data frame
  df &amp;lt;- fixtures %&amp;gt;%
    cbind(., ratings) %&amp;gt;%
    cbind(., rankings) %&amp;gt;%
    cbind(., dates) %&amp;gt;%
    mutate(table_country = country_name)
}

elO_data &amp;lt;- map_df(country_links, scrape_nation)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we want to convert this to long format. We have two observations per country and any point in time- the rating, and the ranking. I’m going to filter out just the ranking, as that’s what the questions ask, but if anything there’s possibly more information in the rating data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;elo_data %&amp;lt;&amp;gt;%
  # rename and select variables
  select(
    date,
    home, away,
    rating_home = r1, rating_away = r2,
    ranking_home = ranking1, ranking_away = ranking2
  ) %&amp;gt;%
  # melt twice to convert to long format
  gather(
    &amp;quot;location&amp;quot;, &amp;quot;nation&amp;quot;,
    -rating_home, -rating_away, -ranking_home, -ranking_away, -date
  ) %&amp;gt;%
  gather(&amp;quot;measure&amp;quot;, &amp;quot;value&amp;quot;, -nation, -date, -location) %&amp;gt;%
  # take only relevant information
  filter(
    (location == &amp;quot;home&amp;quot; &amp;amp; measure %in% c(&amp;quot;rating_home&amp;quot;, &amp;quot;ranking_home&amp;quot;)) |
      (location == &amp;quot;away&amp;quot; &amp;amp; measure %in% c(&amp;quot;rating_away&amp;quot;, &amp;quot;ranking_away&amp;quot;))
  ) %&amp;gt;%
  separate(measure, into = c(&amp;quot;measure&amp;quot;, &amp;quot;location&amp;quot;), &amp;quot;_&amp;quot;) %&amp;gt;%
  # filter out relevant data
  filter(!duplicated(.)) %&amp;gt;%
  filter(date &amp;gt; &amp;quot;1992-01-01&amp;quot;) %&amp;gt;%
  filter(measure == &amp;quot;ranking&amp;quot;) %&amp;gt;%
  select(-measure, ranking = value, -location)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;answering-the-question&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Answering the Question&lt;/h2&gt;
&lt;p&gt;So now we have a database of Premier League players’ nationalities, and also of the ELO rankings of countries since 1992, we can answer the original questions.&lt;/p&gt;
&lt;p&gt;First we need to make sure that the data can join to each other, which means making sure that the nation names are common between the two data sets.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get unique names for countries in both data sets
squad_teams &amp;lt;- unique(squads$nation)
rating_teams &amp;lt;- unique(elo_data$nation)

# find non joining country names
squad_teams[!squad_teams %in% rating_teams]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;Ireland Republic&amp;quot;       &amp;quot;Trinidad and Tobago&amp;quot;   
##  [3] &amp;quot;Czech Republic&amp;quot;         &amp;quot;Macedonia FYR&amp;quot;         
##  [5] &amp;quot;St. Kitts and Nevis&amp;quot;    &amp;quot;Bosnia and Herzegovina&amp;quot;
##  [7] &amp;quot;Congo DR&amp;quot;               &amp;quot;Antigua and Barbuda&amp;quot;   
##  [9] &amp;quot;Korea Republic&amp;quot;         &amp;quot;Curacao&amp;quot;               
## [11] &amp;quot;Cape Verde Islands&amp;quot;     &amp;quot;Equatorial Guinea&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Some are missing where country names follow different convention- e.g. the Democratic Republic of Congo is named DR Congo in one, and Congo DR in the other. We can quickly convert these odd countries and join the two data sets together using dplyr. Then we can get an idea of the national rankings of the nationality of Premier League players since it’s inception&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# rename mismatching nations
elo_data %&amp;lt;&amp;gt;%
  mutate(nation = case_when(
    grepl(&amp;quot;^Ireland&amp;quot;, nation) ~ &amp;quot;Ireland Republic&amp;quot;,
    grepl(&amp;quot;^Czechia&amp;quot;, nation) ~ &amp;quot;Czech Republic&amp;quot;,
    grepl(&amp;quot;Trinidad/Tobago&amp;quot;, nation) ~ &amp;quot;Trinidad and Tobago&amp;quot;,
    grepl(&amp;quot;Macedonia&amp;quot;, nation) ~ &amp;quot;Macedonia FYR&amp;quot;,
    grepl(&amp;quot;St Kitts and Nevis&amp;quot;, nation) ~ &amp;quot;St. Kitts and Nevis&amp;quot;,
    grepl(&amp;quot;Bosnia/Herzeg&amp;quot;, nation) ~ &amp;quot;Bosnia and Herzegovina&amp;quot;,
    grepl(&amp;quot;DR Congo&amp;quot;, nation) ~ &amp;quot;Congo DR&amp;quot;,
    grepl(&amp;quot;Antigua/Barbuda&amp;quot;, nation) ~ &amp;quot;Antigua and Barbuda&amp;quot;,
    grepl(&amp;quot;South Korea&amp;quot;, nation) ~ &amp;quot;Korea Republic&amp;quot;,
    grepl(&amp;quot;Curaçao&amp;quot;, nation) ~ &amp;quot;Curacao&amp;quot;,
    grepl(&amp;quot;Cape Verde&amp;quot;, nation) ~ &amp;quot;Cape Verde Islands&amp;quot;,
    grepl(&amp;quot;Equat Guinea&amp;quot;, nation) ~ &amp;quot;Equatorial Guinea&amp;quot;,
    TRUE ~ nation
  ))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;players_national_elo &amp;lt;- squads %&amp;gt;%
  # convert dates
  mutate(year = as.numeric(year)) %&amp;gt;%
  # join elo rating data
  left_join(., elo_data, by = &amp;quot;nation&amp;quot;) %&amp;gt;%
  # take only relevant data per season
  filter(date &amp;lt; as.Date(paste0(year, &amp;quot;-06-30&amp;quot;)) &amp;amp;
           date &amp;gt; as.Date(paste0(year-1, &amp;quot;-07-01&amp;quot;))) %&amp;gt;%
  # rename for concise printing
  rename(apps = appearances, sub_apps = sub_appearances)

# histogram of players national team lowest ratings
p2 &amp;lt;- players_national_elo %&amp;gt;%
  arrange(ranking) %&amp;gt;%
  # take only lowest ranked observations
  filter(!duplicated(paste(player, team, year), fromLast = TRUE)) %&amp;gt;%
  # group by decade
  mutate(decade = case_when(
    year &amp;lt; 2000 ~ &amp;quot;1990&amp;quot;,
    year &amp;lt; 2010 ~ &amp;quot;2000&amp;quot;,
    year &amp;lt; 2020 ~ &amp;quot;2010&amp;quot;
  )) %&amp;gt;%
  ggplot(aes(ranking)) +
  geom_histogram() +
  labs(title = &amp;quot;Distribution of EPL Player&amp;#39;s Nation&amp;#39;s Ranking&amp;quot;,
       subtitle = &amp;quot;(taking lowest point of ranking data)&amp;quot;,
       x = &amp;quot;lowest national team ELO rating&amp;quot;,
       y = &amp;quot;player count&amp;quot;) +
  theme_minimal() +
  facet_wrap(~decade)

plot(p2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-06-20-The_Knowledge_4_files/figure-html/combine_datasets-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It surprised me that the distribution hasn’t obviously changed over the year. There’s maybe a few more players from ‘mid-level’ nations (ranking 30-50) this decade but I’d doubt it’s significantly more. The majority of players come from nations in the top 20 worldwide consistently since the Premier League’s inception.&lt;/p&gt;
&lt;p&gt;We can easily then take the players with the worst national team ranking by arranging by the ranking of national teams (and removing duplicate players so it isn’t just filled with the same 2/3 names)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;worst_national_team_players &amp;lt;- players_national_elo %&amp;gt;%
  # arrange rating from low to high
  arrange(-ranking) %&amp;gt;%
  # remove duplicated players
  filter(!duplicated(player)) %&amp;gt;%
  # select only relevant info
  select(year, player, team, apps, sub_apps, nation, ranking)

# show the 25 players with the worst ranking their nation had during that time
head(worst_national_team_players, n = 25)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    year             player                    team apps sub_apps
## 1  2015     Brandon Comley     queens-park-rangers    0        1
## 2  2004        Zesh Rehman                  fulham    0        1
## 3  2012     George Elokobi wolverhampton-wanderers    3        6
## 4  2014     Leandro Bacuna             aston-villa   28        7
## 5  2013      Kemy Agustien            swansea-city    4       14
## 6  2015        Kenji Gorré            swansea-city    0        1
## 7  1998 Danny Higginbotham       manchester-united    0        1
## 8  1999          Carl Cort               wimbledon    6       10
## 9  2007 Mikele Leigertwood        sheffield-united   16        3
## 10 2007     Moses Ashikodi                 watford    0        2
## 11 2016       Cuco Martina             southampton   11        4
## 12 2003         Neil Danns        blackburn-rovers    1        1
## 13 2005  Dexter Blackstock             southampton    8        1
## 14 2019     Neil Etheridge            cardiff-city   38        0
## 15 2013     Emmerson Boyce          wigan-athletic   36        0
## 16 1997          Mart Poom            derby-county    4        0
## 17 2007     Matthew Briggs                  fulham    0        1
## 18 2018        Nahki Wells                 burnley    0        9
## 19 2012      Jason Roberts        blackburn-rovers    5        5
## 20 1998 Sagi Burton-Godwin          crystal-palace    1        1
## 21 2010     Gunnar Nielsen         manchester-city    0        1
## 22 2009          Leon Cort              stoke-city    9        2
## 23 2000        Adam Newton         west-ham-united    0        2
## 24 2004       Delroy Facey        bolton-wanderers    0        1
## 25 2013    Gaël Bigirimana        newcastle-united    3       10
##                 nation ranking
## 1           Montserrat     227
## 2             Pakistan     204
## 3              Somalia     199
## 4              Curacao     188
## 5              Curacao     186
## 6              Curacao     186
## 7            Gibraltar     181
## 8               Guyana     179
## 9  Antigua and Barbuda     179
## 10 Antigua and Barbuda     179
## 11             Curacao     179
## 12              Guyana     175
## 13 Antigua and Barbuda     174
## 14         Philippines     174
## 15            Barbados     173
## 16             Estonia     169
## 17              Guyana     169
## 18             Bermuda     167
## 19             Grenada     166
## 20 St. Kitts and Nevis     160
## 21       Faroe Islands     160
## 22              Guyana     153
## 23 St. Kitts and Nevis     147
## 24             Grenada     145
## 25             Burundi     143&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So Zesh Rehman as the question supposes, is one of the players from extremely low ranked nations. However, he is beaten by Brandon Comley at QPR who represents Montserrat internationally, who fell as low as 227 in the ELO world rankings. The 204 for Zesh Rehman is different to the 168 listed in the question for three reasons:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;As earlier discussed we are using ELO rankings, not the official FIFA rankings (and are probably right to)&lt;/li&gt;
&lt;li&gt;This lists the &lt;em&gt;lowest&lt;/em&gt; that nation fell in the time that player was in the Premier League, not just at the time Zesh Rehman (or any other player) made his debut for Pakistan (/other nation)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Indeed, Brandon Comley did not start to play for Montserrat until September 2018, by which time he was playing for Colchester in League Two.&lt;/p&gt;
&lt;p&gt;What is interesting though, is that there are 19 instances of players of nationalities ranked lower than 164- many more than I would have imagined.&lt;/p&gt;
&lt;p&gt;To truly answer the question, that is, to only count rankings in games Premier League players played in, we can scrape international match data from &lt;a href=&#34;https://www.national-football-teams.com/&#34;&gt;national_football-teams.com&lt;/a&gt;. 11v11.com which I’ve used thus far does list international appearances, but tends to have thinner data (and vice versa for national-football-teams.com with regards to Premier League squad data).&lt;/p&gt;
&lt;p&gt;First, we’ll manually add the links to the profiles of players who are contenders for having the lowest ranked appearance (the lowest 20 in the above dataframe), then we can use this to scrape the international matches they’ve played in. This is then matched by data to the ELO ranking data to find the national ranking of the country they represented. Finally, we take the lowest ranked appearance for each player and see if any can beat Zesh Rehman.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(players_intl_links)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           player
## 1 Brandon Comley
## 2    Zesh Rehman
## 3 George Elokobi
## 4 Leandro Bacuna
## 5  Kemy Agustien
## 6    Kenji Gorré
##                                                                        url
## 1 https://www.national-football-teams.com/player/71845/Brandon_Comley.html
## 2    https://www.national-football-teams.com/player/12929/Zesh_Rehman.html
## 3                                                                     &amp;lt;NA&amp;gt;
## 4 https://www.national-football-teams.com/player/63672/Leandro_Bacuna.html
## 5  https://www.national-football-teams.com/player/59413/Kemy_Agustien.html
## 6    https://www.national-football-teams.com/player/74671/Kenji_Gorre.html&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get_international_matches &amp;lt;- function(player, url) {
  if(!is.na(url)) {
    df &amp;lt;- url %&amp;gt;%
      read_html() %&amp;gt;%
      html_nodes(&amp;quot;#games &amp;gt; table&amp;quot;) %&amp;gt;%
      html_table(fill = TRUE) %&amp;gt;%
      as.data.frame() %&amp;gt;%
      .[c(1:2, 5:7)] %&amp;gt;%
      filter(Date != &amp;quot;&amp;quot;) %&amp;gt;%
      mutate(result = gsub(&amp;quot;\n.*&amp;quot;, &amp;quot;&amp;quot;, Result), player = player, match_date = as.Date(Date)) %&amp;gt;%
      select(player, match_date, home = Home.Team, away = Away.Team.1, result, event = Event)
  }
}

low_ranked_appearances &amp;lt;- players_intl_links %&amp;gt;%
  pmap_df(., get_international_matches) %&amp;gt;%
  left_join(., players_national_elo, by = &amp;quot;player&amp;quot;) %&amp;gt;%
  filter(match_date == date) 

lowest_ranked_appearances &amp;lt;- low_ranked_appearances %&amp;gt;%
  arrange(-ranking) %&amp;gt;%
  filter(!duplicated(player, fromLast = TRUE)) %&amp;gt;%
  mutate(match = paste(home, &amp;quot;vs&amp;quot;, away)) %&amp;gt;%
  select(date, player, team, nation, ranking, match, result)

lowest_ranked_appearances&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          date         player             team            nation ranking
## 1  2005-12-07    Zesh Rehman           fulham          Pakistan     197
## 2  2018-11-13 Neil Etheridge     cardiff-city       Philippines     165
## 3  2018-03-26   Cuco Martina          everton           Curacao     136
## 4  2004-05-20  Jason Roberts       portsmouth           Grenada     131
## 5  2008-03-26 Emmerson Boyce   wigan-athletic          Barbados     126
## 6  2019-03-22   Pedro Obiang  west-ham-united Equatorial Guinea     125
## 7  2015-06-13   Modou Barrow     swansea-city            Gambia     122
## 8  2006-11-21     Paul Ifill sheffield-united          Barbados     119
## 9  2019-06-21 Leandro Bacuna     cardiff-city           Curacao     118
## 10 2003-06-07      Mart Poom       sunderland           Estonia      85
##                                     match result
## 1                   Pakistan vs Sri Lanka    1:0
## 2                Philippines vs Singapore    1:0
## 3                      Curaçao vs Bolivia    1:0
## 4                         Cuba vs Grenada    2:2
## 5                    Barbados vs Dominica    1:0
## 6              Sudan vs Equatorial Guinea    1:4
## 7                  South Africa vs Gambia    0:0
## 8  Barbados vs Saint Vincent &amp;amp; Grenadines    3:0
## 9                     Honduras vs Curaçao    0:1
## 10                     Estonia vs Andorra    2:0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And it appears not! It’s quite incredible that in the 13.5 years since the question was answered noone has even got close. This is probably due to the fact that though Pakistan were ranked 168th by FIFA at the time, using the ELO system, they come out as the 197th best team at the end of 2005.&lt;/p&gt;
&lt;p&gt;Perhaps more surprising is that it seems that until 2003 the record was 85th, held by Mart Poom playing for Estonia (though this might also be because data on low ranking international matches gets worse as you go back past this point- Mart Poom probably played for Estonia in).&lt;/p&gt;
&lt;p&gt;We can graph the appearances by Premier League players in matches involving low ranked nations to see how close people have gotten pretty easily. The below shows the rankings for the countries in the above printed data frame. Matches where Premier League players made an appearance are highlighted in black boxes.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p3 &amp;lt;- elo_data %&amp;gt;%
  filter(nation %in% low_ranked_appearances$nation) %&amp;gt;%
  mutate(date = as.Date(date)) %&amp;gt;%
  ggplot(aes(x = date, y = ranking, colour = nation, group = nation)) +
  geom_point(alpha = 0.5, size = 2) +
  geom_line(alpha = 0.5, size = 2) +
  geom_point(data = low_ranked_appearances, aes(x = match_date),
             colour = &amp;quot;black&amp;quot;, fill = NA, size = 3,stroke = 2, shape = 22) +
  # colour by football shirt colour
  scale_colour_manual(values = c(&amp;quot;yellow&amp;quot;, &amp;quot;darkblue&amp;quot;, &amp;quot;darkred&amp;quot;, &amp;quot;lightblue&amp;quot;, &amp;quot;green&amp;quot;, &amp;quot;red&amp;quot;, &amp;quot;darkgreen&amp;quot;, &amp;quot;darkgoldenrod&amp;quot;)) +
  scale_x_date() +
  labs(title = &amp;quot;Lowest National Ranking of Premier League International Caps&amp;quot;,
          subtitle = &amp;quot;premier league player caps in red&amp;quot;,
          y = &amp;quot;national team ELO ranking&amp;quot;) +
  theme_minimal()

plot(p3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-06-20-The_Knowledge_4_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It seems Pakistan have continued to hover around the 200th position pretty consistently over the last 25 years. Indeed, if Zesh Rehman was still playing in the Premier League he would have broken his own record less than 1 month ago, when Pakistan sank to 201st position after &lt;a href=&#34;https://www.national-football-teams.com/matches/report/23278/Pakistan_Cambodia.html&#34;&gt;a defeat to Cambodia&lt;/a&gt;. The Philippines, represented by Neil Etheridge in recent years, have been ranked lower, but not since 2010. Other than that Curacao can be seen to only have come close near to their formation as a FIFA member, and are clearly rapidly improving. Barbados and Grenada might be fruitful for any possible record taker, but are still a good 30 places higher than Pakistan.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lowest-ranked-countries-of-premier-league-winners&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Lowest Ranked Countries of Premier League Winners&lt;/h2&gt;
&lt;p&gt;We can answer the first question and find the players with the worst national team rankings by joining in and selecting for teams that won the league. This is done by first initializing a simple df with the league winners per season. The given answers to this question have differed in when they take the country’s rankings, whether at their lowest point within the season, or at the season’s end. I decided to use a different method- to take the average ranking of the nation over the whole season.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# data frame of EPL winners over year
epl_winners &amp;lt;- data.frame(
  champion = c(
    &amp;quot;manchester-united&amp;quot;,
    &amp;quot;manchester-united&amp;quot;,
    &amp;quot;blackburn-rovers&amp;quot;,
    &amp;quot;manchester-united&amp;quot;,
    &amp;quot;manchester-united&amp;quot;,
    &amp;quot;arsenal&amp;quot;,
    &amp;quot;manchester-united&amp;quot;,
    &amp;quot;manchester-united&amp;quot;,
    &amp;quot;manchester-united&amp;quot;,
    &amp;quot;arsenal&amp;quot;,
    &amp;quot;manchester-united&amp;quot;,
    &amp;quot;arsenal&amp;quot;,
    &amp;quot;chelsea&amp;quot;,
    &amp;quot;chelsea&amp;quot;,
    &amp;quot;manchester-united&amp;quot;,
    &amp;quot;manchester-united&amp;quot;,
    &amp;quot;manchester-united&amp;quot;,
    &amp;quot;chelsea&amp;quot;,
    &amp;quot;manchester-united&amp;quot;,
    &amp;quot;manchester-city&amp;quot;,
    &amp;quot;manchester-united&amp;quot;,
    &amp;quot;manchester-city&amp;quot;,
    &amp;quot;chelsea&amp;quot;,
    &amp;quot;leicester-city&amp;quot;,
    &amp;quot;chelsea&amp;quot;,
    &amp;quot;manchester-city&amp;quot;,
    &amp;quot;manchester-city&amp;quot;),
  year = 1993:2019
) 

# merge in winning temas
epl_winning_squads &amp;lt;- players_national_elo %&amp;gt;%
  left_join(., epl_winners, by = &amp;quot;year&amp;quot;) %&amp;gt;%
  # filter for players that win the league that season
  filter(team == champion) %&amp;gt;%
  # filter for the year that player wins the league
  filter(date &amp;lt; as.Date(paste0(year, &amp;quot;-06-30&amp;quot;)) &amp;amp;
           date &amp;gt; as.Date(paste0(year-1, &amp;quot;-07-01&amp;quot;))) %&amp;gt;%
  group_by(player, year, team, apps, sub_apps, nation) %&amp;gt;%
  summarise(av_ranking = mean(ranking)) %&amp;gt;%
  arrange(-av_ranking) %&amp;gt;%
  # take the lowest ranking per player/year combination
  select(year, player, team, apps, sub_apps, nation, av_ranking)

# show the 25 players with the worst ranking their nation had during that time
head(epl_winning_squads, n = 25)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 25 x 7
## # Groups:   player, year, team, apps, sub_apps [25]
##     year player       team           apps sub_apps nation        av_ranking
##    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;        &amp;lt;chr&amp;gt;         &amp;lt;int&amp;gt;    &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;              &amp;lt;dbl&amp;gt;
##  1  1998 Christopher~ arsenal           7        9 Liberia            114. 
##  2  2010 Gaël Kakuta  chelsea           0        1 Congo DR           106. 
##  3  2004 Justin Hoyte arsenal           0        1 Trinidad and~      102. 
##  4  2013 Jonny Evans  manchester-u~    21        2 Northern Ire~      101. 
##  5  2002 Igors Stepa~ arsenal           6        0 Latvia              99.1
##  6  2009 Manucho      manchester-u~     0        1 Angola              89.9
##  7  2006 Eidur Gudjo~ chelsea          16       10 Iceland             79.8
##  8  2003 Roy Carroll  manchester-u~     8        2 Northern Ire~       76.5
##  9  2001 David Healy  manchester-u~     0        1 Northern Ire~       76  
## 10  1999 Dwight Yorke manchester-u~    32        0 Trinidad and~       75.8
## # ... with 15 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we have another quite clear winner Christopher Wreh, whose Liberia averaged a ranking of 114 over the 1997/1998 season. Gael Kakuta and Justin Hoyte (and Igors Stepanovs and Manucho) seem like false answers as they only achieved a handful of appearances on the way to winning the league, which only leaves Jonny Evans in 2013 as a real contender for this record. Northern Ireland in this season averaged just under 100th place.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;extra-credit&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Extra Credit&lt;/h2&gt;
&lt;p&gt;We can pretty quickly and easily see how these players compare to what we found above in terms of the lowest ranked nation they’ve turned out for. Again, first i had to manually add links to their pages of &lt;a href=&#34;www.national-football-teams.com&#34;&gt;www.national-football-teams.com&lt;/a&gt; and then scrape each match they’ve appeared for their home country in.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(champions_df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 2
##   player         url                                                       
##   &amp;lt;chr&amp;gt;          &amp;lt;chr&amp;gt;                                                     
## 1 Christopher W~ https://www.national-football-teams.com/player/13930/Chri~
## 2 Gaël Kakuta    https://www.national-football-teams.com/player/67629/Gael~
## 3 Justin Hoyte   https://www.national-football-teams.com/player/52483/Just~
## 4 Jonny Evans    https://www.national-football-teams.com/player/16586/Jonn~
## 5 Igors Stepano~ https://www.national-football-teams.com/player/3728/Igors~
## 6 Manucho        https://www.national-football-teams.com/player/14353/Manu~&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When we do this scrape and analyse we get Jonny Evans as the Premier League winner who appeared for the lowest rated nation during a championship campaign. He’s Northern Ireland team slumped to a 2-0 defeat to Israel in 2013 which left them 106th in the world rankings. 2 months later, he won the Premier League with Manchester United. There’s relatively few challengers with only Igors Stepanovs (Latvia 101st, 6 appearances for Arsenal in 2002) getting close and then Roy Carroll (Northern Ireland), Eidur GOdjohnsen (Iceland), and Rihad Mahrez (Algeria) in the 80s (Manucho excluded due to lack of appearances in Manchester United’s 2009 Premier League campaign).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;low_ranked_champs &amp;lt;- champions_df %&amp;gt;%
  pmap_df(., get_international_matches) %&amp;gt;%
  left_join(., players_national_elo, by = &amp;quot;player&amp;quot;) %&amp;gt;%
  left_join(., epl_winners, by = &amp;quot;year&amp;quot;) %&amp;gt;%
  filter(team == champion) %&amp;gt;%
  filter(match_date == date) 

lowest_ranked_champs &amp;lt;- low_ranked_champs %&amp;gt;%
  arrange(-ranking) %&amp;gt;%
  filter(!duplicated(player)) %&amp;gt;%
  mutate(match = paste(home, &amp;quot;vs&amp;quot;, away)) %&amp;gt;%
  select(date, player, team, nation, ranking, match, result)

head(lowest_ranked_champs, n = 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          date           player              team           nation ranking
## 1  2013-03-26      Jonny Evans manchester-united Northern Ireland     106
## 2  2001-11-14  Igors Stepanovs           arsenal           Latvia     101
## 3  2009-06-14          Manucho manchester-united           Angola      94
## 4  2003-06-03      Roy Carroll manchester-united Northern Ireland      87
## 5  2018-10-16     Riyad Mahrez   manchester-city          Algeria      85
## 6  2006-02-28 Eidur Gudjohnsen           chelsea          Iceland      82
## 7  2001-06-06      David Healy manchester-united Northern Ireland      82
## 8  2016-06-13       Wes Morgan    leicester-city          Jamaica      72
## 9  2000-09-02       Ryan Giggs manchester-united            Wales      70
## 10 2007-06-02   DONG Fang Zhou manchester-united            China      64
##                                 match result
## 1          Northern Ireland vs Israel    0:2
## 2                    Latvia vs Russia    1:3
## 3                    Angola vs Guinea    0:0
## 4           Italy vs Northern Ireland    2:0
## 5                    Benin vs Algeria    1:0
## 6        Trinidad &amp;amp; Tobago vs Iceland    2:0
## 7  Czech Republic vs Northern Ireland    3:1
## 8                  Uruguay vs Jamaica    3:0
## 9                    Belarus vs Wales    2:1
## 10                       USA vs China    4:1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However! One notable omission is Christopher Wreh, who played in 16 matches for Arsenal in the 1997/1998 season. Wreh only played 26 times for his nation so I assumed he just hadn’t appeared for them that year, but &lt;a href=&#34;https://www.11v11.com/players/christopher-wreh-4/&#34;&gt;11v11.com&lt;/a&gt; lists him playing on July 27th 1997 (1997/1998 season) at which point Liberia were ranked 110th in the world.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../img/archives.png&#34; alt=&#34;mfw incomplete data&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>An Introduction to Modelling Soccer Matches in R (part 1)</title>
      <link>/post/dixon_coles_1/</link>
      <pubDate>Thu, 30 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/dixon_coles_1/</guid>
      <description>


&lt;p&gt;For anyone watching football, being able to predict matches is a key aspect of the hobby. Whether explicitly (e.g. when betting on matches, or deciding on recruitment for an upcoming season), or more implicitly when discussing favourites to win the league in the pub, almost all discussion of the sport on some level require predictions about some set of upcoming games.&lt;/p&gt;
&lt;p&gt;The first step of prediction is some form of quantification of ability. We’d expect a better team to have a better chance of winning than a worse team. For an example of a more sophisticated set of rankings, see &lt;a href=&#34;https://projects.fivethirtyeight.com/soccer-predictions/&#34;&gt;fivethirtyeight’s Soccer Power Index&lt;/a&gt; which is explicitly used to predict the results of various football competitions.&lt;/p&gt;
&lt;p&gt;The accuracy of our predictions therefore relies on the accuracy of our judgement on team’s ability. When discussing football with friends, we might use half-remembered match highlights to form some impression of how strong a team is. When programming however, we have free access to the results of teams thus far in a campaign and should be able to produce a model more grounded in truth.&lt;/p&gt;
&lt;p&gt;Two seminal papers for using recent football results to assess the abilities of football teams (and then use this assessment to predict matches) are &lt;a href=&#34;https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9574.1982.tb00782.x&#34;&gt;Maher’s 1982 paper&lt;/a&gt; on modelling football scores, which is complimented by &lt;a href=&#34;https://www.jstor.org/stable/pdf/2986290.pdf?casa_token=9deLgF7xOaEAAAAA:fGGfUQKOsezrWBvbmphK56HddtiaohxaUNPdkDBoTApL_beghKXFlru5USztLt7dDVEMSdhAfkg8yzubZsAs7eeyZvp307iAGwqAtVSMMhwk6xhUleM&#34;&gt;Mark Dixon and Stuart Coles’ 1997 paper&lt;/a&gt;. For R various packages to use the methods outlined in these papers exist including &lt;a href=&#34;https://github.com/Torvaney/regista&#34;&gt;Ben Torvaney’s regista&lt;/a&gt;, &lt;a href=&#34;https://github.com/opisthokonta/goalmodel&#34;&gt;opisthokonta’s goalmodel&lt;/a&gt;&lt;sup&gt;1&lt;/sup&gt;, and &lt;a href=&#34;https://cran.r-project.org/web/packages/fbRanks/index.html&#34;&gt;Eli Holmes’ fbRanks&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;However, the overlap between people obsessed enough with football to read mathematical papers on the sport, and those with the formal training in reading math notation to understand these models is fairly low, and I wasn’t able to find&lt;sup&gt;2&lt;/sup&gt; a good intuitive explanation for these models. Hopefully, building up these models from the most basic entry steps to a fully sophisticated model for predicting football matches might help some who want to start modelling football but don’t have the privilege of formal stats/modelling/coding training. As I want to start from pretty much zero, in this first post I make at least one or two claims that are not strictly true (indeed, this post does not actually implement some of the main points of the 1997 Dixon &amp;amp; Coles paper), but will try to point these out as I go, and correct them in later posts.&lt;/p&gt;
&lt;p&gt;First, let’s load libraries and also set a seed for the reproducibility of this document&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# munging
library(tidyverse)

# seed for reproducibility
set.seed(3459)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;##Set up&lt;/p&gt;
&lt;p&gt;In reality, we’d probably want to model a whole league or cup. However, these can generally contain 20+ teams, many of which will have similar abilities. For simplicity here, lets instead imagine a summer league between 6 English football clubs where each team plays each other twice (once at home and once away)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;teams &amp;lt;- c(&amp;quot;Arsenal&amp;quot;, # 5th in the 1st tier
           &amp;quot;Blackburn_Rovers&amp;quot;, # 15th in 2nd tier
           &amp;quot;Coventry_City&amp;quot;, # 8th in 3rd tier
           &amp;quot;Dover_Athletic&amp;quot;, # 14th 5th tier 
           &amp;quot;Enfield_Town&amp;quot;, # 10th in 7th tier
           &amp;quot;Frimley_Green&amp;quot;) # 2nd in 9th tier&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’ve managed to arrange a league that has a nice stratification between teams, so we’d expect each to be comfortably better than the next best (which will make sanity checking our results easier). Lucky for us, the teams are also in alphabetical order of strength so in case you don’t have any prior on a team, take the first letter of it’s name (A-F).&lt;/p&gt;
&lt;p&gt;Each week each team play one game, so we’ll have a fixture list that looks like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(fixtures, 8)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##               home             away gameweek
## 1    Frimley_Green          Arsenal        1
## 2     Enfield_Town Blackburn_Rovers        1
## 3   Dover_Athletic    Coventry_City        1
## 4          Arsenal     Enfield_Town        2
## 5    Frimley_Green   Dover_Athletic        2
## 6 Blackburn_Rovers    Coventry_City        2
## 7   Dover_Athletic          Arsenal        3
## 8    Coventry_City     Enfield_Town        3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Obviously for this we’re going to have to make up our data. For the code used to generate it, see the bottom of the post.&lt;/p&gt;
&lt;p&gt;Let’s say that we’ve had 8 weeks of games played so far, and the results have been as follows&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(results,8)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##               home             away hgoal agoal gameweek
## 1   Dover_Athletic    Coventry_City     0     3        1
## 2     Enfield_Town Blackburn_Rovers     0     3        1
## 3    Frimley_Green          Arsenal     0     8        1
## 4          Arsenal     Enfield_Town     5     0        2
## 5 Blackburn_Rovers    Coventry_City     1     1        2
## 6    Frimley_Green   Dover_Athletic     1     2        2
## 7 Blackburn_Rovers    Frimley_Green     6     0        3
## 8    Coventry_City     Enfield_Town     2     1        3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A better way to show this is to generate a matrix of home (y axis) vs. away (x axis) and show the goals scored in each match between them:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p1 &amp;lt;- results %&amp;gt;%
  # remove unplayed games
  filter(!is.na(hgoal)) %&amp;gt;%
  ggplot(., aes(x = away, y = home, fill = hgoal-agoal)) +
  geom_tile() +
  # add the scorelines
  geom_label(aes(label = paste(hgoal, agoal, sep = &amp;quot;-&amp;quot;)), fill = &amp;quot;white&amp;quot;) +
  # colour where green shows home win and red an away win
  scale_fill_gradient2(low = &amp;quot;darkred&amp;quot;, high = &amp;quot;green&amp;quot;, midpoint = 0, guide = FALSE) +
  scale_x_discrete(limits = levels(results$home), position = &amp;quot;top&amp;quot;) +
  scale_y_discrete(limits = rev(levels(results$away))) +
  theme_minimal()

# plot
p1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-30-5-dixon-coles-1_files/figure-html/plot_results-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As the colour gradient (from bottom right to top left) shows, the teams we’d expect to do better are. Given the stochastic nature of football though, there are some surprises. E.g. Blackburn only managing to draw at home to Coventry.&lt;/p&gt;
&lt;p&gt;A good sense of teams relative abilities can be seen in the league table of results so far (assuming 3 points for a win, and 1 for a draw):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# function to melt results
# returns df with team and goals for and against for each match
melt_results &amp;lt;- function(results_df) {
  results_df %&amp;gt;%
    # select only relevant columns
    select(home, away, hgoal, agoal) %&amp;gt;%
    gather(location, team,  -hgoal, -agoal) %&amp;gt;%
    # calculate goals for/against the team
    mutate(g_for = case_when(
      location == &amp;quot;home&amp;quot; ~ hgoal,
      location == &amp;quot;away&amp;quot; ~ agoal
    )) %&amp;gt;%
    mutate(g_ag = case_when(
      location == &amp;quot;home&amp;quot; ~ agoal,
      location == &amp;quot;away&amp;quot; ~ hgoal
    )) 
}

# function to calculate points won and gd for each team
results_to_table &amp;lt;- function(results_df) {
  results_df %&amp;gt;%
    # use above melting function
    melt_results(.) %&amp;gt;%
    # 3 points for a win, 1 for a draw
    mutate(points = case_when(
      g_for &amp;gt; g_ag ~ 3,
      g_ag &amp;gt; g_for ~ 0,
      g_for == g_ag ~ 1
    )) %&amp;gt;%
    # calculate goal difference for each match
    mutate(gd = g_for - g_ag) %&amp;gt;%
    group_by(team) %&amp;gt;%
    # get the final statistics per team
    summarise(games_played = n(),
              gf = sum(g_for),
              ga = sum(g_ag),
              gd = sum(gd),
              points = sum(points)) %&amp;gt;%
    arrange(-points, -gd, -gf)
}

# calculate league table for our played fixtures
league_table &amp;lt;- results  %&amp;gt;%
  filter(!is.na(hgoal)) %&amp;gt;%
  select(-gameweek) %&amp;gt;%
  results_to_table(.) %&amp;gt;%
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 6
##   team             games_played    gf    ga    gd points
##   &amp;lt;chr&amp;gt;                   &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 Arsenal                     8    39     4    35     24
## 2 Blackburn_Rovers            8    23     6    17     19
## 3 Coventry_City               8    14     8     6     16
## 4 Dover_Athletic              8     8    15    -7      9
## 5 Enfield_Town                8     6    22   -16      3
## 6 Frimley_Green               8     2    37   -35      0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Where teams positions are nicely rank ordered (the data for this example is fairly curated so it’s not that surprising).&lt;/p&gt;
&lt;p&gt;##Predictions&lt;/p&gt;
&lt;p&gt;With two rounds to go, there’s still 6 fixtures we might want to predict (to try and judge which team will end up where, or just to bet on the remaining games).&lt;/p&gt;
&lt;p&gt;This are:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get the yet to be played matches
unplayed_games &amp;lt;- fixtures %&amp;gt;%
  filter(gameweek &amp;gt; 8) %&amp;gt;%
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##               home             away gameweek
## 1    Coventry_City          Arsenal        9
## 2 Blackburn_Rovers   Dover_Athletic        9
## 3    Frimley_Green     Enfield_Town        9
## 4          Arsenal Blackburn_Rovers       10
## 5    Coventry_City    Frimley_Green       10
## 6   Dover_Athletic     Enfield_Town       10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we want to predict these results, we need to have data on the strength of the teams above, but also, a good prior on what sort of scores we should expect.&lt;/p&gt;
&lt;p&gt;Using real data from the engsoccerdata package we can get the results of all 48840 English football league games between August 1992 and May 2016. If we melt this to get the goals scored by each team by their location we get a data.frame of 97680 records of a teams performance in a game:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# load real data from the english league
real_data &amp;lt;- engsoccerdata::england %&amp;gt;%
  # filter out &amp;#39;premier league era&amp;#39; matches
  filter(Season &amp;gt; 1991) %&amp;gt;%
  # select only relevant columns
  select(home, away = visitor, hgoal, agoal = vgoal) %&amp;gt;%
  # munge
  melt_results() %&amp;gt;%
  select(-hgoal, -agoal) %&amp;gt;%
  mutate(data = &amp;quot;real&amp;quot;)

head(real_data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   location           team g_for g_ag data
## 1     home        Arsenal     2    4 real
## 2     home        Chelsea     1    1 real
## 3     home  Coventry City     2    1 real
## 4     home Crystal Palace     3    3 real
## 5     home        Everton     1    1 real
## 6     home   Ipswich Town     1    1 real&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here every row shows a team that played a match (as it’s sorted by league then alphabetically, the first 6 records are all for Arsenal). It also shows if the team played home or away. The data also shows the goals scored by (e.g.) Arsenal in g_for, and the goals they conceded in g_ag.&lt;/p&gt;
&lt;p&gt;If we plot the goals scored for each game, we get a nice humped distribution with slightly offset peaks for home and away. That is to say, in most games teams will score 0, 1, or 2 goals, and that scoring more than 6 goals in a match is incredibly rare. The difference between the home and away distributions mean that teams are slightly more likely to score more if playing at home, compared to play away from home.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# plot goals scored home/away for real english football matches
p2 &amp;lt;- real_data %&amp;gt;%
  ggplot(., aes(x = g_for, fill = location)) +
  # smooth densities
  geom_density(adjust = 8, alpha = 0.5) +
  scale_fill_manual(values = c(&amp;quot;red&amp;quot;, &amp;quot;blue&amp;quot;)) +
  scale_x_continuous(breaks = 0:6) +
  labs(title = &amp;quot;Goals scored at home and away in English football&amp;quot;,
       subtitle = &amp;quot;data from 48.8k matches 1992-2016&amp;quot;,
       x = &amp;quot;goals scored&amp;quot;,
       y = &amp;quot;density&amp;quot;) +
  theme_minimal()

# plot
p2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-30-5-dixon-coles-1_files/figure-html/plot_real_goal_distributions-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can work out what the average difference between playing at home and away is by taking the means of goals scored at home, and when playing away:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# calculate mean home and away goals
real_data_means &amp;lt;- real_data %&amp;gt;%
    group_by(location) %&amp;gt;%
    summarise(mean_scored = mean(g_for)) %&amp;gt;%
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 2
##   location mean_scored
##   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
## 1 away            1.12
## 2 home            1.47&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Goals in games are both relatively sparse, and relatively stochastic; football is a low scoring game where goals are evenly distributed throughout the game. In theory any attack made by a team i has a probability of being scored dependent upon the strength of team i’s attack (α&lt;sub&gt;i&lt;/sub&gt;) which is independent of all the other attacks that team has made.&lt;/p&gt;
&lt;p&gt;(there is some reason to doubt this may be the case&lt;sup&gt;3&lt;/sup&gt;, but for now this is a fine generalisation)&lt;/p&gt;
&lt;p&gt;By grouping all teams together into “home” and “away” categories (in a league setting each team will play each other home and away so this should average out) and taking the average number of goals scored per match as the Poisson mean (λ) we can see how well our above graph fits a simulated Poisson process.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# generate Poisson distributed vector with mean = real world mean
simulated_poisson &amp;lt;- real_data_means %&amp;gt;%
  split(f = .$location) %&amp;gt;%
  lapply(., function(x) df = data.frame(dist = rpois(100000, x$mean_scored),
                                        location = x$location)) %&amp;gt;%
  # map it all together and label
  map_df(I) %&amp;gt;%
  mutate(data = &amp;quot;simulated&amp;quot;) 

# add these distributions to the plot
p2 + geom_density(data = simulated_poisson, aes(x = dist),
                  fill = NA, adjust = 8, alpha = 0.2) +
  scale_fill_manual(values = c(&amp;quot;red&amp;quot;, &amp;quot;blue&amp;quot;), guide = FALSE) +
  facet_wrap(~location)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-30-5-dixon-coles-1_files/figure-html/simulated_poisson-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It’s not perfect, but it’s not a bad fit either. In actuality, a Chi-squared test will show that goals scored &lt;em&gt;does not&lt;/em&gt; follow a Poisson distribution given the number of matches we have as data. But for the sake of this post, put that out of mind.&lt;/p&gt;
&lt;p&gt;If we think that goals scored represents some Poisson process, it can be modeled using the equation which underlies the Poisson distribution. For a given interval (one match), the probability of x events (goals scored) in that interval will be:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P(x) = \frac{\lambda^{x}e^{-\lambda}}{x!}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The simplest model we can produce is to estimate λ as each team’s attack rating (henceforth α&lt;sub&gt;i&lt;/sub&gt;) which is equal to observed mean rate of goals for that team.&lt;/p&gt;
&lt;p&gt;That is the say the probability of team i scoring x goals against team j is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P(x_{i,j} = x) = \frac{\alpha_{i}^{x}e^{-\alpha_{i}}}{x!}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where α&lt;sub&gt;i&lt;/sub&gt; is the sum of all goals scored divided by the total number of matches:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\alpha_{i} = \frac{1}{N}\sum_{n=1}^{N} x\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;grouping by teams makes this easy to calculate:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;basic_model &amp;lt;- results %&amp;gt;%
  melt_results() %&amp;gt;%
  group_by(team) %&amp;gt;%
  # we&amp;#39;ll use the goals scored to model the attack
  # and goals conceeded to measure defence rating
  summarise(alpha = mean(g_for),
            beta = mean(g_ag)) %&amp;gt;%
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 3
##   team             alpha  beta
##   &amp;lt;chr&amp;gt;            &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 Arsenal           4.88  0.5 
## 2 Blackburn_Rovers  2.88  0.75
## 3 Coventry_City     1.75  1   
## 4 Dover_Athletic    1     1.88
## 5 Enfield_Town      0.75  2.75
## 6 Frimley_Green     0.25  4.62&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(we’ll come on to the beta parameter in a bit- where alpha is the average scoring rate, beta is the average conceding rate).&lt;/p&gt;
&lt;p&gt;If we take Coventry’s remaining two games as examples we can see that they are yet to play Arsenal and Frimley Green at home&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coventry_games &amp;lt;- unplayed_games %&amp;gt;%
  # filter out Coventry City&amp;#39;s remaining fixtures
  filter(grepl(&amp;quot;Coventry_City&amp;quot;, home)) %&amp;gt;%
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            home          away gameweek
## 1 Coventry_City       Arsenal        9
## 2 Coventry_City Frimley_Green       10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And we can take the attack rating (α) of each team and use it to estimate the results&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get the attack ratings of all teams
team_alphas &amp;lt;- basic_model$alpha %&amp;gt;% `names&amp;lt;-`(basic_model$team)

# assume goals scored for each team will be it&amp;#39;s attack rating
e_results &amp;lt;- paste(team_alphas[coventry_games$home],
                   team_alphas[coventry_games$away],
                   sep = &amp;quot;-&amp;quot;) %&amp;gt;%
  # name each match with the teams competing
  `names&amp;lt;-`(c(paste(coventry_games$home, coventry_games$away, sep = &amp;quot;-&amp;quot;))) %&amp;gt;%
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       Coventry_City-Arsenal Coventry_City-Frimley_Green 
##                &amp;quot;1.75-4.875&amp;quot;                 &amp;quot;1.75-0.25&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These aren’t ridiculous estimates by any stretch but it’s clear something is up. It’s pretty intuitive that Coventry City would be expected to score more goals at home to Frimley Green than at home to Arsenal.&lt;/p&gt;
&lt;p&gt;We can account for this by introducing an opposing team defence parameter β&lt;sub&gt;j&lt;/sub&gt;. In our very simple model this will be estimating by taking the average rate a team concedes goals. As with the attack rating, this is the calculated as the sum of all goals conceded divided by number of matches. We’ll then multiply α&lt;sub&gt;i&lt;/sub&gt; and β&lt;sub&gt;j&lt;/sub&gt; together to get the score estimate:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get and name the defence rating for each team
team_betas &amp;lt;- basic_model$beta %&amp;gt;% `names&amp;lt;-`(basic_model$team)

# assume the goals scored will be the attack rating of the team times 
# the defence rating of it&amp;#39;s opponent
e_results &amp;lt;- paste(round(team_alphas[coventry_games$home]*
                           team_betas[coventry_games$away], 3),
                   round(team_alphas[coventry_games$away]*
                           team_betas[coventry_games$home], 3),
                   sep = &amp;quot;-&amp;quot;) %&amp;gt;%
  `names&amp;lt;-`(c(paste(coventry_games$home, coventry_games$away, sep = &amp;quot;-&amp;quot;))) %&amp;gt;%
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       Coventry_City-Arsenal Coventry_City-Frimley_Green 
##               &amp;quot;0.875-4.875&amp;quot;                &amp;quot;8.094-0.25&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The opposition scores remain the same because Coventry have on average conceded 1 goal per game.&lt;/p&gt;
&lt;p&gt;Coventry’s predicted goals though has diverged with them now predicted to score less than a goal against Arsenal and to score 8(!) against Frimley Green, both of which sound reasonable (when you consider that Frimley Green are a team of amateurs).&lt;/p&gt;
&lt;p&gt;However, we’re also missing one final piece of the model we’ll finish with today. Recall modelling the English football data from 1992 onwards, we were left with a difference between the home scoring rate and the away scoring rate.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# reprint what we calculated earlier
real_data_means&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 2
##   location mean_scored
##   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
## 1 away            1.12
## 2 home            1.47&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It’s pretty common knowledge that football teams do better at home, so we’ll want to factor that in. A simple estimate is to divide the mean home goals/game by the mean away goals/game.&lt;/p&gt;
&lt;p&gt;We’ll call this parameter γ and can be formalised as the sum of home goals (which we’ll refer to as x from now on) divided by the sum of away goals (y)&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\gamma = \frac{\sum{x}}{\sum{y}}\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# the home advantage is how much easier it is to score at home
home_advantage_gamma &amp;lt;- sum(results$hgoal) / sum(results$agoal)

e_results &amp;lt;- paste(round(team_alphas[coventry_games$home]*
                           team_betas[coventry_games$away] * 
                           # add in home advantage for home team
                           home_advantage_gamma, 3),
                   round(team_alphas[coventry_games$away]*
                           team_betas[coventry_games$home], 3),
                   sep = &amp;quot;-&amp;quot;) %&amp;gt;%
  `names&amp;lt;-`(c(paste(coventry_games$home, coventry_games$away, sep = &amp;quot;-&amp;quot;))) %&amp;gt;%
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       Coventry_City-Arsenal Coventry_City-Frimley_Green 
##               &amp;quot;0.955-4.875&amp;quot;                 &amp;quot;8.83-0.25&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Which tilts the scales a little towards Coventry’s favour but (as we’d expect- home advantage can only go so far) doesn’t affect the results too much.&lt;/p&gt;
&lt;p&gt;Now we have a method to predict matches, we can use this on the remaining 6 nice and easily:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# simplify to just gamma
gamma &amp;lt;- home_advantage_gamma

# wrap the above into a function for home and away teams
predict_results &amp;lt;- function(home, away, parameters) {
  e_goals_home &amp;lt;- parameters$alpha[home]*parameters$beta[away] * gamma
  e_goals_away &amp;lt;- parameters$alpha[away]*parameters$beta[home]
  
  # output a df of expected goals for home and away teams
  df &amp;lt;- data.frame(home = home, away = away,
                   e_hgoal = e_goals_home, e_agoal = e_goals_away)
  return(df)
}

# convert the basic_model df into a list with $attack and $defence parameters
# for each team
basic_parameters &amp;lt;- basic_model %&amp;gt;%
  # rename scored/conceeded to attack/defence
  select(-team) %&amp;gt;%
  # convert to a list and name each element
  as.list() %&amp;gt;%
  lapply(., function(x){names(x) &amp;lt;- teams;return(x)})

# predict results using the function defined above and the list of parameters
# could use e.g. mapply here but I prefer the map2 grammar
# run the predict results function over each game consisting of $home and $away
predicted_fixtures &amp;lt;- map2_df(unplayed_games$home, unplayed_games$away, 
                    predict_results,
                    # parameters forms an extra argument that does not vary
                    basic_parameters) %&amp;gt;%
  # round the outputs
  mutate_if(is.numeric, round, digits = 2) %&amp;gt;%
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##               home             away e_hgoal e_agoal
## 1    Coventry_City          Arsenal    0.95    4.88
## 2 Blackburn_Rovers   Dover_Athletic    5.88    0.75
## 3    Frimley_Green     Enfield_Town    0.75    3.47
## 4          Arsenal Blackburn_Rovers    3.99    1.44
## 5    Coventry_City    Frimley_Green    8.83    0.25
## 6   Dover_Athletic     Enfield_Town    3.00    1.41&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All of which look reasonable, if maybe a little bullish on the ‘better’ teams prospects.&lt;/p&gt;
&lt;p&gt;However, while this is good for back of the envelope predictions, we know that this is a very basic model. If we want to improve it, first we must quantify how good it is.&lt;/p&gt;
&lt;p&gt;In order to do this we can use the results we have from the first 8 weeks of matches as training data. We know what the ‘correct’ scores are for these matches, so if our model is good, it will predict similar scores to those observed.&lt;/p&gt;
&lt;p&gt;Remember that for the Poisson distribution, the probability of x goals in one match is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P(x) = \frac{\lambda^{x}e^{-\lambda}}{x!}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The expected value of the Poisson distribution is equal to λ, so we can plug λ as our predicted goals, and x as the actual goals, and calculate the probability of that results occurring &lt;em&gt;given&lt;/em&gt; the attack/defence/home advantage parameters that we think are correct.&lt;/p&gt;
&lt;p&gt;We then do this for all the matches played and get the likelihood for the home and away teams scores given the model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# &amp;#39;predict&amp;#39; the already played matches using our function
predicted_results &amp;lt;- map2_df(results$home, results$away, 
                    predict_results,
                    basic_parameters) %&amp;gt;%
  mutate_if(is.numeric, round, digits = 2) %&amp;gt;%
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                home             away e_hgoal e_agoal
## 1    Dover_Athletic    Coventry_City    1.09    3.28
## 2      Enfield_Town Blackburn_Rovers    0.61    7.91
## 3     Frimley_Green          Arsenal    0.14   22.55
## 4           Arsenal     Enfield_Town   14.62    0.38
## 5  Blackburn_Rovers    Coventry_City    3.14    1.31
## 6     Frimley_Green   Dover_Athletic    0.51    4.62
## 7  Blackburn_Rovers    Frimley_Green   14.51    0.19
## 8     Coventry_City     Enfield_Town    5.25    0.75
## 9    Dover_Athletic          Arsenal    0.55    9.14
## 10          Arsenal    Coventry_City    5.32    0.88
## 11   Dover_Athletic Blackburn_Rovers    0.82    5.39
## 12     Enfield_Town    Frimley_Green    3.78    0.69
## 13 Blackburn_Rovers          Arsenal    1.57    3.66
## 14     Enfield_Town   Dover_Athletic    1.53    2.75
## 15    Frimley_Green    Coventry_City    0.27    8.09
## 16          Arsenal    Frimley_Green   24.60    0.12
## 17 Blackburn_Rovers     Enfield_Town    8.62    0.56
## 18    Coventry_City   Dover_Athletic    3.58    1.00
## 19    Coventry_City Blackburn_Rovers    1.43    2.88
## 20   Dover_Athletic    Frimley_Green    5.05    0.47
## 21     Enfield_Town          Arsenal    0.41   13.41
## 22          Arsenal   Dover_Athletic    9.97    0.50
## 23     Enfield_Town    Coventry_City    0.82    4.81
## 24    Frimley_Green Blackburn_Rovers    0.20   13.30&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# calculate the likelihood of each home/away team actually scoring that many goals
# given the parameters for attack/defence supplied
likelihoods &amp;lt;- data.frame(lik_hgoal = dpois(results$hgoal,
                                            predicted_results$e_hgoal),
                          lik_agoal = dpois(results$agoal,
                                            predicted_results$e_agoal)) %&amp;gt;%
  # round the probabilities
  mutate_all(round, 4) %&amp;gt;%
  # bind likelihoods to results
  cbind(results, . ) %&amp;gt;%
  # bind in predictions
  left_join(., predicted_results, by = c(&amp;quot;home&amp;quot;, &amp;quot;away&amp;quot;)) %&amp;gt;%
  # select useful parameters
  select(home, away, hgoal, e_hgoal, lik_hgoal, agoal, e_agoal, lik_agoal) %&amp;gt;%
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                home             away hgoal e_hgoal lik_hgoal agoal e_agoal
## 1    Dover_Athletic    Coventry_City     0    1.09    0.3362     3    3.28
## 2      Enfield_Town Blackburn_Rovers     0    0.61    0.5434     3    7.91
## 3     Frimley_Green          Arsenal     0    0.14    0.8694     8   22.55
## 4           Arsenal     Enfield_Town     5   14.62    0.0025     0    0.38
## 5  Blackburn_Rovers    Coventry_City     1    3.14    0.1359     1    1.31
## 6     Frimley_Green   Dover_Athletic     1    0.51    0.3063     2    4.62
## 7  Blackburn_Rovers    Frimley_Green     6   14.51    0.0065     0    0.19
## 8     Coventry_City     Enfield_Town     2    5.25    0.0723     1    0.75
## 9    Dover_Athletic          Arsenal     1    0.55    0.3173     3    9.14
## 10          Arsenal    Coventry_City     3    5.32    0.1228     1    0.88
## 11   Dover_Athletic Blackburn_Rovers     1    0.82    0.3612     2    5.39
## 12     Enfield_Town    Frimley_Green     1    3.78    0.0863     0    0.69
## 13 Blackburn_Rovers          Arsenal     0    1.57    0.2080     2    3.66
## 14     Enfield_Town   Dover_Athletic     1    1.53    0.3313     2    2.75
## 15    Frimley_Green    Coventry_City     0    0.27    0.7634     3    8.09
## 16          Arsenal    Frimley_Green    10   24.60    0.0005     0    0.12
## 17 Blackburn_Rovers     Enfield_Town     4    8.62    0.0415     0    0.56
## 18    Coventry_City   Dover_Athletic     1    3.58    0.0998     0    1.00
## 19    Coventry_City Blackburn_Rovers     1    1.43    0.3422     2    2.88
## 20   Dover_Athletic    Frimley_Green     2    5.05    0.0817     0    0.47
## 21     Enfield_Town          Arsenal     2    0.41    0.0558     4   13.41
## 22          Arsenal   Dover_Athletic     4    9.97    0.0193     0    0.50
## 23     Enfield_Town    Coventry_City     1    0.82    0.3612     2    4.81
## 24    Frimley_Green Blackburn_Rovers     1    0.20    0.1637     5   13.30
##    lik_agoal
## 1     0.2213
## 2     0.0303
## 3     0.0003
## 4     0.6839
## 5     0.3535
## 6     0.1052
## 7     0.8270
## 8     0.3543
## 9     0.0137
## 10    0.3650
## 11    0.0663
## 12    0.5016
## 13    0.1724
## 14    0.2417
## 15    0.0271
## 16    0.8869
## 17    0.5712
## 18    0.3679
## 19    0.2328
## 20    0.6250
## 21    0.0020
## 22    0.6065
## 23    0.0943
## 24    0.0058&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we sum the log of those likelihood values we get a measure of how wrong overall our predictions are:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;log_likehood &amp;lt;- sum(log(likelihoods$lik_hgoal), log(likelihoods$lik_agoal)) * -1

log_likehood&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 105.995&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(n.b. there will be some rounding errors- especially on the pre-log probabilities, but this will suffice for now)&lt;/p&gt;
&lt;p&gt;To get an idea of whether or not this is good, let’s quickly run the model with all the parameters set to zero. Given that we’re pretty sure that at least Arsenal will be a lot better than Frimley Green, this model should do worse than our basic model above.&lt;/p&gt;
&lt;p&gt;If it indeed does fit the results worse we will get a greater error term- the log likelihood sum&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# do the same but set each teams attack and defence to 1
# expect model to be worse as assumes all teams are equal
equal_parameters &amp;lt;- list(
  alpha = rep(1, length(teams)) %&amp;gt;% `names&amp;lt;-`(teams),
  beta = rep(1, length(teams)) %&amp;gt;% `names&amp;lt;-`(teams)
)

# predict results and munge through to find sum of log likelihoods
worse_log_likelihood &amp;lt;- map2_df(results$home, results$away, 
                    predict_results,
                    equal_parameters) %&amp;gt;%
  mutate_if(is.numeric, round, digits = 2) %&amp;gt;%
  # take the log probability straight away this time
  mutate(lik_hgoal = dpois(results$hgoal, e_hgoal, log = TRUE),
         lik_agoal = dpois(results$agoal, e_agoal, log = TRUE)) %&amp;gt;%
  select(lik_hgoal, lik_agoal) %&amp;gt;%
  map_dbl(sum) %&amp;gt;%
  sum(.) * -1 

worse_log_likelihood&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 112.618&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The worse log likelihood (112.6) is worse (only a bit though) than the 106.0 we previously. This suggests that either the teams are actually quite equal, or that our basic model wasn’t all that good.&lt;/p&gt;
&lt;div id=&#34;parameter-optimisation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Parameter Optimisation&lt;/h2&gt;
&lt;p&gt;There will exist some parameters (α and β for each team, and γ for the home field advantage) that will minimise this negative log likelihood. That is to say, they will predict the results of the already played games most accurately.&lt;/p&gt;
&lt;p&gt;If we want to find those we can use the optim() function in the stats package. This will take a vector of parameters and iterate while slightly changing their values until it gets the lowest value it can find as the output for a supplied function. It also takes a data.frame of results between teams. The results of these games are predicted and then checked against this actually observed data.&lt;/p&gt;
&lt;p&gt;At the end, I’ve also set the function to pass some information from each iteration into the global environment, namely, the iteration number (i), the parameter values the optim() function has chosen for this iteration, and the negative log likelihood of those parameters- the likelihood of the observed scores if those parameters are correct.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;optimise_params &amp;lt;- function(parameters, results) {
  # form the parameters back into a list
  # parameters names alpha (attack), beta (defense), and gamma (hfa)
  param_list &amp;lt;- relist_params(parameters)
  
  # predict the expected results for the games that have been played
  e_results &amp;lt;- map2_df(results$home, results$away, 
                      predict_results,
                      param_list)
  
  # calculate the negative log likelihood of those predictions
  # given the parameters how likely are those scores
  neg_log_likelihood &amp;lt;- calculate_log_likelihood(results, e_results)
  
  # capture the parameters and likelihood at each loop
  # only do it if i is initialised
  if(exists(&amp;quot;i&amp;quot;)) {
    i &amp;lt;&amp;lt;- i + 1
    current_parameters[[i]] &amp;lt;&amp;lt;- parameters
    current_nll[[i]] &amp;lt;&amp;lt;- neg_log_likelihood
  }
  
  # return the value to be minimised
  # in this case the negative log likelihood
  return(neg_log_likelihood)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The three separate functions are coded out separately so we can tinker with them shortly:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;to predict our results we have been supplying a list of two elements: alpha and beta, each of which are numeric vectors. optim() can only take one vector to optimise over but we can trick it by supplying unlist(&lt;code&gt;list_of_parameters&lt;/code&gt;). If we do this we then first want to convert this unlisted numeric vector back into our two element list*&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;*it isn’t vital to have the parameters arranged like this, but I think it leads to neater indexing when predicting the results&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;we then need to use these parameters to predict the results of past games. For each home and away team in a data.frame of results we can predict the expected home and expected away goals. These are then bound into a data.frame of home and away teams and these predicted goals for each&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;finally, we need to calculate the negative log likelihood by calculating the log probability of the observed goals given the predicted goals and summing these. We then multiply this by -1 as the sum of the log probabilities will be negative and we want to minimise this number as close to zero as possible. The transformation of prod(neg_log_likelihood, -1) is a quick hack for this&lt;sup&gt;4&lt;/sup&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Hopefully this is at least bearable to follow. Formalised, this can be written for teams i and matches k as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mathcal L(\alpha_{i},\beta_{i},\gamma;i = 1 ... n) = \prod_{k = 1}^{K}{\frac{\lambda_{k}^{x_{k}}e^{-\lambda_{k}}}{x_{k}!}\frac{\mu_{k}^{y_{k}}e^{-\mu_{k}}}{y_{k}!}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where for match k and teams i and j, home goals, x is defined by&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[x_{k} \sim Poisson(\lambda_{k} = \alpha_{i(k)}\beta_{j(k)}\gamma)\]&lt;/span&gt;
and away goals, y&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_{k} \sim Poisson(\mu_{k} = \alpha_{j(k)}\beta_{i(k)})\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;which seems daunting when you write it down, but we’ve already covered everything we need to do solve it. It’s just saying we want to minimise the result of the multiplication (the sum of logs in our case above) of the probability of scoring x and y goals in a game. The probability of goals scored assumed to be Poisson distributed, controlled by parameters α, β, and γ for home and away teams.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# optim requires parameters to be supplied as a vector
# we&amp;#39;ll unlist the parameters then relist in the function
relist_params &amp;lt;- function(parameters) {
  parameter_list &amp;lt;- list(
    # alpha = attack rating
    alpha = parameters %&amp;gt;%
      .[grepl(&amp;quot;alpha&amp;quot;, names(.))] %&amp;gt;%
      `names&amp;lt;-`(teams),
    # beta = defence rating
    beta = parameters %&amp;gt;%
      .[grepl(&amp;quot;beta&amp;quot;, names(.))] %&amp;gt;%
      `names&amp;lt;-`(teams),
    # gamma = home field advantage
    gamma = parameters[&amp;quot;gamma&amp;quot;]
  )
  
  return(parameter_list)
}

# use these parameters to predict results for supplied matches
predict_results &amp;lt;- function(home, away, param_list) {
  # expected home goals
  e_goals_home &amp;lt;- param_list$alpha[home] * param_list$beta[away] * param_list$gamma
  # expected away goals
  e_goals_away &amp;lt;- (param_list$alpha[away] * param_list$beta[home])
  
  # bind to df
  df &amp;lt;- data.frame(home = home, away = away,
                   e_hgoal = e_goals_home, e_agoal = e_goals_away)
  
  return(df)
}

# calculate the log likelihood of predict results vs supplied results
calculate_log_likelihood &amp;lt;- function(results, e_results) {
  home_likelihoods = dpois(results$hgoal, lambda = e_results$e_hgoal, log = TRUE)
  away_likelihoods = dpois(results$agoal, lambda = e_results$e_agoal, log = TRUE)
  
  # sum log likelihood and multiply by -1 so we&amp;#39;re minimising neg log likelihood
  likelihood_sum &amp;lt;- sum(home_likelihoods, away_likelihoods)
  neg_log_likelihood &amp;lt;- prod(likelihood_sum, -1)
  
  return(neg_log_likelihood)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’ll supply parameters that are all equal to 1 to optim to stop it falling into local minima that might affect the ‘optimal’ parameters it finds. The unlisted parameters are then supplied to optim along with the optimise_parameters() function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# start with all parameters equal
equal_parameters &amp;lt;- list(
  alpha = rep(1, length(teams)) %&amp;gt;% `names&amp;lt;-`(teams),
  beta = rep(1, length(teams)) %&amp;gt;% `names&amp;lt;-`(teams),
  gamma = 1
)

# run optim over the functions with these initial parameters
optimised_parameters &amp;lt;- optim(
  # the equal initial parameters
  par = unlist(equal_parameters),
  # run over the function to optimise parameters
  fn = optimise_params,
  # extra arguments to function
  results = results,
  # Nelder-Mead equation with 10k iterations max
  method = &amp;quot;Nelder-Mead&amp;quot;,
  control = list(maxit = 10000)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can take the $par element of the output of this to find the parameters for which the negative log likelihood is minimised&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# display the parameters found to minimise
# the negative log likelihood
optimised_parameters$par&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          alpha.Arsenal alpha.Blackburn_Rovers    alpha.Coventry_City 
##              2.9858302              1.8014838              1.2995271 
##   alpha.Dover_Athletic     alpha.Enfield_Town    alpha.Frimley_Green 
##              0.8192267              0.7762002              0.2748448 
##           beta.Arsenal  beta.Blackburn_Rovers     beta.Coventry_City 
##              0.4738011              0.6346112              0.7503864 
##    beta.Dover_Athletic      beta.Enfield_Town     beta.Frimley_Green 
##              1.2208768              1.5180931              2.5535961 
##                  gamma 
##              1.1663125&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As expected, alpha decreases as teams get worse, and beta increases. The found gamma (1.166) is only marginally higher than the 1.091 for our simple model.&lt;/p&gt;
&lt;p&gt;The $value element gives the negative log likelihood calculated for these parameters&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;optimised_parameters$value&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 57.5175&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Which is much smaller than the ~100 we got from our very basic model.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tinkering&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Tinkering&lt;/h2&gt;
&lt;p&gt;This is all very well but there’s still some small improvements we can make.&lt;/p&gt;
&lt;p&gt;For starters, I always think it’s simpler to have both scales of α and β to increase as a teams becomes more skillful in attack or defence. In our original equation the expected home and away goals follow the formula&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[x_{ij} \sim Poisson(α_{i}β_{j}γ)\]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[y_{ij} \sim Poisson(α_{j}β_{i})\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;if instead of multiplying by β, we divide instead, a stronger defence will reduce the value of x&lt;sub&gt;ij&lt;/sub&gt;/y&lt;sub&gt;ij&lt;/sub&gt; (reducing the number of expected goals for the opposing team).&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[x_{ij} \sim Poisson(\frac{α_{i}γ}{β_{j}})\]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[y_{ij} \sim Poisson(\frac{α_{j}}{β_{i}})\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;To achieve this we just have to flip two lines of the predict_results function. Instead of multiplying α and β, we divide them instead.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# change prediction to inverse defence parameters
predict_results &amp;lt;- function(home, away, param_list) {
  e_goals_home &amp;lt;- (param_list$alpha[home] / param_list$beta[away]) * param_list$gamma
  e_goals_away &amp;lt;- (param_list$alpha[away] / param_list$beta[home])
  
  df &amp;lt;- data.frame(home = home, away = away,
                   e_hgoal = e_goals_home, e_agoal = e_goals_away)
  
  return(df)
}

# re run using new subfunction
optimised_parameters2 &amp;lt;- optim(
  par = unlist(equal_parameters),
  fn = optimise_params,
  results = results,
  method = &amp;quot;Nelder-Mead&amp;quot;,
  control = list(maxit = 10000))

# check this does what we want
optimised_parameters2$par&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(n.b. I won’t print out the results of all these steps as this post is long enough, but you can run and see the gradual improvements for yourself)&lt;/p&gt;
&lt;p&gt;Next we want to subtly change how the expected goals are calculated.&lt;/p&gt;
&lt;p&gt;Given that&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ A = \frac{B \cdot C}{D}\]&lt;/span&gt;
is exactly the same as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ A = e ^{log(B) + log(C) - log(D)}\]&lt;/span&gt;
we can convert the parameters we are looking for into log(parameters) and take the exponent of their sum as the predicted goals. This might seem like a minor change, but prevents an important exception. Using home goals as an example, remember that&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[x_{ij} \sim Poisson(\frac{α_{i}γ}{β_{j}})\]&lt;/span&gt;
if any of the three parameters become negative then we’re left with a Poisson distribution with a negative mean, which is is absurd: events cannot unhappen. For instance, imagine a football game where one team scores negative goals.&lt;/p&gt;
&lt;p&gt;If we take the log parameters instead we have&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[x_{ij} \sim Poisson(e ^ {α_{i} - β_{j} + γ})\]&lt;/span&gt;
where no matter what values α, β, or γ take, the exponent of their sum will never be negative. When playing a very strong away teams, the mean goals will tend towards 0 (though will never actually reach it).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# change prediction to use log parameters
# exp(log(x) + log(y)) = x * y
predict_results &amp;lt;- function(home, away, param_list) {
  e_goals_home &amp;lt;- exp(param_list$alpha[home] - param_list$beta[away] + param_list$gamma)
  e_goals_away &amp;lt;- exp(param_list$alpha[away] - param_list$beta[home])
  
  df &amp;lt;- data.frame(home = home, away = away,
                   e_hgoal = e_goals_home, e_agoal = e_goals_away)
  
  return(df)
}

# initialise parameters as all 0
# log(1) = 0
equal_parameters &amp;lt;- list(
  alpha = rep(0, length(teams)) %&amp;gt;% `names&amp;lt;-`(teams),
  beta = rep(0, length(teams)) %&amp;gt;% `names&amp;lt;-`(teams),
  gamma = 0
)

# re run using new subfunction
optimised_parameters3 &amp;lt;- optim(
  par = unlist(equal_parameters), 
  fn = optimise_params,
  results = results,
  # using log will avoid non-finite differences 
  # so can use BFGS model
  method = &amp;quot;BFGS&amp;quot;,
  control = list(maxit = 10000))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’ve also switched optimisation algorithm from Nelder-Mead to BFGS. BFGS is &lt;a href=&#34;https://docs.mantidproject.org/v3.7.1/concepts/FittingMinimizersComparisonDetailed.html#minimizers-unweighted-comparison-in-terms-of-accuracy&#34;&gt;quicker&lt;/a&gt; than Nelder-Mead but requires the minimisation function (i.e. the negative log likelihood we calculate) to be finite. Before, we could get infinite negative log likelihoods, as it was possible to calculate a negative mean (expected goals for a team). Running dpois() for a negative lambda will return NaN so it becomes impossible to calculate the final negative log likelihood.&lt;/p&gt;
&lt;p&gt;Finally, we want to constrain the final optimised parameters by fixing the sum of all attack parameters, and the sum of all defence parameters, to equal 0. In practice, this basically means that above average attacking/defending teams will have parameters above 0, and below average teams will have parameters below 0. This is handy, but also the main advantage is this prevents &lt;a href=&#34;https://en.wikipedia.org/wiki/Overfitting&#34;&gt;overfitting&lt;/a&gt; of the parameters by the optimisation algorithm.&lt;/p&gt;
&lt;p&gt;To do this, we can simply drop the first (or last, or any, it doesn’t matter) parameter from attack or defence (the parameters for Arsenal) and then calculate Arsenal’s parameters as the sum of the remaining parameters multiplied by minus 1.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\alpha_{n} = -\sum_{i = 1}^{n-1} \alpha_{i} \]&lt;/span&gt;
and also&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\beta_{n} = -\sum_{i = 1}^{n-1} \beta_{i} \]&lt;/span&gt;
In terms of code this just requires adding one line to the relist_params() function to append the value back. We also then need to remove this parameter that we will add back in from the initial parameters which is done below.&lt;/p&gt;
&lt;p&gt;Our output will now be missing the parameters for Arsenal (as they will only exist within the function), but we can easily calculate it from the parameters we do get out.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# introduce sum to zero constraint by calculating
# first teams parameters as minus sum of the rest
relist_params &amp;lt;- function(parameters) {
  parameter_list &amp;lt;- list(
    alpha = parameters %&amp;gt;%
      .[grepl(&amp;quot;alpha&amp;quot;, names(.))] %&amp;gt;%
      append(prod(sum(.), -1), .) %&amp;gt;%
      `names&amp;lt;-`(teams),
    beta = parameters %&amp;gt;%
      .[grepl(&amp;quot;beta&amp;quot;, names(.))] %&amp;gt;%
      append(prod(sum(.), -1), .) %&amp;gt;%
      `names&amp;lt;-`(teams),
    gamma = parameters[&amp;quot;gamma&amp;quot;]
  )
  
  return(parameter_list)
}

# remove the first team from the attack and defence ratings
equal_parameters &amp;lt;- list(
  alpha = rep(0, length(teams)-1) %&amp;gt;% `names&amp;lt;-`(teams[2:length(teams)]),
  beta = rep(0, length(teams)-1) %&amp;gt;% `names&amp;lt;-`(teams[2:length(teams)]),
  gamma = 0
)

# initialise i to collect data about the optimisation process at each iteration
i &amp;lt;- 0
# collect current parameter values and neg log likelihood at each iteration
current_parameters &amp;lt;- list()
current_nll &amp;lt;- list()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can then final the optim() function one final time to get our final optimised parameters&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# run our final calculation
optimised_parameters4 &amp;lt;- optim(
  par = unlist(equal_parameters), 
  fn = optimise_params,
  results = results,
  method = &amp;quot;BFGS&amp;quot;,
  control = list(maxit = 10000))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can plot the log likelihood at each iteration. Notice how it starts around &amp;lt;120, which is pretty close what our worse_log_likelihood returned. For these optimisations, the original parameters we are supplying are similar to the zeroed parameters for that example.&lt;/p&gt;
&lt;p&gt;As the optim() function plays with the parameters you can see the log likelihood jumps around quite violently, but over time tend towards zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p3 &amp;lt;- data.frame(likelihood = unlist(current_nll),
                iteration = seq(length(current_nll))) %&amp;gt;%
  ggplot(aes(x = iteration, y = likelihood)) +
  geom_line(colour = &amp;quot;red&amp;quot;) +
  # cut out some cases where optim() has been a bit ambitious
  coord_cartesian(ylim = c(0, 250)) +
  labs(title = &amp;quot;Negative log likelihood of parameters over iterations&amp;quot;,
       y = &amp;quot;negative log likelihood&amp;quot;,
       x = &amp;quot;iteration&amp;quot;) +
  theme_minimal()

p3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-30-5-dixon-coles-1_files/figure-html/plot_log_liks-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The final parameters can also be extracted from the output from optim() and plotted:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p4 &amp;lt;- optimised_parameters4$par %&amp;gt;%
  # relist to add in first team
  relist_params() %&amp;gt;%
  unlist() %&amp;gt;%
  # select team parameters
  .[grepl(&amp;quot;beta|alpha&amp;quot;, names(.))] %&amp;gt;%
  data.frame(value = .,
             parameter = names(.)) %&amp;gt;%
  separate(parameter, into = c(&amp;quot;parameter&amp;quot;, &amp;quot;team&amp;quot;), &amp;quot;\\.&amp;quot;) %&amp;gt;%
  # spread into wide format
  spread(parameter, value) %&amp;gt;%
  # pipe into a plot
  ggplot(aes(x = alpha, y = beta)) +
  geom_point() +
  ggrepel::geom_text_repel(aes(label = team)) +
  stat_smooth(method = &amp;quot;lm&amp;quot;, se = FALSE) +
  labs(title = &amp;quot;Optimal parameters for teams&amp;quot;,
       subtitle = &amp;quot;given first 8 weeks of results&amp;quot;,
       x = &amp;quot;alpha (more likely to score -&amp;gt;)&amp;quot;,
       y = &amp;quot;beta (less likely to concede -&amp;gt;)&amp;quot;) +
  theme_minimal()

p4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-30-5-dixon-coles-1_files/figure-html/plot_parameters-1.png&#34; width=&#34;672&#34; /&gt;
Notice how the teams monotonically increase in both attack and defensive ability. This is by design on how the results were created (see the bottom of this post). With only 8 games per team however, there is quite a lot of noise in the signal. Hitting the crossbar instead of scoring in one game could make a fairly large difference in how the function rates a team.&lt;/p&gt;
&lt;p&gt;Also note how the regression line passes through the origin- this is a result of us constraining the parameters to sum to zero.&lt;/p&gt;
&lt;p&gt;If we want to see how optim() selects these, we can plot how they change over iterations. You can see how it jumps around then settles on incremental improvements to the model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p5 &amp;lt;- current_parameters %&amp;gt;%
  # get the parameters for arsenal for each iteration
  lapply(., function(x){ unlist(relist_params(x))}) %&amp;gt;%
  map_df(bind_rows, .id = &amp;quot;iteration&amp;quot;) %&amp;gt;%
  # melt data and split parameters into team and parameter
  gather(&amp;quot;parameter&amp;quot;, &amp;quot;value&amp;quot;, -iteration) %&amp;gt;%
  # get rid of the gamma parameter
  filter(parameter != &amp;quot;gamma.gamma&amp;quot;) %&amp;gt;%
  separate(parameter, into = c(&amp;quot;parameter&amp;quot;, &amp;quot;team&amp;quot;), sep = &amp;quot;\\.&amp;quot;) %&amp;gt;%
  # spread data back by parameter
  spread(parameter, value) %&amp;gt;%
  mutate(iteration = as.numeric(iteration)) %&amp;gt;%
  # plot alpha against beta for each iteration
  ggplot(aes(x = alpha, y = beta)) +
  geom_text(aes(label = team)) +
  labs(title = &amp;#39;Parameters for Iteration {floor(frame_time)}&amp;#39;,
       subtitle = &amp;quot;given first 8 weeks of results&amp;quot;,
       x = &amp;quot;alpha (more likely to score -&amp;gt;)&amp;quot;,
       y = &amp;quot;beta (less likely to concede -&amp;gt;)&amp;quot;) +
  # using gganimate package
  gganimate::transition_time(iteration) +
  gganimate::ease_aes(&amp;#39;linear&amp;#39;) +
  gganimate::view_follow()

# animate the plot
gganimate::animate(p5, nframes = i)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-30-5-dixon-coles-1_files/figure-html/plot_optimisation_animation-1.gif&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;predict-remaining-matches&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Predict Remaining Matches&lt;/h2&gt;
&lt;p&gt;Now we have rated each teams attack/defense, and the advantage to a team to play at home, we can predict the remaining matches between the teams.&lt;/p&gt;
&lt;p&gt;For this, we just have to use the predict_results() function we defined earlier, except this time the output will be the expected goals per team. Earlier we were measuring the deviance from expectation, but not we assume the most likely result is exactly equal to the expected results. If we wanted to we could work out how likely this result is, and what the most likely results are.&lt;/p&gt;
&lt;p&gt;This post is long enough however, so for now, we’ll just detail the most likely results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;predicted_results &amp;lt;- predict_results(unplayed_games$home,
                      unplayed_games$away, 
                      relist_params(optimised_parameters4$par)) %&amp;gt;%
  mutate_if(is.numeric, round, 2) %&amp;gt;%
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##               home             away e_hgoal e_agoal
## 1    Coventry_City          Arsenal    0.86    2.11
## 2 Blackburn_Rovers   Dover_Athletic    2.62    0.49
## 3    Frimley_Green     Enfield_Town    0.44    1.72
## 4          Arsenal Blackburn_Rovers    2.39    0.99
## 5    Coventry_City    Frimley_Green    4.09    0.17
## 6   Dover_Athletic     Enfield_Town    1.33    0.79&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All of these look reasonable, with better teams beating worse ones. The only match that the model thinks might well end in a draw is Dover at home to Enfield, which is not entirely unreasonable.&lt;/p&gt;
&lt;p&gt;We can add these predictions to our earlier matrix of results to get a sense if these fit in with the trend from the observed matches:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p6 &amp;lt;- rbind(
  predicted_results %&amp;gt;%
    rename_if(is.numeric, gsub, pattern = &amp;quot;e_&amp;quot;, replacement = &amp;quot;&amp;quot;) %&amp;gt;%
    mutate(type = &amp;quot;predicted&amp;quot;),
  results %&amp;gt;%
    select(-gameweek) %&amp;gt;%
    mutate(type = &amp;quot;result&amp;quot;)
) %&amp;gt;%
  ggplot(., aes(x = away, y = home, fill = hgoal-agoal)) +
  geom_tile() +
  # add the scorelines
  geom_label(aes(label = paste(hgoal, agoal, sep = &amp;quot;-&amp;quot;), colour = type), fill = &amp;quot;white&amp;quot;) +
  # colour where black for actual results and red for predictions
  scale_colour_manual(values = c(&amp;quot;red&amp;quot;, &amp;quot;black&amp;quot;)) +
  # colour where green shows home win and red an away win
  scale_fill_gradient2(low = &amp;quot;darkred&amp;quot;, high = &amp;quot;green&amp;quot;, midpoint = 0, guide = FALSE) +
  scale_x_discrete(limits = levels(results$home), position = &amp;quot;top&amp;quot;) +
  scale_y_discrete(limits = rev(levels(results$away))) +
  theme_minimal()

p6&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-30-5-dixon-coles-1_files/figure-html/plot_all_games-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Which they do! The predicted results fit in with the gradient of heavier defeats for home teams towards the bottom left, progressing to easy home victories in the top right.&lt;/p&gt;
&lt;p&gt;That’s all for this post. Hopefully using the Poisson distribution to model football matches is a little clearer now. Feel free to email me any questions and check out the packages I stole all the codes/idea from.&lt;/p&gt;
&lt;p&gt;Next time, I’ll go over how to quantify the probability of a range of results for any single match in (hopefully) a shorter post; until then!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;notes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Notes&lt;/h2&gt;
&lt;p&gt;&lt;sup&gt;1&lt;/sup&gt; much of the code I use here is stolen/reworked from the code shared on this repo&lt;/p&gt;
&lt;p&gt;&lt;sup&gt;2&lt;/sup&gt; towards the end of writing this post I came across &lt;a href=&#34;https://dashee87.github.io/football/python/predicting-football-results-with-statistical-modelling-dixon-coles-and-time-weighting/&#34;&gt;David Sheehan’s blog&lt;/a&gt; which actually does a pretty good job, but I felt still didn’t quite go through how/why the model uses the maths it does&lt;/p&gt;
&lt;p&gt;&lt;sup&gt;3&lt;/sup&gt; see &lt;a href=&#34;https://arxiv.org/pdf/cond-mat/0110605.pdf&#34; class=&#34;uri&#34;&gt;https://arxiv.org/pdf/cond-mat/0110605.pdf&lt;/a&gt; and also the conclusion of &lt;a href=&#34;https://dashee87.github.io/football/python/predicting-football-results-with-statistical-modelling/&#34;&gt;David Sheehan’s blog on Dixon-Coles processes&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;sup&gt;4&lt;/sup&gt; *we could instead &lt;em&gt;maximise&lt;/em&gt; the sum of the log likelihoods and then the error will converge towards 0 from a negative number. Either is fine.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;results-generation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Results Generation&lt;/h2&gt;
&lt;p&gt;First we need to create a data.frame of fixtures for each team&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# https://stackoverflow.com/questions/54099990/is-there-an-efficient-algorithm-to-create-this-type-of-schedule
create_fixtures &amp;lt;- function(teams) {
  # keep team 1 in place
  team1 &amp;lt;- as.character(teams[1])
  #rotate other teams around team 1
  other_teams &amp;lt;- as.character(teams[!teams %in% team1])
  length &amp;lt;- length(other_teams)
  
  # generate fixtures each week
  for(week in seq((length(teams)-1)*2)) {
    
    if(week %% 2 == 0) {
      fixtures &amp;lt;- data.frame(home = c(team1, other_teams[1:2]),
                             away = other_teams[length:3],
                             gameweek = week)
    } else {
      fixtures &amp;lt;- data.frame(home = other_teams[length:3],
                             away = c(team1, other_teams[1:2]),
                             gameweek = week)
      
    }
    
    if(week == 1) {
      fixtures_df &amp;lt;- fixtures 
    } else {
      fixtures_df &amp;lt;- rbind(fixtures_df, fixtures)
    }
    
    # rotate other teams around
    other_teams &amp;lt;- c(other_teams[length], other_teams[1:length-1])
  }
  
  return(fixtures_df)
}

# create the fixtures
fixtures &amp;lt;- create_fixtures(teams) %&amp;gt;%
  mutate_if(is.factor, as.character)

# print the fixture list
fixtures&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                home             away gameweek
## 1     Frimley_Green          Arsenal        1
## 2      Enfield_Town Blackburn_Rovers        1
## 3    Dover_Athletic    Coventry_City        1
## 4           Arsenal     Enfield_Town        2
## 5     Frimley_Green   Dover_Athletic        2
## 6  Blackburn_Rovers    Coventry_City        2
## 7    Dover_Athletic          Arsenal        3
## 8     Coventry_City     Enfield_Town        3
## 9  Blackburn_Rovers    Frimley_Green        3
## 10          Arsenal    Coventry_City        4
## 11   Dover_Athletic Blackburn_Rovers        4
## 12     Enfield_Town    Frimley_Green        4
## 13 Blackburn_Rovers          Arsenal        5
## 14    Frimley_Green    Coventry_City        5
## 15     Enfield_Town   Dover_Athletic        5
## 16          Arsenal    Frimley_Green        6
## 17 Blackburn_Rovers     Enfield_Town        6
## 18    Coventry_City   Dover_Athletic        6
## 19     Enfield_Town          Arsenal        7
## 20   Dover_Athletic    Frimley_Green        7
## 21    Coventry_City Blackburn_Rovers        7
## 22          Arsenal   Dover_Athletic        8
## 23     Enfield_Town    Coventry_City        8
## 24    Frimley_Green Blackburn_Rovers        8
## 25    Coventry_City          Arsenal        9
## 26 Blackburn_Rovers   Dover_Athletic        9
## 27    Frimley_Green     Enfield_Town        9
## 28          Arsenal Blackburn_Rovers       10
## 29    Coventry_City    Frimley_Green       10
## 30   Dover_Athletic     Enfield_Town       10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and then create the results&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# using goalmodel package 
# https://github.com/opisthokonta/goalmodel
library(goalmodel)

# have to manually create a list of parameters
model &amp;lt;- list()
# stratify teams abilities in attack and defense
model$parameters &amp;lt;- list(attack = seq(1, -1 + 2/length(teams), by = -2/(length(teams)-1)) %&amp;gt;%
                           append(-sum(.)) %&amp;gt;%
                           `names&amp;lt;-`(teams), 
                         defense = seq(1, -1 + 2/length(teams), by = -2/(length(teams)-1)) %&amp;gt;%
                           append(-sum(.)) %&amp;gt;%
                           `names&amp;lt;-`(teams), 
                         # no base rate of goals
                         intercept = 0, 
                         # roughly accurate hfa for English professional football
                         hfa = 0.3)

# add in teams
model$all_teams &amp;lt;- teams
# use a simple Poisson model with 8 goals max
model$model &amp;lt;- &amp;quot;poisson&amp;quot;
model$maxgoal &amp;lt;- 8

# use the model to predict results using regista package
results &amp;lt;- predict_expg(model, fixtures$home, fixtures$away, return_df = TRUE) %&amp;gt;%
  # add some noise
  mutate(noise1 = rnorm(nrow(.), 0, 0.5),
         noise2 = rnorm(nrow(.), 0, 0.5)) %&amp;gt;%
  mutate(hgoal = round(expg1 + noise1,0 ),
         agoal = round(expg2 + noise2,0),
         home = as.factor(team1),
         away = as.factor(team2)) %&amp;gt;%
  # merge to fixtures
  merge(., fixtures, by = c(&amp;quot;home&amp;quot;, &amp;quot;away&amp;quot;)) %&amp;gt;%
  # cant score less than zero goals
  mutate_at(vars(hgoal:agoal), funs(replace(., .&amp;lt;0, 0))) %&amp;gt;%
  select(home, away, hgoal, agoal, gameweek) %&amp;gt;%
  arrange(gameweek, home) %&amp;gt;%
  # treat only first 8 weeks as played
  filter(gameweek &amp;lt;= 8)

# print results
results&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                home             away hgoal agoal gameweek
## 1    Dover_Athletic    Coventry_City     0     2        1
## 2      Enfield_Town Blackburn_Rovers     1     3        1
## 3     Frimley_Green          Arsenal     0     6        1
## 4           Arsenal     Enfield_Town     6     0        2
## 5  Blackburn_Rovers    Coventry_City     2     0        2
## 6     Frimley_Green   Dover_Athletic     0     3        2
## 7  Blackburn_Rovers    Frimley_Green     8     0        3
## 8     Coventry_City     Enfield_Town     3     1        3
## 9    Dover_Athletic          Arsenal     1     3        3
## 10          Arsenal    Coventry_City     3     0        4
## 11   Dover_Athletic Blackburn_Rovers     1     2        4
## 12     Enfield_Town    Frimley_Green     2     1        4
## 13 Blackburn_Rovers          Arsenal     2     2        5
## 14     Enfield_Town   Dover_Athletic     0     2        5
## 15    Frimley_Green    Coventry_City     1     3        5
## 16          Arsenal    Frimley_Green     9     0        6
## 17 Blackburn_Rovers     Enfield_Town     5     0        6
## 18    Coventry_City   Dover_Athletic     1     2        6
## 19    Coventry_City Blackburn_Rovers     0     2        7
## 20   Dover_Athletic    Frimley_Green     3     1        7
## 21     Enfield_Town          Arsenal     0     5        7
## 22          Arsenal   Dover_Athletic     4     1        8
## 23     Enfield_Town    Coventry_City     1     2        8
## 24    Frimley_Green Blackburn_Rovers     1     4        8&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
